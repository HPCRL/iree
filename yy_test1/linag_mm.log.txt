// -----// IR Dump After StablehloLegalizeToHloPass (stablehlo-legalize-to-hlo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After LegalizeControlFlowPass (mhlo-legalize-control-flow) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After TopLevelSCFToCFG (iree-top-level-scf-to-cfg) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After MHLOToMHLOPreprocessing (iree-mhlo-to-mhlo-preprocessing) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After ShapeToShapeLowering (shape-to-shape-lowering) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After ConvertShapeToStandard (convert-shape-to-std) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After Inliner (inline) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After DemoteI64ToI32 (iree-util-demote-i64-to-i32) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After DemoteF64ToF32 (iree-util-demote-f64-to-f32) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After HloLegalizeShapeComputationsPass (hlo-legalize-shape-computations) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After ConvertMHLOToLinalgExt (iree-mhlo-to-linalg-ext) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After ConvertMHLOToLinalgOnTensors (iree-mhlo-to-linalg-on-tensors) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After VerifyCompilerMHLOInputLegality (iree-mhlo-verify-compiler-input-legality) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After IREEImportPublic (iree-import-public) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After ImportMLProgram (iree-import-ml-program) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After SanitizeModuleNames (iree-sanitize-module-names) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = call @_matmul_static(%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
  func.func private @_matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
    %0 = linalg.matmul {compilation_info = #compilation} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    return %0 : tensor<512x1024xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_static(%arg0: tensor<512x256xf32>, %arg1: tensor<256x1024xf32>, %arg2: tensor<512x1024xf32>) -> tensor<512x1024xf32> {
  %0 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%arg0, %arg1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%arg2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  return %0 : tensor<512x1024xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = call @_matmul_static(%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteF64ToF32 (iree-util-demote-f64-to-f32) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After DetachElementwiseFromNamedOps (iree-flow-detach-elementwise-from-named-ops) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversion (linalg-named-op-conversion) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Convert1X1FilterConv2DToMatmul (iree-flow-convert-1x1-filter-conv2d-to-matmul) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After VerifyInputLegality (iree-verify-input-legality) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapes (iree-flow-expand-tensor-shapes) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After TensorPadToTensorInsertSlice (iree-flow-tensor-pad-to-tensor-insert-slice) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalg (convert-elementwise-to-linalg) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgFoldUnitExtentDims (linalg-fold-unit-extent-dims) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After FusionOfTensorOps (iree-flow-fusion-of-tensor-ops) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgDetensorize (linalg-detensorize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CollapseDims (iree-flow-collapse-dims) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SplitReduction (iree-flow-split-reduction-ops) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegions (iree-flow-form-dispatch-regions) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1_0 = arith.constant 1 : index
  %3 = affine.apply affine_map<()[s0, s1, s2] -> ((s1 - s0) ceildiv s2)>()[%c0, %c512, %c1_0]
  %c0_1 = arith.constant 0 : index
  %c1024 = arith.constant 1024 : index
  %c1_2 = arith.constant 1 : index
  %4 = affine.apply affine_map<()[s0, s1, s2] -> ((s1 - s0) ceildiv s2)>()[%c0_1, %c1024, %c1_2]
  %c0_3 = arith.constant 0 : index
  %c1_4 = arith.constant 1 : index
  %5 = affine.apply affine_map<()[s0, s1, s2] -> ((s1 - s0) ceildiv s2)>()[%c0_3, %c1, %c1_4]
  %6 = flow.dispatch.region[%3, %4, %5] -> (tensor<512x1024xf32>) {
    %8 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.return %8 : tensor<512x1024xf32>
  } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
    flow.return %x, %y, %z : index, index, index
  }
  %7 = hal.tensor.export %6 : tensor<512x1024xf32> -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchWorkgroups (iree-flow-form-dispatch-workgroups) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch.workgroups[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2 =
      (%arg3: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg5: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
    %5 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %6 = flow.dispatch.tensor.load %arg4, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %7 = flow.dispatch.tensor.load %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %8 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%5, %6 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%7 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %8, %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    flow.return
  } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CaptureDispatchDynamicDims (iree-flow-capture-dispatch-dynamic-dims) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch.workgroups[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2 =
      (%arg3: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg5: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
    %5 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %6 = flow.dispatch.tensor.load %arg4, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %7 = flow.dispatch.tensor.load %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %8 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%5, %6 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%7 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %8, %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    flow.return
  } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch.workgroups[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2 =
      (%arg3: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg5: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
    %5 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %6 = flow.dispatch.tensor.load %arg4, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %7 = flow.dispatch.tensor.load %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %8 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%5, %6 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%7 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %8, %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    flow.return
  } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch.workgroups[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2 =
      (%arg3: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg5: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
    %5 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %6 = flow.dispatch.tensor.load %arg4, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %7 = flow.dispatch.tensor.load %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %8 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%5, %6 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%7 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %8, %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    flow.return
  } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After InitializeEmptyTensors (iree-flow-initialize-empty-tensors) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch.workgroups[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2 =
        (%arg3: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg4: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg5: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
      %5 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
      %6 = flow.dispatch.tensor.load %arg4, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
      %7 = flow.dispatch.tensor.load %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
      %8 = linalg.matmul {compilation_info = #compilation} ins(%5, %6 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%7 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
      flow.dispatch.tensor.store %8, %arg5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      flow.return
    } count(%arg3: index, %arg4: index, %arg5: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg3, %arg4, %arg5
      flow.return %x, %y, %z : index, index, index
    }
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineDispatchRegions (iree-flow-outline-dispatch-regions) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @matmul_static_dispatch_0 {
  flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
      %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
      flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutables (iree-flow-deduplicate-executables) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
flow.executable private @matmul_static_dispatch_0 {
  flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
      %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
      flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      return
    }
  }
}

// -----// IR Dump After CSE (cse) //----- //
flow.executable private @matmul_static_dispatch_0 {
  flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
      %3 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
      flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      return
    }
  }
}

// -----// IR Dump After CleanupTensorShapes (iree-flow-cleanup-tensor-shapes) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInput (iree-stream-verify-input) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineConstants (iree-stream-outline-constants) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
  %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
  %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
  %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
  %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  flow.executable private @matmul_static_dispatch_0 {
    flow.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !flow.dispatch.tensor<readonly:tensor<512x256xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %3 = linalg.matmul {compilation_info = #compilation} ins(%0, %1 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%2 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = hal.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32>
    %1 = hal.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32>
    %2 = hal.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32>
    %3 = flow.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0, %1, %2) : (tensor<512x256xf32>, tensor<256x1024xf32>, tensor<512x1024xf32>) -> %2
    %4 = hal.tensor.export %3 : tensor<512x1024xf32> -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStream (iree-stream-conversion) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c512_0 = arith.constant 512 : index
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512_0, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %c553648160_i32_1 = arith.constant 553648160 : i32
    %c1_i32_2 = arith.constant 1 : i32
    %c256_3 = arith.constant 256 : index
    %c1024_4 = arith.constant 1024 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256_3, %c1024_4]) type(%c553648160_i32_1) encoding(%c1_i32_2)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %c553648160_i32_5 = arith.constant 553648160 : i32
    %c1_i32_6 = arith.constant 1 : i32
    %c512_7 = arith.constant 512 : index
    %c1024_8 = arith.constant 1024 : index
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512_7, %c1024_8]) type(%c553648160_i32_5) encoding(%c1_i32_6)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %c0 = arith.constant 0 : index
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensors (iree-stream-verify-lowering-to-tensors) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c512_0 = arith.constant 512 : index
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512_0, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %c553648160_i32_1 = arith.constant 553648160 : i32
    %c1_i32_2 = arith.constant 1 : i32
    %c256_3 = arith.constant 256 : index
    %c1024_4 = arith.constant 1024 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256_3, %c1024_4]) type(%c553648160_i32_1) encoding(%c1_i32_2)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %c553648160_i32_5 = arith.constant 553648160 : i32
    %c1_i32_6 = arith.constant 1 : i32
    %c512_7 = arith.constant 512 : index
    %c1024_8 = arith.constant 1024 : index
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512_7, %c1024_8]) type(%c553648160_i32_5) encoding(%c1_i32_6)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %c0 = arith.constant 0 : index
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.sizeof tensor<512x256xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
  %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
  %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
  %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
  %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
  %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
  %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.sizeof tensor<512x256xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
  %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
  %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
  %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
  %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
  %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
  %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.sizeof tensor<512x256xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
  %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
  %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
  %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
  %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
  %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
  %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.sizeof tensor<512x256xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = stream.tensor.sizeof tensor<256x1024xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = stream.tensor.sizeof tensor<512x1024xf32> : index
    %7 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%6}
    %8 = stream.async.transfer %7 : !stream.resource<external>{%6} -> !stream.resource<*>{%6}
    %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%2[%c0 to %0 for %0], %5[%c0 to %3 for %3], %8[%c0 to %6 for %6]) : (!stream.resource<*>{%0}, !stream.resource<*>{%3}, !stream.resource<*>{%6}) -> %8{%6}
    %10 = stream.async.transfer %9 : !stream.resource<*>{%6} -> !stream.resource<external>{%6}
    %11 = stream.tensor.export %10 : tensor<512x1024xf32> in !stream.resource<external>{%6} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeDeviceTensors (iree-stream-encode-device-tensors) //----- //
stream.executable private @matmul_static_dispatch_0 {
  stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
      %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
      %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
      %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
      flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      return
    }
  }
}

// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After MaterializeBuiltins (iree-stream-materialize-builtins) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopies (iree-stream-elide-async-copies) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
    %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c524288} -> !stream.resource<*>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c1048576} -> !stream.resource<*>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %4 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%c2097152} -> !stream.resource<*>{%c2097152}
  %6 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%1[%c0 to %c524288 for %c524288], %3[%c0 to %c1048576 for %c1048576], %5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<*>{%c524288}, !stream.resource<*>{%c1048576}, !stream.resource<*>{%c2097152}) -> %5{%c2097152}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%c2097152} -> !stream.resource<external>{%c2097152}
  %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After RefineUsage (iree-stream-refine-usage) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%0[%c0 to %c524288 for %c524288], %1[%c0 to %c1048576 for %c1048576], %2[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %2{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
    %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
    stream.yield %5 : !stream.resource<external>{%c2097152}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
    %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
    stream.yield %5 : !stream.resource<external>{%c2097152}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After PropagateTimepoints (iree-stream-propagate-timepoints) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.immediate => !stream.timepoint
    %5 = stream.timepoint.immediate => !stream.timepoint
    %6 = stream.timepoint.immediate => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%6) => with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %9 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %9 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %7 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %8 = stream.tensor.export %7 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
    %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
    stream.yield %5 : !stream.resource<external>{%c2097152}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
    %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
    stream.yield %5 : !stream.resource<external>{%c2097152}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
    %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
    stream.yield %5 : !stream.resource<external>{%c2097152}
  } => !stream.timepoint
  %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
  %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %5 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %5 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %5 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %5 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsync (iree-stream-verify-lowering-to-async) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) -> %2{%c2097152} {
      %5 = stream.async.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%arg3[%c0 to %c524288 for %c524288], %arg4[%c0 to %c1048576 for %c1048576], %arg5[%c0 to %c2097152 for %c2097152]) : (!stream.resource<external>{%c524288}, !stream.resource<external>{%c1048576}, !stream.resource<external>{%c2097152}) -> %arg5{%c2097152}
      stream.yield %5 : !stream.resource<external>{%c2097152}
    } => !stream.timepoint
    %3 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c2097152}
    %4 = stream.tensor.export %3 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocation (iree-stream-schedule-allocation) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %c0_0 = arith.constant 0 : index
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %c0_0 = arith.constant 0 : index
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After PackAllocations (iree-stream-pack-allocations) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %c0_0 = arith.constant 0 : index
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %c0_0 = arith.constant 0 : index
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0_0 = arith.constant 0 : index
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmd (iree-stream-verify-lowering-to-cmd) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepoints (iree-stream-elide-timepoints) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindings (iree-stream-fuse-dispatch-bindings) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index) {
        %c0 = arith.constant 0 : index
        %0 = arith.addi %c0, %arg3 : index
        %1 = stream.binding.subspan %arg0[%0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %2 = arith.addi %c0, %arg4 : index
        %3 = stream.binding.subspan %arg1[%2] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %4 = arith.addi %c0, %arg5 : index
        %5 = stream.binding.subspan %arg2[%4] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %6 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %7 = flow.dispatch.tensor.load %3, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %8 = flow.dispatch.tensor.load %5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %9 = linalg.matmul {compilation_info = #compilation} ins(%6, %7 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%8 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %9, %5, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0_0 = arith.constant 0 : index
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%c0, %c0, %c0 : index, index, index) {
        ro %arg3[%c0_0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0_0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0_0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperands (iree-stream-pack-dispatch-operands) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: i32, %arg4: i32, %arg5: i32) {
        %0 = arith.index_castui %arg3 : i32 to index
        %1 = arith.index_castui %arg4 : i32 to index
        %2 = arith.index_castui %arg5 : i32 to index
        %c0 = arith.constant 0 : index
        %3 = arith.addi %c0, %0 : index
        %4 = stream.binding.subspan %arg0[%3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %5 = arith.addi %c0, %1 : index
        %6 = stream.binding.subspan %arg1[%5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %7 = arith.addi %c0, %2 : index
        %8 = stream.binding.subspan %arg2[%7] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %9 = flow.dispatch.tensor.load %4, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %10 = flow.dispatch.tensor.load %6, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %11 = flow.dispatch.tensor.load %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %12 = linalg.matmul {compilation_info = #compilation} ins(%9, %10 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%11 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0_0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%c0_i32, %c0_i32_1, %c0_i32_2 : i32, i32, i32) {
        ro %arg3[%c0_0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0_0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0_0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: i32, %arg4: i32, %arg5: i32) {
        %0 = arith.index_castui %arg3 : i32 to index
        %1 = arith.index_castui %arg4 : i32 to index
        %2 = arith.index_castui %arg5 : i32 to index
        %c0 = arith.constant 0 : index
        %3 = arith.addi %c0, %0 : index
        %4 = stream.binding.subspan %arg0[%3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %5 = arith.addi %c0, %1 : index
        %6 = stream.binding.subspan %arg1[%5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %7 = arith.addi %c0, %2 : index
        %8 = stream.binding.subspan %arg2[%7] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %9 = flow.dispatch.tensor.load %4, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %10 = flow.dispatch.tensor.load %6, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %11 = flow.dispatch.tensor.load %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %12 = linalg.matmul {compilation_info = #compilation} ins(%9, %10 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%11 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1](%c0_i32, %c0_i32, %c0_i32 : i32, i32, i32) {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperands (iree-stream-fold-uniform-operands) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0_i32 = arith.constant 0 : i32
        %0 = arith.index_castui %c0_i32 : i32 to index
        %1 = arith.index_castui %c0_i32 : i32 to index
        %2 = arith.index_castui %c0_i32 : i32 to index
        %c0 = arith.constant 0 : index
        %3 = arith.addi %c0, %0 : index
        %4 = stream.binding.subspan %arg0[%3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %5 = arith.addi %c0, %1 : index
        %6 = stream.binding.subspan %arg1[%5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %7 = arith.addi %c0, %2 : index
        %8 = stream.binding.subspan %arg2[%7] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %9 = flow.dispatch.tensor.load %4, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %10 = flow.dispatch.tensor.load %6, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %11 = flow.dispatch.tensor.load %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %12 = linalg.matmul {compilation_info = #compilation} ins(%9, %10 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%11 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArguments (iree-stream-annotate-dispatch-arguments) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %0 = arith.index_castui %c0_i32 : i32 to index
        %1 = arith.index_castui %c0_i32 : i32 to index
        %2 = arith.index_castui %c0_i32 : i32 to index
        %c0 = arith.constant 0 : index
        %3 = arith.addi %c0, %0 : index
        %4 = stream.binding.subspan %arg0[%3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %5 = arith.addi %c0, %1 : index
        %6 = stream.binding.subspan %arg1[%5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %7 = arith.addi %c0, %2 : index
        %8 = stream.binding.subspan %arg2[%7] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %9 = flow.dispatch.tensor.load %4, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %10 = flow.dispatch.tensor.load %6, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %11 = flow.dispatch.tensor.load %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %12 = linalg.matmul {compilation_info = #compilation} ins(%9, %10 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%11 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After MemoizeChannels (iree-stream-memoize-channels) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %0 = arith.index_castui %c0_i32 : i32 to index
        %1 = arith.index_castui %c0_i32 : i32 to index
        %2 = arith.index_castui %c0_i32 : i32 to index
        %c0 = arith.constant 0 : index
        %3 = arith.addi %c0, %0 : index
        %4 = stream.binding.subspan %arg0[%3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %5 = arith.addi %c0, %1 : index
        %6 = stream.binding.subspan %arg1[%5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %7 = arith.addi %c0, %2 : index
        %8 = stream.binding.subspan %arg2[%7] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %9 = flow.dispatch.tensor.load %4, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %10 = flow.dispatch.tensor.load %6, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %11 = flow.dispatch.tensor.load %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %12 = linalg.matmul {compilation_info = #compilation} ins(%9, %10 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%11 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
  %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
    stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
      ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
      ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
      rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
  %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
module {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::VerifyTargetEnvironmentPass (iree-hal-verify-target-environment) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  stream.executable private @matmul_static_dispatch_0 {
    stream.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg0, %arg1, %arg2
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
        %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        return
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#compilation = #iree_codegen.compilation_info<lowering_config = #config, translation_info = #translation>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %x, %y, %z = flow.dispatch.workgroup_count_from_dag_root %arg1, %arg2, %arg3
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
          %c0 = arith.constant 0 : index
          %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
          %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
          %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
          %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
          %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
          %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
          %6 = linalg.matmul {compilation_info = #compilation} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
          flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
          return
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<512x256xf32> in !stream.resource<external>{%c524288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<256x1024xf32> in !stream.resource<external>{%c1048576}
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg2 : !hal.buffer_view -> tensor<512x1024xf32> in !stream.resource<external>{%c2097152}
    %3 = stream.cmd.execute with(%0 as %arg3: !stream.resource<external>{%c524288}, %1 as %arg4: !stream.resource<external>{%c1048576}, %2 as %arg5: !stream.resource<external>{%c2097152}) {
      stream.cmd.dispatch @matmul_static_dispatch_0::@matmul_static_dispatch_0_matmul_512x1024x256[%c512, %c1024, %c1] {
        ro %arg3[%c0 for %c524288] : !stream.resource<external>{%c524288},
        ro %arg4[%c0 for %c1048576] : !stream.resource<external>{%c1048576},
        rw %arg5[%c0 for %c2097152] : !stream.resource<external>{%c2097152}
      } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>]}
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %2 : !stream.resource<external>{%c2097152}
    %5 = stream.tensor.export %4 : tensor<512x1024xf32> in !stream.resource<external>{%c2097152} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLinalgTransformLegality (iree-llvmcpu-verify-linalg-transform-legality) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    return
  }
}

// -----// IR Dump After TypePropagation (iree-codegen-type-propagation) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
  %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
  %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
  %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  return
}

// -----// IR Dump After IREEMaterializeEncoding (iree-codegen-materialize-encoding) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
  %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
  %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
  %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  return
}

// -----// IR Dump After BufferizeCopyOnlyDispatches (iree-codegen-bufferize-copy-only-dispatches) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
    %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
    %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
    %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
    flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    return
  }
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRef (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %3 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [512, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<512x256xf32>
  %4 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [256, 1024], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x1024xf32>
  %5 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<512x1024xf32>
  %6 = linalg.matmul {compilation_info = #iree_codegen.compilation_info<lowering_config = <tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>, translation_info = <CPUDoubleTilingPadExpert>>} ins(%3, %4 : tensor<512x256xf32>, tensor<256x1024xf32>) outs(%5 : tensor<512x1024xf32>) -> tensor<512x1024xf32>
  flow.dispatch.tensor.store %6, %2, offsets = [0, 0], sizes = [512, 1024], strides = [1, 1] : tensor<512x1024xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  return
}

// -----// IR Dump After TileAndDistributeToWorkgroups (iree-codegen-tile-and-distribute-to-workgroups) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
  hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    hal.return %c32, %c16, %c1 : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
      %c32 = arith.constant 32 : index
      %c512 = arith.constant 512 : index
      %c1024 = arith.constant 1024 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
      %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %workgroup_count_y = hal.interface.workgroup.count[1] : index
      %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
      %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
      scf.for %arg0 = %3 to %c512 step %4 {
        %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
        %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
        scf.for %arg1 = %5 to %c1024 step %6 {
          %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%c32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<?x256xf32>
          %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, %c32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x?xf32>
          %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<?x?xf32>
          %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<?x256xf32>, tensor<256x?xf32>) outs(%9 : tensor<?x?xf32>) -> tensor<?x?xf32>
          flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
        }
      }
      return
    }
  }
}

// -----// IR Dump After ConvertToDestinationPassingStyle (iree-codegen-convert-to-destination-passing-style) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  scf.for %arg0 = %3 to %c512 step %4 {
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg1 = %5 to %c1024 step %6 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%c32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<?x256xf32>
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, %c32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x?xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<?x?xf32>
      %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<?x256xf32>, tensor<256x?xf32>) outs(%9 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After FoldAffineMinInDistributedLoops (iree-codegen-fold-affinemin-in-distributed-loops) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  scf.for %arg0 = %3 to %c512 step %4 {
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg1 = %5 to %c1024 step %6 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [%c32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<?x256xf32>
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, %c32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x?xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<?x?xf32>
      %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<?x256xf32>, tensor<256x?xf32>) outs(%9 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [%c32, %c32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    scf.for %arg0 = %3 to %c512 step %4 {
      %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
      %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
      scf.for %arg1 = %5 to %c1024 step %6 {
        %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
        %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
        %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
        %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%9 : tensor<32x32xf32>) -> tensor<32x32xf32>
        flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      }
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    scf.for %arg0 = %3 to %c512 step %4 {
      %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
      %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
      scf.for %arg1 = %5 to %c1024 step %6 {
        %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
        %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
        %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
        %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%9 : tensor<32x32xf32>) -> tensor<32x32xf32>
        flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      }
    }
    return
  }
}

// -----// IR Dump After TileAndDecomposeWinogradTransform (iree-linalg-ext-tile-and-decompose-winograd) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  scf.for %arg0 = %3 to %c512 step %4 {
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg1 = %5 to %c1024 step %6 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%7, %8 : tensor<32x256xf32>, tensor<256x32xf32>) outs(%9 : tensor<32x32xf32>) -> tensor<32x32xf32>
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyTileAndFusePass (iree-linalg-strategy-tile-and-fuse-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  scf.for %arg0 = %3 to %c512 step %4 {
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg1 = %5 to %c1024 step %6 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgFuse (linalg-fuse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyPadPass (iree-linalg-strategy-pad-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgFuse (linalg-fuse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyPadPass (iree-linalg-strategy-pad-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgFuse (linalg-fuse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyPadPass (iree-linalg-strategy-pad-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgFuse (linalg-fuse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice, %extracted_slice_0 : tensor<8x256xf32>, tensor<256x8xf32>) outs(%extracted_slice_1 : tensor<8x8xf32>) -> tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyTilePass (iree-linalg-strategy-tile-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgSingleTilingExpert (linalg-single-tiling-expert-driver) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyPadPass (iree-linalg-strategy-pad-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {__internal_linalg_transform__ = "1", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgFuse (linalg-fuse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
          %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
            %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
            %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
            %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
            scf.yield %13 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg0 = %3 to %c512 step %4 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
      scf.for %arg1 = %5 to %c1024 step %6 {
        %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
        %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
        %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %7[%arg2, 0] [8, 256] [1, 1] : tensor<32x256xf32> to tensor<8x256xf32>
          %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
            %extracted_slice_0 = tensor.extract_slice %8[0, %arg4] [256, 8] [1, 1] : tensor<256x32xf32> to tensor<256x8xf32>
            %extracted_slice_1 = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
            %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice_1) -> (tensor<8x8xf32>) {
              %extracted_slice_2 = tensor.extract_slice %extracted_slice[0, %arg6] [8, 8] [1, 1] : tensor<8x256xf32> to tensor<8x8xf32>
              %extracted_slice_3 = tensor.extract_slice %extracted_slice_0[%arg6, 0] [8, 8] [1, 1] : tensor<256x8xf32> to tensor<8x8xf32>
              %13 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 32], [8, 8, 0], [0, 0, 8]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<8x8xf32>, tensor<8x8xf32>) outs(%arg7 : tensor<8x8xf32>) -> tensor<8x8xf32>
              scf.yield %13 : tensor<8x8xf32>
            }
            %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
            scf.yield %inserted_slice : tensor<32x32xf32>
          }
          scf.yield %11 : tensor<32x32xf32>
        }
        flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      }
    }
    return
  }
}

// -----// IR Dump After LinalgStrategyVectorizePass (iree-linalg-strategy-vectorize-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %extracted_slice) -> (tensor<8x8xf32>) {
            %13 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %14 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %15 = vector.transfer_read %arg7[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
            %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %13, %14, %15 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            %17 = vector.transfer_write %16, %arg7[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
            scf.yield %17 : tensor<8x8xf32>
          }
          %inserted_slice = tensor.insert_slice %12 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After LinalgSingleTilingExpert (linalg-single-tiling-expert-driver) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %extracted_slice = tensor.extract_slice %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<32x32xf32> to tensor<8x8xf32>
          %12 = vector.transfer_read %extracted_slice[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<8x8xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %extracted_slice[%c0, %c0] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<8x8xf32>
          %inserted_slice = tensor.insert_slice %14 into %arg5[%arg2, %arg4] [8, 8] [1, 1] : tensor<8x8xf32> into tensor<32x32xf32>
          scf.yield %inserted_slice : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : tensor<32x32xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<32x32xf32>
          scf.yield %14 : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
      %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
        %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
          %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : tensor<32x32xf32>, vector<8x8xf32>
          %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
            %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
            %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
            %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %17 : vector<8x8xf32>
          }
          %14 = vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<32x32xf32>
          scf.yield %14 : tensor<32x32xf32>
        }
        scf.yield %11 : tensor<32x32xf32>
      }
      flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    }
  }
  return
}

// -----// IR Dump After EliminateEmptyTensors (iree-eliminate-empty-tensors) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant 0.000000e+00 : f32
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg0 = %3 to %c512 step %4 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
      scf.for %arg1 = %5 to %c1024 step %6 {
        %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
        %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
        %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
          %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
            %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : tensor<32x32xf32>, vector<8x8xf32>
            %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
              %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
              %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
              %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
              scf.yield %17 : vector<8x8xf32>
            }
            %14 = vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<32x32xf32>
            scf.yield %14 : tensor<32x32xf32>
          }
          scf.yield %11 : tensor<32x32xf32>
        }
        flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      }
    }
    return
  }
}

// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant 0.000000e+00 : f32
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg0 = %3 to %c512 step %4 {
      %7 = flow.dispatch.tensor.load %0, offsets = [%arg0, 0], sizes = [32, 256], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<512x256xf32>> -> tensor<32x256xf32>
      scf.for %arg1 = %5 to %c1024 step %6 {
        %8 = flow.dispatch.tensor.load %1, offsets = [0, %arg1], sizes = [256, 32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>> -> tensor<256x32xf32>
        %9 = flow.dispatch.tensor.load %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>> -> tensor<32x32xf32>
        %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %9) -> (tensor<32x32xf32>) {
          %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (tensor<32x32xf32>) {
            %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : tensor<32x32xf32>, vector<8x8xf32>
            %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
              %15 = vector.transfer_read %7[%arg2, %arg6], %cst {in_bounds = [true, true]} : tensor<32x256xf32>, vector<8x8xf32>
              %16 = vector.transfer_read %8[%arg6, %arg4], %cst {in_bounds = [true, true]} : tensor<256x32xf32>, vector<8x8xf32>
              %17 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %15, %16, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
              scf.yield %17 : vector<8x8xf32>
            }
            %14 = vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, tensor<32x32xf32>
            scf.yield %14 : tensor<32x32xf32>
          }
          scf.yield %11 : tensor<32x32xf32>
        }
        flow.dispatch.tensor.store %10, %2, offsets = [%arg0, %arg1], sizes = [32, 32], strides = [1, 1] : tensor<32x32xf32> -> !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
      }
    }
    return
  }
}

// -----// IR Dump After IREEComprehensiveBufferize (iree-codegen-iree-comprehensive-bufferize) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant 0.000000e+00 : f32
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %4, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
    %5 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %7 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    %8 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %9 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg0 = %6 to %c512 step %7 {
      %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg1 = %8 to %c1024 step %9 {
        %subview_0 = memref.subview %2[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_1 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %subview_1) -> (memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
          %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
            %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
              %14 = vector.transfer_read %subview[%arg2, %arg6], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
              %15 = vector.transfer_read %subview_0[%arg6, %arg4], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
              %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %14, %15, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
              scf.yield %16 : vector<8x8xf32>
            }
            vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
            scf.yield %arg5 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
          scf.yield %11 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
        %subview_2 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        ^bb0(%in: f32, %out: f32):
          linalg.yield %in : f32
        }
      }
    }
    return
  }
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant 0.000000e+00 : f32
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %4, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
    %5 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %workgroup_count_y = hal.interface.workgroup.count[1] : index
    %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %7 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
    %8 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %9 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
    scf.for %arg0 = %6 to %c512 step %7 {
      %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg1 = %8 to %c1024 step %9 {
        %subview_0 = memref.subview %2[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_1 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %10 = scf.for %arg2 = %c0 to %c32 step %c8 iter_args(%arg3 = %subview_1) -> (memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
          %11 = scf.for %arg4 = %c0 to %c32 step %c8 iter_args(%arg5 = %arg3) -> (memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
            %12 = vector.transfer_read %arg5[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %13 = scf.for %arg6 = %c0 to %c256 step %c8 iter_args(%arg7 = %12) -> (vector<8x8xf32>) {
              %14 = vector.transfer_read %subview[%arg2, %arg6], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
              %15 = vector.transfer_read %subview_0[%arg6, %arg4], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
              %16 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %14, %15, %arg7 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
              scf.yield %16 : vector<8x8xf32>
            }
            vector.transfer_write %13, %arg5[%arg2, %arg4] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
            scf.yield %arg5 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
          }
          scf.yield %11 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
        %subview_2 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%10 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
        ^bb0(%in: f32, %out: f32):
          linalg.yield %in : f32
        }
      }
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %4, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %7 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %8 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %9 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %6 to %c512 step %7 {
    %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %8 to %c1024 step %9 {
      %subview_0 = memref.subview %2[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg2 = %c0 to %c32 step %c8 {
        scf.for %arg3 = %c0 to %c32 step %c8 {
          %10 = vector.transfer_read %subview_1[%arg2, %arg3], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
          %11 = scf.for %arg4 = %c0 to %c256 step %c8 iter_args(%arg5 = %10) -> (vector<8x8xf32>) {
            %12 = vector.transfer_read %subview[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %13 = vector.transfer_read %subview_0[%arg4, %arg3], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %12, %13, %arg5 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %14 : vector<8x8xf32>
          }
          vector.transfer_write %11, %subview_1[%arg2, %arg3] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
      %subview_2 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview_1 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      }
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %4, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %7 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %8 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %9 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %6 to %c512 step %7 {
    %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %8 to %c1024 step %9 {
      %subview_0 = memref.subview %2[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg2 = %c0 to %c32 step %c8 {
        scf.for %arg3 = %c0 to %c32 step %c8 {
          %10 = vector.transfer_read %subview_1[%arg2, %arg3], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
          %11 = scf.for %arg4 = %c0 to %c256 step %c8 iter_args(%arg5 = %10) -> (vector<8x8xf32>) {
            %12 = vector.transfer_read %subview[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %13 = vector.transfer_read %subview_0[%arg4, %arg3], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %12, %13, %arg5 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %14 : vector<8x8xf32>
          }
          vector.transfer_write %11, %subview_1[%arg2, %arg3] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
      linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview_1 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_1 : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      }
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<512x256xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readonly:tensor<256x1024xf32>>
  %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %4, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  %5 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : !flow.dispatch.tensor<readwrite:tensor<512x1024xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %7 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %8 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %9 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %6 to %c512 step %7 {
    %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %8 to %c1024 step %9 {
      %subview_0 = memref.subview %2[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %4[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg2 = %c0 to %c32 step %c8 {
        scf.for %arg3 = %c0 to %c32 step %c8 {
          %10 = vector.transfer_read %subview_1[%arg2, %arg3], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
          %11 = scf.for %arg4 = %c0 to %c256 step %c8 iter_args(%arg5 = %10) -> (vector<8x8xf32>) {
            %12 = vector.transfer_read %subview[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %13 = vector.transfer_read %subview_0[%arg4, %arg3], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %14 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %12, %13, %arg5 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %14 : vector<8x8xf32>
          }
          vector.transfer_write %11, %subview_1[%arg2, %arg3] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  }
  return
}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<512x256xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32, #hal.descriptor_type<storage_buffer>> to memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %subview_0 = memref.subview %1[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %2[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32, #hal.descriptor_type<storage_buffer>> to memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.for %arg2 = %c0 to %c32 step %c8 {
        scf.for %arg3 = %c0 to %c32 step %c8 {
          %7 = vector.transfer_read %subview_1[%arg2, %arg3], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
          %8 = scf.for %arg4 = %c0 to %c256 step %c8 iter_args(%arg5 = %7) -> (vector<8x8xf32>) {
            %9 = vector.transfer_read %subview[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %10 = vector.transfer_read %subview_0[%arg4, %arg3], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<8x8xf32>
            %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %9, %10, %arg5 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %11 : vector<8x8xf32>
          }
          vector.transfer_write %8, %subview_1[%arg2, %arg3] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        }
      }
    }
  }
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRef (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %workgroup_count_y = hal.interface.workgroup.count[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_y]
  %5 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %6 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_count_x]
  scf.for %arg0 = %3 to %c512 step %4 {
    %subview = memref.subview %0[%arg0, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
    scf.for %arg1 = %5 to %c1024 step %6 {
      %subview_0 = memref.subview %1[0, %arg1] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
      %subview_1 = memref.subview %2[%arg0, %arg1] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
      scf.for %arg2 = %c0 to %c32 step %c8 {
        scf.for %arg3 = %c0 to %c32 step %c8 {
          %7 = vector.transfer_read %subview_1[%arg2, %arg3], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
          %8 = scf.for %arg4 = %c0 to %c256 step %c8 iter_args(%arg5 = %7) -> (vector<8x8xf32>) {
            %9 = vector.transfer_read %subview[%arg2, %arg4], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
            %10 = vector.transfer_read %subview_0[%arg4, %arg3], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
            %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %9, %10, %arg5 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
            scf.yield %11 : vector<8x8xf32>
          }
          vector.transfer_write %8, %subview_1[%arg2, %arg3] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
        }
      }
    }
  }
  return
}

// -----// IR Dump After RemoveSingleIterationLoop (iree-codegen-remove-single-iteration-loop) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %arg3 : vector<8x8xf32>, vector<8x8xf32> into vector<8x8xf32>
        scf.yield %9 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant 0.000000e+00 : f32
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.transfer_read %subview_1[%arg0, %arg1], %cst {in_bounds = [true, true]} : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
      %6 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %5) -> (vector<8x8xf32>) {
        %7 = vector.transfer_read %subview[%arg0, %arg2], %cst {in_bounds = [true, true]} : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8x8xf32>
        %8 = vector.transfer_read %subview_0[%arg2, %arg1], %cst {in_bounds = [true, true]} : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8x8xf32>
        %9 = vector.transpose %7, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %10 = vector.extract %9[0] : vector<8x8xf32>
        %11 = vector.extract %8[0] : vector<8x8xf32>
        %12 = vector.outerproduct %10, %11, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %13 = vector.extract %9[1] : vector<8x8xf32>
        %14 = vector.extract %8[1] : vector<8x8xf32>
        %15 = vector.outerproduct %13, %14, %12 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %16 = vector.extract %9[2] : vector<8x8xf32>
        %17 = vector.extract %8[2] : vector<8x8xf32>
        %18 = vector.outerproduct %16, %17, %15 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %19 = vector.extract %9[3] : vector<8x8xf32>
        %20 = vector.extract %8[3] : vector<8x8xf32>
        %21 = vector.outerproduct %19, %20, %18 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %22 = vector.extract %9[4] : vector<8x8xf32>
        %23 = vector.extract %8[4] : vector<8x8xf32>
        %24 = vector.outerproduct %22, %23, %21 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %25 = vector.extract %9[5] : vector<8x8xf32>
        %26 = vector.extract %8[5] : vector<8x8xf32>
        %27 = vector.outerproduct %25, %26, %24 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %28 = vector.extract %9[6] : vector<8x8xf32>
        %29 = vector.extract %8[6] : vector<8x8xf32>
        %30 = vector.outerproduct %28, %29, %27 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %31 = vector.extract %9[7] : vector<8x8xf32>
        %32 = vector.extract %8[7] : vector<8x8xf32>
        %33 = vector.outerproduct %31, %32, %30 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %33 : vector<8x8xf32>
      }
      vector.transfer_write %6, %subview_1[%arg0, %arg1] {in_bounds = [true, true]} : vector<8x8xf32>, memref<32x32xf32, strided<[1024, 1], offset: ?>>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %5 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %6 = vector.insert %5, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %7 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
      %8 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %9 = vector.insert %8, %6 [1] : vector<8xf32> into vector<8x8xf32>
      %10 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
      %11 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %12 = vector.insert %11, %9 [2] : vector<8xf32> into vector<8x8xf32>
      %13 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
      %14 = vector.load %subview_1[%13, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %12 [3] : vector<8xf32> into vector<8x8xf32>
      %16 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
      %17 = vector.load %subview_1[%16, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %18 = vector.insert %17, %15 [4] : vector<8xf32> into vector<8x8xf32>
      %19 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
      %20 = vector.load %subview_1[%19, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %18 [5] : vector<8xf32> into vector<8x8xf32>
      %22 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
      %23 = vector.load %subview_1[%22, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %24 = vector.insert %23, %21 [6] : vector<8xf32> into vector<8x8xf32>
      %25 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
      %26 = vector.load %subview_1[%25, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %24 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %44 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.insert %44, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
        %47 = vector.load %subview[%46, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %45 [1] : vector<8xf32> into vector<8x8xf32>
        %49 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
        %50 = vector.load %subview[%49, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %51 = vector.insert %50, %48 [2] : vector<8xf32> into vector<8x8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
        %53 = vector.load %subview[%52, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %54 = vector.insert %53, %51 [3] : vector<8xf32> into vector<8x8xf32>
        %55 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
        %56 = vector.load %subview[%55, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %57 = vector.insert %56, %54 [4] : vector<8xf32> into vector<8x8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
        %59 = vector.load %subview[%58, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert %59, %57 [5] : vector<8xf32> into vector<8x8xf32>
        %61 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
        %62 = vector.load %subview[%61, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %63 = vector.insert %62, %60 [6] : vector<8xf32> into vector<8x8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
        %65 = vector.load %subview[%64, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %66 = vector.insert %65, %63 [7] : vector<8xf32> into vector<8x8xf32>
        %67 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %69 = vector.load %subview_0[%68, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %70 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %71 = vector.load %subview_0[%70, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %72 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %73 = vector.load %subview_0[%72, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %74 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %75 = vector.load %subview_0[%74, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %76 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %77 = vector.load %subview_0[%76, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %78 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %79 = vector.load %subview_0[%78, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %80 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %81 = vector.load %subview_0[%80, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %82 = vector.transpose %66, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %83 = vector.extract %82[0] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %82[1] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %69, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %87 = vector.extract %82[2] : vector<8x8xf32>
        %88 = vector.outerproduct %87, %71, %86 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %89 = vector.extract %82[3] : vector<8x8xf32>
        %90 = vector.outerproduct %89, %73, %88 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %91 = vector.extract %82[4] : vector<8x8xf32>
        %92 = vector.outerproduct %91, %75, %90 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %93 = vector.extract %82[5] : vector<8x8xf32>
        %94 = vector.outerproduct %93, %77, %92 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %95 = vector.extract %82[6] : vector<8x8xf32>
        %96 = vector.outerproduct %95, %79, %94 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %97 = vector.extract %82[7] : vector<8x8xf32>
        %98 = vector.outerproduct %97, %81, %96 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %98 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
      %31 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %31, %subview_1[%30, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
      %33 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %33, %subview_1[%32, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
      %35 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %35, %subview_1[%34, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
      %37 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %37, %subview_1[%36, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %38 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
      %39 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %39, %subview_1[%38, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %40 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
      %41 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %41, %subview_1[%40, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %42 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
      %43 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %43, %subview_1[%42, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.transpose %52, [1, 0] : vector<8x8xf32> to vector<8x8xf32>
        %69 = vector.extract %68[0] : vector<8x8xf32>
        %70 = vector.outerproduct %69, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %71 = vector.extract %68[1] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %55, %70 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %68[2] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %57, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %68[3] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %59, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %68[4] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %61, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %68[5] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %63, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %68[6] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %65, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %68[7] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %67, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_0 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_1 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.insert %37, %cst [0] : vector<8xf32> into vector<8x8xf32>
        %39 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.insert %39, %38 [1] : vector<8xf32> into vector<8x8xf32>
        %41 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.insert %41, %40 [2] : vector<8xf32> into vector<8x8xf32>
        %43 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.insert %43, %42 [3] : vector<8xf32> into vector<8x8xf32>
        %45 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %46 = vector.insert %45, %44 [4] : vector<8xf32> into vector<8x8xf32>
        %47 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %48 = vector.insert %47, %46 [5] : vector<8xf32> into vector<8x8xf32>
        %49 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %50 = vector.insert %49, %48 [6] : vector<8xf32> into vector<8x8xf32>
        %51 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %52 = vector.insert %51, %50 [7] : vector<8xf32> into vector<8x8xf32>
        %53 = vector.load %subview_0[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %55 = vector.load %subview_0[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %57 = vector.load %subview_0[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %59 = vector.load %subview_0[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %61 = vector.load %subview_0[%60, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %62 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %63 = vector.load %subview_0[%62, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %64 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %65 = vector.load %subview_0[%64, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %66 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %67 = vector.load %subview_0[%66, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %68 = vector.shape_cast %52 : vector<8x8xf32> to vector<64xf32>
        %69 = vector.shuffle %68, %68 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %70 = vector.shape_cast %69 : vector<64xf32> to vector<8x8xf32>
        %71 = vector.extract %70[0] : vector<8x8xf32>
        %72 = vector.outerproduct %71, %53, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %73 = vector.extract %70[1] : vector<8x8xf32>
        %74 = vector.outerproduct %73, %55, %72 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %75 = vector.extract %70[2] : vector<8x8xf32>
        %76 = vector.outerproduct %75, %57, %74 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %77 = vector.extract %70[3] : vector<8x8xf32>
        %78 = vector.outerproduct %77, %59, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.extract %70[4] : vector<8x8xf32>
        %80 = vector.outerproduct %79, %61, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.extract %70[5] : vector<8x8xf32>
        %82 = vector.outerproduct %81, %63, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.extract %70[6] : vector<8x8xf32>
        %84 = vector.outerproduct %83, %65, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %85 = vector.extract %70[7] : vector<8x8xf32>
        %86 = vector.outerproduct %85, %67, %84 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %86 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_1[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_1[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_1[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_1[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_1[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_1[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_1[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_1[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyLowerVectorsPass (iree-linalg-strategy-lower-vectors-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyRemoveMarkersPass (iree-linalg-strategy-remove-markers-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgStrategyEnablePass (iree-linalg-strategy-enable-pass) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgVectorLowering (linalg-vector-lowering) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LLVMCPULowerExecutableTarget (iree-llvmcpu-lower-executable-target) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
  hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    hal.return %c32, %c16, %c1 : index, index, index
  }
  builtin.module {
    func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
      %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
      %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
      %c256 = arith.constant 256 : index
      %c8 = arith.constant 8 : index
      %c32 = arith.constant 32 : index
      %c0 = arith.constant 0 : index
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
      memref.assume_alignment %0, 64 : memref<512x256xf32>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
      memref.assume_alignment %1, 64 : memref<256x1024xf32>
      %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
      memref.assume_alignment %2, 64 : memref<512x1024xf32>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_id_y = hal.interface.workgroup.id[1] : index
      %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
      %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
      %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
      %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
      %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
      scf.for %arg0 = %c0 to %c32 step %c8 {
        %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
        %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
        %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
        %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
        %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
        %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
        %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
        scf.for %arg1 = %c0 to %c32 step %c8 {
          %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
          %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
          %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
          %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
          %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
          %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
          %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
          %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
          %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
            %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
            %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
            %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
            %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
            %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
            %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
            %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
            %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
            %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
            %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
            %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
            %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
            %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
            %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
            %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
            %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
            %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
            %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
            %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
            %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
            scf.yield %84 : vector<8x8xf32>
          }
          %29 = vector.extract %28[0] : vector<8x8xf32>
          vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %30 = vector.extract %28[1] : vector<8x8xf32>
          vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %31 = vector.extract %28[2] : vector<8x8xf32>
          vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %32 = vector.extract %28[3] : vector<8x8xf32>
          vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %33 = vector.extract %28[4] : vector<8x8xf32>
          vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %34 = vector.extract %28[5] : vector<8x8xf32>
          vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %35 = vector.extract %28[6] : vector<8x8xf32>
          vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %36 = vector.extract %28[7] : vector<8x8xf32>
          vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        }
      }
      return
    }
  }
}

// -----// IR Dump After LinalgExtToLoops (iree-linalg-ext-to-loops) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After ArithBufferize (arith-bufferize) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
    memref.assume_alignment %0, 64 : memref<512x256xf32>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
    memref.assume_alignment %1, 64 : memref<256x1024xf32>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
    memref.assume_alignment %2, 64 : memref<512x1024xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
    %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
    %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c32 step %c8 {
      %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
      %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
      %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
      %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
      %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
      %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
      %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
      scf.for %arg1 = %c0 to %c32 step %c8 {
        %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
        %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
        %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
        %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
        %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
        %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
        %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
        %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
        %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
          %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
          %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
          %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
          %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
          %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
          %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
          %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
          %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
          %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
          %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
          %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
          %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
          %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
          %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
          %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
          %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
          %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          scf.yield %84 : vector<8x8xf32>
        }
        %29 = vector.extract %28[0] : vector<8x8xf32>
        vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %30 = vector.extract %28[1] : vector<8x8xf32>
        vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %31 = vector.extract %28[2] : vector<8x8xf32>
        vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %32 = vector.extract %28[3] : vector<8x8xf32>
        vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %33 = vector.extract %28[4] : vector<8x8xf32>
        vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %34 = vector.extract %28[5] : vector<8x8xf32>
        vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %35 = vector.extract %28[6] : vector<8x8xf32>
        vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %36 = vector.extract %28[7] : vector<8x8xf32>
        vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      }
    }
    return
  }
}

// -----// IR Dump After FoldTensorExtractOp (iree-codegen-fold-tensor-extract-op) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
    memref.assume_alignment %0, 64 : memref<512x256xf32>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
    memref.assume_alignment %1, 64 : memref<256x1024xf32>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
    memref.assume_alignment %2, 64 : memref<512x1024xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
    %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
    %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c32 step %c8 {
      %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
      %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
      %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
      %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
      %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
      %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
      %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
      scf.for %arg1 = %c0 to %c32 step %c8 {
        %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
        %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
        %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
        %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
        %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
        %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
        %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
        %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
        %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
          %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
          %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
          %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
          %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
          %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
          %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
          %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
          %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
          %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
          %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
          %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
          %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
          %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
          %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
          %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
          %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
          %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          scf.yield %84 : vector<8x8xf32>
        }
        %29 = vector.extract %28[0] : vector<8x8xf32>
        vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %30 = vector.extract %28[1] : vector<8x8xf32>
        vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %31 = vector.extract %28[2] : vector<8x8xf32>
        vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %32 = vector.extract %28[3] : vector<8x8xf32>
        vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %33 = vector.extract %28[4] : vector<8x8xf32>
        vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %34 = vector.extract %28[5] : vector<8x8xf32>
        vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %35 = vector.extract %28[6] : vector<8x8xf32>
        vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %36 = vector.extract %28[7] : vector<8x8xf32>
        vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      }
    }
    return
  }
}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  scf.for %arg0 = %c0 to %c32 step %c8 {
    %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
    %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
    %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
    %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
    %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
    %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
    %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
    scf.for %arg1 = %c0 to %c32 step %c8 {
      %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
      %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
      %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
      %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
      %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
      %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
      %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
      %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
      %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
        %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
        %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
        %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
        %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
        %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
        %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
        %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
        %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
        %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
        %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
        %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
        %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
        %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
        %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
        %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
        %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
        %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
        %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
        %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
        scf.yield %84 : vector<8x8xf32>
      }
      %29 = vector.extract %28[0] : vector<8x8xf32>
      vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %30 = vector.extract %28[1] : vector<8x8xf32>
      vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %31 = vector.extract %28[2] : vector<8x8xf32>
      vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %32 = vector.extract %28[3] : vector<8x8xf32>
      vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %33 = vector.extract %28[4] : vector<8x8xf32>
      vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %34 = vector.extract %28[5] : vector<8x8xf32>
      vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %35 = vector.extract %28[6] : vector<8x8xf32>
      vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      %36 = vector.extract %28[7] : vector<8x8xf32>
      vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
    }
  }
  return
}

// -----// IR Dump After LLVMCPUCheckIRBeforeLLVMConversion (iree-llvmcpu-check-ir-before-llvm-conversion) //----- //
module {
  func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
    %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
    memref.assume_alignment %0, 64 : memref<512x256xf32>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
    memref.assume_alignment %1, 64 : memref<256x1024xf32>
    %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
    memref.assume_alignment %2, 64 : memref<512x1024xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_id_y = hal.interface.workgroup.id[1] : index
    %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
    %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
    %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
    %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
    %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
    scf.for %arg0 = %c0 to %c32 step %c8 {
      %5 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg0)
      %6 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg0)
      %7 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg0)
      %8 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg0)
      %9 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg0)
      %10 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg0)
      %11 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg0)
      scf.for %arg1 = %c0 to %c32 step %c8 {
        %12 = vector.load %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %13 = vector.insert %12, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
        %14 = vector.load %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %15 = vector.insert %14, %13 [1] : vector<8xf32> into vector<8x8xf32>
        %16 = vector.load %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %17 = vector.insert %16, %15 [2] : vector<8xf32> into vector<8x8xf32>
        %18 = vector.load %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %19 = vector.insert %18, %17 [3] : vector<8xf32> into vector<8x8xf32>
        %20 = vector.load %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %21 = vector.insert %20, %19 [4] : vector<8xf32> into vector<8x8xf32>
        %22 = vector.load %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %23 = vector.insert %22, %21 [5] : vector<8xf32> into vector<8x8xf32>
        %24 = vector.load %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %25 = vector.insert %24, %23 [6] : vector<8xf32> into vector<8x8xf32>
        %26 = vector.load %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %27 = vector.insert %26, %25 [7] : vector<8xf32> into vector<8x8xf32>
        %28 = scf.for %arg2 = %c0 to %c256 step %c8 iter_args(%arg3 = %27) -> (vector<8x8xf32>) {
          %37 = vector.load %subview[%arg0, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %38 = vector.load %subview[%5, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %39 = vector.load %subview[%6, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %40 = vector.load %subview[%7, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %41 = vector.load %subview[%8, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %42 = vector.load %subview[%9, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %43 = vector.load %subview[%10, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %44 = vector.load %subview[%11, %arg2] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
          %45 = vector.load %subview_1[%arg2, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %46 = affine.apply affine_map<(d0) -> (d0 + 1)>(%arg2)
          %47 = vector.load %subview_1[%46, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %48 = affine.apply affine_map<(d0) -> (d0 + 2)>(%arg2)
          %49 = vector.load %subview_1[%48, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %50 = affine.apply affine_map<(d0) -> (d0 + 3)>(%arg2)
          %51 = vector.load %subview_1[%50, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %52 = affine.apply affine_map<(d0) -> (d0 + 4)>(%arg2)
          %53 = vector.load %subview_1[%52, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %54 = affine.apply affine_map<(d0) -> (d0 + 5)>(%arg2)
          %55 = vector.load %subview_1[%54, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %56 = affine.apply affine_map<(d0) -> (d0 + 6)>(%arg2)
          %57 = vector.load %subview_1[%56, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %58 = affine.apply affine_map<(d0) -> (d0 + 7)>(%arg2)
          %59 = vector.load %subview_1[%58, %arg1] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
          %60 = vector.insert_strided_slice %37, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
          %61 = vector.insert_strided_slice %38, %60 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
          %62 = vector.insert_strided_slice %39, %61 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
          %63 = vector.insert_strided_slice %40, %62 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
          %64 = vector.insert_strided_slice %41, %63 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
          %65 = vector.insert_strided_slice %42, %64 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
          %66 = vector.insert_strided_slice %43, %65 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
          %67 = vector.insert_strided_slice %44, %66 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
          %68 = vector.shuffle %67, %67 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
          %69 = vector.extract_strided_slice %68 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %70 = vector.extract_strided_slice %68 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %71 = vector.extract_strided_slice %68 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %72 = vector.extract_strided_slice %68 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %73 = vector.extract_strided_slice %68 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %74 = vector.extract_strided_slice %68 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %75 = vector.extract_strided_slice %68 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %76 = vector.extract_strided_slice %68 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
          %77 = vector.outerproduct %69, %45, %arg3 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %78 = vector.outerproduct %70, %47, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %79 = vector.outerproduct %71, %49, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %80 = vector.outerproduct %72, %51, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %81 = vector.outerproduct %73, %53, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %82 = vector.outerproduct %74, %55, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %83 = vector.outerproduct %75, %57, %82 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          %84 = vector.outerproduct %76, %59, %83 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
          scf.yield %84 : vector<8x8xf32>
        }
        %29 = vector.extract %28[0] : vector<8x8xf32>
        vector.store %29, %subview_2[%arg0, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %30 = vector.extract %28[1] : vector<8x8xf32>
        vector.store %30, %subview_2[%5, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %31 = vector.extract %28[2] : vector<8x8xf32>
        vector.store %31, %subview_2[%6, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %32 = vector.extract %28[3] : vector<8x8xf32>
        vector.store %32, %subview_2[%7, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %33 = vector.extract %28[4] : vector<8x8xf32>
        vector.store %33, %subview_2[%8, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %34 = vector.extract %28[5] : vector<8x8xf32>
        vector.store %34, %subview_2[%9, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %35 = vector.extract %28[6] : vector<8x8xf32>
        vector.store %35, %subview_2[%10, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
        %36 = vector.extract %28[7] : vector<8x8xf32>
        vector.store %36, %subview_2[%11, %arg1] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
      }
    }
    return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb8
  %6 = arith.cmpi slt, %5, %c32 : index
  cf.cond_br %6, ^bb2, ^bb9
^bb2:  // pred: ^bb1
  %7 = affine.apply affine_map<(d0) -> (d0 + 1)>(%5)
  %8 = affine.apply affine_map<(d0) -> (d0 + 2)>(%5)
  %9 = affine.apply affine_map<(d0) -> (d0 + 3)>(%5)
  %10 = affine.apply affine_map<(d0) -> (d0 + 4)>(%5)
  %11 = affine.apply affine_map<(d0) -> (d0 + 5)>(%5)
  %12 = affine.apply affine_map<(d0) -> (d0 + 6)>(%5)
  %13 = affine.apply affine_map<(d0) -> (d0 + 7)>(%5)
  cf.br ^bb3(%c0 : index)
^bb3(%14: index):  // 2 preds: ^bb2, ^bb7
  %15 = arith.cmpi slt, %14, %c32 : index
  cf.cond_br %15, ^bb4, ^bb8
^bb4:  // pred: ^bb3
  %16 = vector.load %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %17 = vector.insert %16, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
  %18 = vector.load %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %19 = vector.insert %18, %17 [1] : vector<8xf32> into vector<8x8xf32>
  %20 = vector.load %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %21 = vector.insert %20, %19 [2] : vector<8xf32> into vector<8x8xf32>
  %22 = vector.load %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %23 = vector.insert %22, %21 [3] : vector<8xf32> into vector<8x8xf32>
  %24 = vector.load %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %25 = vector.insert %24, %23 [4] : vector<8xf32> into vector<8x8xf32>
  %26 = vector.load %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %27 = vector.insert %26, %25 [5] : vector<8xf32> into vector<8x8xf32>
  %28 = vector.load %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %29 = vector.insert %28, %27 [6] : vector<8xf32> into vector<8x8xf32>
  %30 = vector.load %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %31 = vector.insert %30, %29 [7] : vector<8xf32> into vector<8x8xf32>
  cf.br ^bb5(%c0, %31 : index, vector<8x8xf32>)
^bb5(%32: index, %33: vector<8x8xf32>):  // 2 preds: ^bb4, ^bb6
  %34 = arith.cmpi slt, %32, %c256 : index
  cf.cond_br %34, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %35 = vector.load %subview[%5, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %36 = vector.load %subview[%7, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %37 = vector.load %subview[%8, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %38 = vector.load %subview[%9, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %39 = vector.load %subview[%10, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %40 = vector.load %subview[%11, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %41 = vector.load %subview[%12, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %42 = vector.load %subview[%13, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %43 = vector.load %subview_1[%32, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %44 = affine.apply affine_map<(d0) -> (d0 + 1)>(%32)
  %45 = vector.load %subview_1[%44, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %46 = affine.apply affine_map<(d0) -> (d0 + 2)>(%32)
  %47 = vector.load %subview_1[%46, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %48 = affine.apply affine_map<(d0) -> (d0 + 3)>(%32)
  %49 = vector.load %subview_1[%48, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %50 = affine.apply affine_map<(d0) -> (d0 + 4)>(%32)
  %51 = vector.load %subview_1[%50, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %52 = affine.apply affine_map<(d0) -> (d0 + 5)>(%32)
  %53 = vector.load %subview_1[%52, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %54 = affine.apply affine_map<(d0) -> (d0 + 6)>(%32)
  %55 = vector.load %subview_1[%54, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %56 = affine.apply affine_map<(d0) -> (d0 + 7)>(%32)
  %57 = vector.load %subview_1[%56, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %58 = vector.insert_strided_slice %35, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
  %59 = vector.insert_strided_slice %36, %58 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
  %60 = vector.insert_strided_slice %37, %59 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
  %61 = vector.insert_strided_slice %38, %60 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
  %62 = vector.insert_strided_slice %39, %61 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
  %63 = vector.insert_strided_slice %40, %62 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
  %64 = vector.insert_strided_slice %41, %63 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
  %65 = vector.insert_strided_slice %42, %64 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
  %66 = vector.shuffle %65, %65 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
  %67 = vector.extract_strided_slice %66 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %68 = vector.extract_strided_slice %66 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %69 = vector.extract_strided_slice %66 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %70 = vector.extract_strided_slice %66 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %71 = vector.extract_strided_slice %66 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %72 = vector.extract_strided_slice %66 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %73 = vector.extract_strided_slice %66 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %74 = vector.extract_strided_slice %66 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %75 = vector.outerproduct %67, %43, %33 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %76 = vector.outerproduct %68, %45, %75 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %77 = vector.outerproduct %69, %47, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %78 = vector.outerproduct %70, %49, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %79 = vector.outerproduct %71, %51, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %80 = vector.outerproduct %72, %53, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %81 = vector.outerproduct %73, %55, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %82 = vector.outerproduct %74, %57, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %83 = arith.addi %32, %c8 : index
  cf.br ^bb5(%83, %82 : index, vector<8x8xf32>)
^bb7:  // pred: ^bb5
  %84 = vector.extract %33[0] : vector<8x8xf32>
  vector.store %84, %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %85 = vector.extract %33[1] : vector<8x8xf32>
  vector.store %85, %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %86 = vector.extract %33[2] : vector<8x8xf32>
  vector.store %86, %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %87 = vector.extract %33[3] : vector<8x8xf32>
  vector.store %87, %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %88 = vector.extract %33[4] : vector<8x8xf32>
  vector.store %88, %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %89 = vector.extract %33[5] : vector<8x8xf32>
  vector.store %89, %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %90 = vector.extract %33[6] : vector<8x8xf32>
  vector.store %90, %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %91 = vector.extract %33[7] : vector<8x8xf32>
  vector.store %91, %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %92 = arith.addi %14, %c8 : index
  cf.br ^bb3(%92 : index)
^bb8:  // pred: ^bb3
  %93 = arith.addi %5, %c8 : index
  cf.br ^bb1(%93 : index)
^bb9:  // pred: ^bb1
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb8
  %6 = arith.cmpi slt, %5, %c32 : index
  cf.cond_br %6, ^bb2, ^bb9
^bb2:  // pred: ^bb1
  %7 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%5]
  %8 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%5]
  %9 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%5]
  %10 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%5]
  %11 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%5]
  %12 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%5]
  %13 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%5]
  cf.br ^bb3(%c0 : index)
^bb3(%14: index):  // 2 preds: ^bb2, ^bb7
  %15 = arith.cmpi slt, %14, %c32 : index
  cf.cond_br %15, ^bb4, ^bb8
^bb4:  // pred: ^bb3
  %16 = vector.load %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %17 = vector.insert %16, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
  %18 = vector.load %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %19 = vector.insert %18, %17 [1] : vector<8xf32> into vector<8x8xf32>
  %20 = vector.load %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %21 = vector.insert %20, %19 [2] : vector<8xf32> into vector<8x8xf32>
  %22 = vector.load %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %23 = vector.insert %22, %21 [3] : vector<8xf32> into vector<8x8xf32>
  %24 = vector.load %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %25 = vector.insert %24, %23 [4] : vector<8xf32> into vector<8x8xf32>
  %26 = vector.load %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %27 = vector.insert %26, %25 [5] : vector<8xf32> into vector<8x8xf32>
  %28 = vector.load %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %29 = vector.insert %28, %27 [6] : vector<8xf32> into vector<8x8xf32>
  %30 = vector.load %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %31 = vector.insert %30, %29 [7] : vector<8xf32> into vector<8x8xf32>
  cf.br ^bb5(%c0, %31 : index, vector<8x8xf32>)
^bb5(%32: index, %33: vector<8x8xf32>):  // 2 preds: ^bb4, ^bb6
  %34 = arith.cmpi slt, %32, %c256 : index
  cf.cond_br %34, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %35 = vector.load %subview[%5, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %36 = vector.load %subview[%7, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %37 = vector.load %subview[%8, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %38 = vector.load %subview[%9, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %39 = vector.load %subview[%10, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %40 = vector.load %subview[%11, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %41 = vector.load %subview[%12, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %42 = vector.load %subview[%13, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %43 = vector.load %subview_1[%32, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %44 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%32]
  %45 = vector.load %subview_1[%44, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %46 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%32]
  %47 = vector.load %subview_1[%46, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %48 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%32]
  %49 = vector.load %subview_1[%48, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %50 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%32]
  %51 = vector.load %subview_1[%50, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %52 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%32]
  %53 = vector.load %subview_1[%52, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %54 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%32]
  %55 = vector.load %subview_1[%54, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %56 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%32]
  %57 = vector.load %subview_1[%56, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %58 = vector.insert_strided_slice %35, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
  %59 = vector.insert_strided_slice %36, %58 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
  %60 = vector.insert_strided_slice %37, %59 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
  %61 = vector.insert_strided_slice %38, %60 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
  %62 = vector.insert_strided_slice %39, %61 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
  %63 = vector.insert_strided_slice %40, %62 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
  %64 = vector.insert_strided_slice %41, %63 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
  %65 = vector.insert_strided_slice %42, %64 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
  %66 = vector.shuffle %65, %65 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
  %67 = vector.extract_strided_slice %66 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %68 = vector.extract_strided_slice %66 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %69 = vector.extract_strided_slice %66 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %70 = vector.extract_strided_slice %66 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %71 = vector.extract_strided_slice %66 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %72 = vector.extract_strided_slice %66 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %73 = vector.extract_strided_slice %66 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %74 = vector.extract_strided_slice %66 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %75 = vector.outerproduct %67, %43, %33 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %76 = vector.outerproduct %68, %45, %75 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %77 = vector.outerproduct %69, %47, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %78 = vector.outerproduct %70, %49, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %79 = vector.outerproduct %71, %51, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %80 = vector.outerproduct %72, %53, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %81 = vector.outerproduct %73, %55, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %82 = vector.outerproduct %74, %57, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %83 = arith.addi %32, %c8 : index
  cf.br ^bb5(%83, %82 : index, vector<8x8xf32>)
^bb7:  // pred: ^bb5
  %84 = vector.extract %33[0] : vector<8x8xf32>
  vector.store %84, %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %85 = vector.extract %33[1] : vector<8x8xf32>
  vector.store %85, %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %86 = vector.extract %33[2] : vector<8x8xf32>
  vector.store %86, %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %87 = vector.extract %33[3] : vector<8x8xf32>
  vector.store %87, %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %88 = vector.extract %33[4] : vector<8x8xf32>
  vector.store %88, %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %89 = vector.extract %33[5] : vector<8x8xf32>
  vector.store %89, %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %90 = vector.extract %33[6] : vector<8x8xf32>
  vector.store %90, %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %91 = vector.extract %33[7] : vector<8x8xf32>
  vector.store %91, %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %92 = arith.addi %14, %c8 : index
  cf.br ^bb3(%92 : index)
^bb8:  // pred: ^bb3
  %93 = arith.addi %5, %c8 : index
  cf.br ^bb1(%93 : index)
^bb9:  // pred: ^bb1
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb8
  %6 = arith.cmpi slt, %5, %c32 : index
  cf.cond_br %6, ^bb2, ^bb9
^bb2:  // pred: ^bb1
  %7 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%5]
  %8 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%5]
  %9 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%5]
  %10 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%5]
  %11 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%5]
  %12 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%5]
  %13 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%5]
  cf.br ^bb3(%c0 : index)
^bb3(%14: index):  // 2 preds: ^bb2, ^bb7
  %15 = arith.cmpi slt, %14, %c32 : index
  cf.cond_br %15, ^bb4, ^bb8
^bb4:  // pred: ^bb3
  %16 = vector.load %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %17 = vector.insert %16, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
  %18 = vector.load %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %19 = vector.insert %18, %17 [1] : vector<8xf32> into vector<8x8xf32>
  %20 = vector.load %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %21 = vector.insert %20, %19 [2] : vector<8xf32> into vector<8x8xf32>
  %22 = vector.load %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %23 = vector.insert %22, %21 [3] : vector<8xf32> into vector<8x8xf32>
  %24 = vector.load %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %25 = vector.insert %24, %23 [4] : vector<8xf32> into vector<8x8xf32>
  %26 = vector.load %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %27 = vector.insert %26, %25 [5] : vector<8xf32> into vector<8x8xf32>
  %28 = vector.load %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %29 = vector.insert %28, %27 [6] : vector<8xf32> into vector<8x8xf32>
  %30 = vector.load %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %31 = vector.insert %30, %29 [7] : vector<8xf32> into vector<8x8xf32>
  cf.br ^bb5(%c0, %31 : index, vector<8x8xf32>)
^bb5(%32: index, %33: vector<8x8xf32>):  // 2 preds: ^bb4, ^bb6
  %34 = arith.cmpi slt, %32, %c256 : index
  cf.cond_br %34, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %35 = vector.load %subview[%5, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %36 = vector.load %subview[%7, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %37 = vector.load %subview[%8, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %38 = vector.load %subview[%9, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %39 = vector.load %subview[%10, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %40 = vector.load %subview[%11, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %41 = vector.load %subview[%12, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %42 = vector.load %subview[%13, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %43 = vector.load %subview_1[%32, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %44 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%32]
  %45 = vector.load %subview_1[%44, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %46 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%32]
  %47 = vector.load %subview_1[%46, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %48 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%32]
  %49 = vector.load %subview_1[%48, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %50 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%32]
  %51 = vector.load %subview_1[%50, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %52 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%32]
  %53 = vector.load %subview_1[%52, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %54 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%32]
  %55 = vector.load %subview_1[%54, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %56 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%32]
  %57 = vector.load %subview_1[%56, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %58 = vector.insert_strided_slice %35, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
  %59 = vector.insert_strided_slice %36, %58 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
  %60 = vector.insert_strided_slice %37, %59 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
  %61 = vector.insert_strided_slice %38, %60 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
  %62 = vector.insert_strided_slice %39, %61 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
  %63 = vector.insert_strided_slice %40, %62 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
  %64 = vector.insert_strided_slice %41, %63 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
  %65 = vector.insert_strided_slice %42, %64 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
  %66 = vector.shuffle %65, %65 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
  %67 = vector.extract_strided_slice %66 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %68 = vector.extract_strided_slice %66 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %69 = vector.extract_strided_slice %66 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %70 = vector.extract_strided_slice %66 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %71 = vector.extract_strided_slice %66 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %72 = vector.extract_strided_slice %66 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %73 = vector.extract_strided_slice %66 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %74 = vector.extract_strided_slice %66 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %75 = vector.outerproduct %67, %43, %33 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %76 = vector.outerproduct %68, %45, %75 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %77 = vector.outerproduct %69, %47, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %78 = vector.outerproduct %70, %49, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %79 = vector.outerproduct %71, %51, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %80 = vector.outerproduct %72, %53, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %81 = vector.outerproduct %73, %55, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %82 = vector.outerproduct %74, %57, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %83 = arith.addi %32, %c8 : index
  cf.br ^bb5(%83, %82 : index, vector<8x8xf32>)
^bb7:  // pred: ^bb5
  %84 = vector.extract %33[0] : vector<8x8xf32>
  vector.store %84, %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %85 = vector.extract %33[1] : vector<8x8xf32>
  vector.store %85, %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %86 = vector.extract %33[2] : vector<8x8xf32>
  vector.store %86, %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %87 = vector.extract %33[3] : vector<8x8xf32>
  vector.store %87, %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %88 = vector.extract %33[4] : vector<8x8xf32>
  vector.store %88, %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %89 = vector.extract %33[5] : vector<8x8xf32>
  vector.store %89, %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %90 = vector.extract %33[6] : vector<8x8xf32>
  vector.store %90, %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %91 = vector.extract %33[7] : vector<8x8xf32>
  vector.store %91, %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %92 = arith.addi %14, %c8 : index
  cf.br ^bb3(%92 : index)
^bb8:  // pred: ^bb3
  %93 = arith.addi %5, %c8 : index
  cf.br ^bb1(%93 : index)
^bb9:  // pred: ^bb1
  return
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb8
  %6 = arith.cmpi slt, %5, %c32 : index
  cf.cond_br %6, ^bb2, ^bb9
^bb2:  // pred: ^bb1
  %7 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%5]
  %8 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%5]
  %9 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%5]
  %10 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%5]
  %11 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%5]
  %12 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%5]
  %13 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%5]
  cf.br ^bb3(%c0 : index)
^bb3(%14: index):  // 2 preds: ^bb2, ^bb7
  %15 = arith.cmpi slt, %14, %c32 : index
  cf.cond_br %15, ^bb4, ^bb8
^bb4:  // pred: ^bb3
  %16 = vector.load %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %17 = vector.insert %16, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
  %18 = vector.load %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %19 = vector.insert %18, %17 [1] : vector<8xf32> into vector<8x8xf32>
  %20 = vector.load %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %21 = vector.insert %20, %19 [2] : vector<8xf32> into vector<8x8xf32>
  %22 = vector.load %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %23 = vector.insert %22, %21 [3] : vector<8xf32> into vector<8x8xf32>
  %24 = vector.load %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %25 = vector.insert %24, %23 [4] : vector<8xf32> into vector<8x8xf32>
  %26 = vector.load %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %27 = vector.insert %26, %25 [5] : vector<8xf32> into vector<8x8xf32>
  %28 = vector.load %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %29 = vector.insert %28, %27 [6] : vector<8xf32> into vector<8x8xf32>
  %30 = vector.load %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %31 = vector.insert %30, %29 [7] : vector<8xf32> into vector<8x8xf32>
  cf.br ^bb5(%c0, %31 : index, vector<8x8xf32>)
^bb5(%32: index, %33: vector<8x8xf32>):  // 2 preds: ^bb4, ^bb6
  %34 = arith.cmpi slt, %32, %c256 : index
  cf.cond_br %34, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %35 = vector.load %subview[%5, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %36 = vector.load %subview[%7, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %37 = vector.load %subview[%8, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %38 = vector.load %subview[%9, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %39 = vector.load %subview[%10, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %40 = vector.load %subview[%11, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %41 = vector.load %subview[%12, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %42 = vector.load %subview[%13, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %43 = vector.load %subview_1[%32, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %44 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%32]
  %45 = vector.load %subview_1[%44, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %46 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%32]
  %47 = vector.load %subview_1[%46, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %48 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%32]
  %49 = vector.load %subview_1[%48, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %50 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%32]
  %51 = vector.load %subview_1[%50, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %52 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%32]
  %53 = vector.load %subview_1[%52, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %54 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%32]
  %55 = vector.load %subview_1[%54, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %56 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%32]
  %57 = vector.load %subview_1[%56, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %58 = vector.insert_strided_slice %35, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
  %59 = vector.insert_strided_slice %36, %58 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
  %60 = vector.insert_strided_slice %37, %59 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
  %61 = vector.insert_strided_slice %38, %60 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
  %62 = vector.insert_strided_slice %39, %61 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
  %63 = vector.insert_strided_slice %40, %62 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
  %64 = vector.insert_strided_slice %41, %63 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
  %65 = vector.insert_strided_slice %42, %64 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
  %66 = vector.shuffle %65, %65 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
  %67 = vector.extract_strided_slice %66 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %68 = vector.extract_strided_slice %66 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %69 = vector.extract_strided_slice %66 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %70 = vector.extract_strided_slice %66 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %71 = vector.extract_strided_slice %66 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %72 = vector.extract_strided_slice %66 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %73 = vector.extract_strided_slice %66 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %74 = vector.extract_strided_slice %66 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %75 = vector.outerproduct %67, %43, %33 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %76 = vector.outerproduct %68, %45, %75 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %77 = vector.outerproduct %69, %47, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %78 = vector.outerproduct %70, %49, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %79 = vector.outerproduct %71, %51, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %80 = vector.outerproduct %72, %53, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %81 = vector.outerproduct %73, %55, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %82 = vector.outerproduct %74, %57, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %83 = arith.addi %32, %c8 : index
  cf.br ^bb5(%83, %82 : index, vector<8x8xf32>)
^bb7:  // pred: ^bb5
  %84 = vector.extract %33[0] : vector<8x8xf32>
  vector.store %84, %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %85 = vector.extract %33[1] : vector<8x8xf32>
  vector.store %85, %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %86 = vector.extract %33[2] : vector<8x8xf32>
  vector.store %86, %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %87 = vector.extract %33[3] : vector<8x8xf32>
  vector.store %87, %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %88 = vector.extract %33[4] : vector<8x8xf32>
  vector.store %88, %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %89 = vector.extract %33[5] : vector<8x8xf32>
  vector.store %89, %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %90 = vector.extract %33[6] : vector<8x8xf32>
  vector.store %90, %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %91 = vector.extract %33[7] : vector<8x8xf32>
  vector.store %91, %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %92 = arith.addi %14, %c8 : index
  cf.br ^bb3(%92 : index)
^bb8:  // pred: ^bb3
  %93 = arith.addi %5, %c8 : index
  cf.br ^bb1(%93 : index)
^bb9:  // pred: ^bb1
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @matmul_static_dispatch_0_matmul_512x1024x256() {
  %cst = arith.constant dense<0.000000e+00> : vector<64xf32>
  %cst_0 = arith.constant dense<0.000000e+00> : vector<8x8xf32>
  %c256 = arith.constant 256 : index
  %c8 = arith.constant 8 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) offset(%c0) alignment(64) : memref<512x256xf32>
  memref.assume_alignment %0, 64 : memref<512x256xf32>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) offset(%c0) alignment(64) : memref<256x1024xf32>
  memref.assume_alignment %1, 64 : memref<256x1024xf32>
  %2 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) offset(%c0) alignment(64) : memref<512x1024xf32>
  memref.assume_alignment %2, 64 : memref<512x1024xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_id_y = hal.interface.workgroup.id[1] : index
  %3 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_y]
  %4 = affine.apply affine_map<()[s0] -> (s0 * 32)>()[%workgroup_id_x]
  %subview = memref.subview %0[%3, 0] [32, 256] [1, 1] : memref<512x256xf32> to memref<32x256xf32, strided<[256, 1], offset: ?>>
  %subview_1 = memref.subview %1[0, %4] [256, 32] [1, 1] : memref<256x1024xf32> to memref<256x32xf32, strided<[1024, 1], offset: ?>>
  %subview_2 = memref.subview %2[%3, %4] [32, 32] [1, 1] : memref<512x1024xf32> to memref<32x32xf32, strided<[1024, 1], offset: ?>>
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb8
  %6 = arith.cmpi slt, %5, %c32 : index
  cf.cond_br %6, ^bb2, ^bb9
^bb2:  // pred: ^bb1
  %7 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%5]
  %8 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%5]
  %9 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%5]
  %10 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%5]
  %11 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%5]
  %12 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%5]
  %13 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%5]
  cf.br ^bb3(%c0 : index)
^bb3(%14: index):  // 2 preds: ^bb2, ^bb7
  %15 = arith.cmpi slt, %14, %c32 : index
  cf.cond_br %15, ^bb4, ^bb8
^bb4:  // pred: ^bb3
  %16 = vector.load %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %17 = vector.insert %16, %cst_0 [0] : vector<8xf32> into vector<8x8xf32>
  %18 = vector.load %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %19 = vector.insert %18, %17 [1] : vector<8xf32> into vector<8x8xf32>
  %20 = vector.load %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %21 = vector.insert %20, %19 [2] : vector<8xf32> into vector<8x8xf32>
  %22 = vector.load %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %23 = vector.insert %22, %21 [3] : vector<8xf32> into vector<8x8xf32>
  %24 = vector.load %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %25 = vector.insert %24, %23 [4] : vector<8xf32> into vector<8x8xf32>
  %26 = vector.load %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %27 = vector.insert %26, %25 [5] : vector<8xf32> into vector<8x8xf32>
  %28 = vector.load %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %29 = vector.insert %28, %27 [6] : vector<8xf32> into vector<8x8xf32>
  %30 = vector.load %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %31 = vector.insert %30, %29 [7] : vector<8xf32> into vector<8x8xf32>
  cf.br ^bb5(%c0, %31 : index, vector<8x8xf32>)
^bb5(%32: index, %33: vector<8x8xf32>):  // 2 preds: ^bb4, ^bb6
  %34 = arith.cmpi slt, %32, %c256 : index
  cf.cond_br %34, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %35 = vector.load %subview[%5, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %36 = vector.load %subview[%7, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %37 = vector.load %subview[%8, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %38 = vector.load %subview[%9, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %39 = vector.load %subview[%10, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %40 = vector.load %subview[%11, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %41 = vector.load %subview[%12, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %42 = vector.load %subview[%13, %32] : memref<32x256xf32, strided<[256, 1], offset: ?>>, vector<8xf32>
  %43 = vector.load %subview_1[%32, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %44 = affine.apply affine_map<()[s0] -> (s0 + 1)>()[%32]
  %45 = vector.load %subview_1[%44, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %46 = affine.apply affine_map<()[s0] -> (s0 + 2)>()[%32]
  %47 = vector.load %subview_1[%46, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %48 = affine.apply affine_map<()[s0] -> (s0 + 3)>()[%32]
  %49 = vector.load %subview_1[%48, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %50 = affine.apply affine_map<()[s0] -> (s0 + 4)>()[%32]
  %51 = vector.load %subview_1[%50, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %52 = affine.apply affine_map<()[s0] -> (s0 + 5)>()[%32]
  %53 = vector.load %subview_1[%52, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %54 = affine.apply affine_map<()[s0] -> (s0 + 6)>()[%32]
  %55 = vector.load %subview_1[%54, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %56 = affine.apply affine_map<()[s0] -> (s0 + 7)>()[%32]
  %57 = vector.load %subview_1[%56, %14] : memref<256x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %58 = vector.insert_strided_slice %35, %cst {offsets = [0], strides = [1]} : vector<8xf32> into vector<64xf32>
  %59 = vector.insert_strided_slice %36, %58 {offsets = [8], strides = [1]} : vector<8xf32> into vector<64xf32>
  %60 = vector.insert_strided_slice %37, %59 {offsets = [16], strides = [1]} : vector<8xf32> into vector<64xf32>
  %61 = vector.insert_strided_slice %38, %60 {offsets = [24], strides = [1]} : vector<8xf32> into vector<64xf32>
  %62 = vector.insert_strided_slice %39, %61 {offsets = [32], strides = [1]} : vector<8xf32> into vector<64xf32>
  %63 = vector.insert_strided_slice %40, %62 {offsets = [40], strides = [1]} : vector<8xf32> into vector<64xf32>
  %64 = vector.insert_strided_slice %41, %63 {offsets = [48], strides = [1]} : vector<8xf32> into vector<64xf32>
  %65 = vector.insert_strided_slice %42, %64 {offsets = [56], strides = [1]} : vector<8xf32> into vector<64xf32>
  %66 = vector.shuffle %65, %65 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32>, vector<64xf32>
  %67 = vector.extract_strided_slice %66 {offsets = [0], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %68 = vector.extract_strided_slice %66 {offsets = [8], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %69 = vector.extract_strided_slice %66 {offsets = [16], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %70 = vector.extract_strided_slice %66 {offsets = [24], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %71 = vector.extract_strided_slice %66 {offsets = [32], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %72 = vector.extract_strided_slice %66 {offsets = [40], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %73 = vector.extract_strided_slice %66 {offsets = [48], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %74 = vector.extract_strided_slice %66 {offsets = [56], sizes = [8], strides = [1]} : vector<64xf32> to vector<8xf32>
  %75 = vector.outerproduct %67, %43, %33 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %76 = vector.outerproduct %68, %45, %75 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %77 = vector.outerproduct %69, %47, %76 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %78 = vector.outerproduct %70, %49, %77 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %79 = vector.outerproduct %71, %51, %78 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %80 = vector.outerproduct %72, %53, %79 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %81 = vector.outerproduct %73, %55, %80 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %82 = vector.outerproduct %74, %57, %81 {kind = #vector.kind<add>} : vector<8xf32>, vector<8xf32>
  %83 = arith.addi %32, %c8 : index
  cf.br ^bb5(%83, %82 : index, vector<8x8xf32>)
^bb7:  // pred: ^bb5
  %84 = vector.extract %33[0] : vector<8x8xf32>
  vector.store %84, %subview_2[%5, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %85 = vector.extract %33[1] : vector<8x8xf32>
  vector.store %85, %subview_2[%7, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %86 = vector.extract %33[2] : vector<8x8xf32>
  vector.store %86, %subview_2[%8, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %87 = vector.extract %33[3] : vector<8x8xf32>
  vector.store %87, %subview_2[%9, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %88 = vector.extract %33[4] : vector<8x8xf32>
  vector.store %88, %subview_2[%10, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %89 = vector.extract %33[5] : vector<8x8xf32>
  vector.store %89, %subview_2[%11, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %90 = vector.extract %33[6] : vector<8x8xf32>
  vector.store %90, %subview_2[%12, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %91 = vector.extract %33[7] : vector<8x8xf32>
  vector.store %91, %subview_2[%13, %14] : memref<32x32xf32, strided<[1024, 1], offset: ?>>, vector<8xf32>
  %92 = arith.addi %14, %c8 : index
  cf.br ^bb3(%92 : index)
^bb8:  // pred: ^bb3
  %93 = arith.addi %5, %c8 : index
  cf.br ^bb1(%93 : index)
^bb9:  // pred: ^bb1
  return
}

// -----// IR Dump After ConvertToLLVM (iree-convert-to-llvm) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(63 : i64) : i64
    %1 = llvm.mlir.constant(62 : i64) : i64
    %2 = llvm.mlir.constant(61 : i64) : i64
    %3 = llvm.mlir.constant(60 : i64) : i64
    %4 = llvm.mlir.constant(59 : i64) : i64
    %5 = llvm.mlir.constant(58 : i64) : i64
    %6 = llvm.mlir.constant(57 : i64) : i64
    %7 = llvm.mlir.constant(56 : i64) : i64
    %8 = llvm.mlir.constant(55 : i64) : i64
    %9 = llvm.mlir.constant(54 : i64) : i64
    %10 = llvm.mlir.constant(53 : i64) : i64
    %11 = llvm.mlir.constant(52 : i64) : i64
    %12 = llvm.mlir.constant(51 : i64) : i64
    %13 = llvm.mlir.constant(50 : i64) : i64
    %14 = llvm.mlir.constant(49 : i64) : i64
    %15 = llvm.mlir.constant(48 : i64) : i64
    %16 = llvm.mlir.constant(47 : i64) : i64
    %17 = llvm.mlir.constant(46 : i64) : i64
    %18 = llvm.mlir.constant(45 : i64) : i64
    %19 = llvm.mlir.constant(44 : i64) : i64
    %20 = llvm.mlir.constant(43 : i64) : i64
    %21 = llvm.mlir.constant(42 : i64) : i64
    %22 = llvm.mlir.constant(41 : i64) : i64
    %23 = llvm.mlir.constant(40 : i64) : i64
    %24 = llvm.mlir.constant(39 : i64) : i64
    %25 = llvm.mlir.constant(38 : i64) : i64
    %26 = llvm.mlir.constant(37 : i64) : i64
    %27 = llvm.mlir.constant(36 : i64) : i64
    %28 = llvm.mlir.constant(35 : i64) : i64
    %29 = llvm.mlir.constant(34 : i64) : i64
    %30 = llvm.mlir.constant(33 : i64) : i64
    %31 = llvm.mlir.constant(32 : i64) : i64
    %32 = llvm.mlir.constant(31 : i64) : i64
    %33 = llvm.mlir.constant(30 : i64) : i64
    %34 = llvm.mlir.constant(29 : i64) : i64
    %35 = llvm.mlir.constant(28 : i64) : i64
    %36 = llvm.mlir.constant(27 : i64) : i64
    %37 = llvm.mlir.constant(26 : i64) : i64
    %38 = llvm.mlir.constant(25 : i64) : i64
    %39 = llvm.mlir.constant(24 : i64) : i64
    %40 = llvm.mlir.constant(23 : i64) : i64
    %41 = llvm.mlir.constant(22 : i64) : i64
    %42 = llvm.mlir.constant(21 : i64) : i64
    %43 = llvm.mlir.constant(20 : i64) : i64
    %44 = llvm.mlir.constant(19 : i64) : i64
    %45 = llvm.mlir.constant(18 : i64) : i64
    %46 = llvm.mlir.constant(17 : i64) : i64
    %47 = llvm.mlir.constant(16 : i64) : i64
    %48 = llvm.mlir.constant(15 : i64) : i64
    %49 = llvm.mlir.constant(14 : i64) : i64
    %50 = llvm.mlir.constant(13 : i64) : i64
    %51 = llvm.mlir.constant(12 : i64) : i64
    %52 = llvm.mlir.constant(11 : i64) : i64
    %53 = llvm.mlir.constant(10 : i64) : i64
    %54 = llvm.mlir.constant(9 : i64) : i64
    %55 = llvm.mlir.constant(8 : i64) : i64
    %56 = llvm.mlir.constant(7 : i64) : i64
    %57 = llvm.mlir.constant(6 : i64) : i64
    %58 = llvm.mlir.constant(5 : i64) : i64
    %59 = llvm.mlir.constant(4 : i64) : i64
    %60 = llvm.mlir.constant(3 : i64) : i64
    %61 = llvm.mlir.constant(0 : i32) : i32
    %62 = llvm.mlir.constant(7 : index) : i64
    %63 = llvm.mlir.constant(6 : index) : i64
    %64 = llvm.mlir.constant(5 : index) : i64
    %65 = llvm.mlir.constant(4 : index) : i64
    %66 = llvm.mlir.constant(3 : index) : i64
    %67 = llvm.mlir.constant(2 : index) : i64
    %68 = llvm.mlir.constant(32768 : index) : i64
    %69 = llvm.mlir.constant(8192 : index) : i64
    %70 = llvm.mlir.constant(2 : i64) : i64
    %71 = llvm.mlir.constant(1024 : index) : i64
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.constant(63 : index) : i64
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.mlir.constant(0 : i64) : i64
    %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
    %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
    %78 = llvm.mlir.constant(256 : index) : i64
    %79 = llvm.mlir.constant(8 : index) : i64
    %80 = llvm.mlir.constant(32 : index) : i64
    %81 = llvm.mlir.constant(0 : index) : i64
    %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
    %87 = llvm.and %86, %73  : i64
    %88 = llvm.icmp "eq" %87, %81 : i64
    "llvm.intr.assume"(%88) : (i1) -> ()
    %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
    %95 = llvm.and %94, %73  : i64
    %96 = llvm.icmp "eq" %95, %81 : i64
    "llvm.intr.assume"(%96) : (i1) -> ()
    %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
    %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
    %103 = llvm.and %102, %73  : i64
    %104 = llvm.icmp "eq" %103, %81 : i64
    "llvm.intr.assume"(%104) : (i1) -> ()
    %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %107 = llvm.zext %106 : i32 to i64
    %108 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %109 = llvm.extractvalue %108[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %110 = llvm.zext %109 : i32 to i64
    %111 = llvm.mul %110, %69  : i64
    %112 = llvm.mul %107, %80  : i64
    %113 = llvm.mul %110, %68  : i64
    %114 = llvm.mul %107, %80  : i64
    %115 = llvm.add %113, %114  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb1(%116: i64):  // 2 preds: ^bb0, ^bb8
    %117 = llvm.icmp "slt" %116, %80 : i64
    llvm.cond_br %117, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %118 = llvm.add %116, %74  : i64
    %119 = llvm.add %116, %67  : i64
    %120 = llvm.add %116, %66  : i64
    %121 = llvm.add %116, %65  : i64
    %122 = llvm.add %116, %64  : i64
    %123 = llvm.add %116, %63  : i64
    %124 = llvm.add %116, %62  : i64
    llvm.br ^bb3(%81 : i64)
  ^bb3(%125: i64):  // 2 preds: ^bb2, ^bb7
    %126 = llvm.icmp "slt" %125, %80 : i64
    llvm.cond_br %126, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %127 = llvm.mul %116, %71  : i64
    %128 = llvm.add %115, %127  : i64
    %129 = llvm.add %128, %125  : i64
    %130 = llvm.getelementptr %101[%129] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %131 = llvm.bitcast %130 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %132 = llvm.load %131 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %133 = llvm.insertvalue %132, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %134 = llvm.mul %118, %71  : i64
    %135 = llvm.add %115, %134  : i64
    %136 = llvm.add %135, %125  : i64
    %137 = llvm.getelementptr %101[%136] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %138 = llvm.bitcast %137 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %139 = llvm.load %138 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %140 = llvm.insertvalue %139, %133[1] : !llvm.array<8 x vector<8xf32>> 
    %141 = llvm.mul %119, %71  : i64
    %142 = llvm.add %115, %141  : i64
    %143 = llvm.add %142, %125  : i64
    %144 = llvm.getelementptr %101[%143] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %145 = llvm.bitcast %144 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %146 = llvm.load %145 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %147 = llvm.insertvalue %146, %140[2] : !llvm.array<8 x vector<8xf32>> 
    %148 = llvm.mul %120, %71  : i64
    %149 = llvm.add %115, %148  : i64
    %150 = llvm.add %149, %125  : i64
    %151 = llvm.getelementptr %101[%150] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %152 = llvm.bitcast %151 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %153 = llvm.load %152 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %154 = llvm.insertvalue %153, %147[3] : !llvm.array<8 x vector<8xf32>> 
    %155 = llvm.mul %121, %71  : i64
    %156 = llvm.add %115, %155  : i64
    %157 = llvm.add %156, %125  : i64
    %158 = llvm.getelementptr %101[%157] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %159 = llvm.bitcast %158 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %160 = llvm.load %159 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %161 = llvm.insertvalue %160, %154[4] : !llvm.array<8 x vector<8xf32>> 
    %162 = llvm.mul %122, %71  : i64
    %163 = llvm.add %115, %162  : i64
    %164 = llvm.add %163, %125  : i64
    %165 = llvm.getelementptr %101[%164] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %166 = llvm.bitcast %165 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %167 = llvm.load %166 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %168 = llvm.insertvalue %167, %161[5] : !llvm.array<8 x vector<8xf32>> 
    %169 = llvm.mul %123, %71  : i64
    %170 = llvm.add %115, %169  : i64
    %171 = llvm.add %170, %125  : i64
    %172 = llvm.getelementptr %101[%171] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %173 = llvm.bitcast %172 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %174 = llvm.load %173 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %175 = llvm.insertvalue %174, %168[6] : !llvm.array<8 x vector<8xf32>> 
    %176 = llvm.mul %124, %71  : i64
    %177 = llvm.add %115, %176  : i64
    %178 = llvm.add %177, %125  : i64
    %179 = llvm.getelementptr %101[%178] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %180 = llvm.bitcast %179 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %181 = llvm.load %180 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %182 = llvm.insertvalue %181, %175[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.br ^bb5(%81, %182 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb5(%183: i64, %184: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
    %185 = llvm.icmp "slt" %183, %78 : i64
    llvm.cond_br %185, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %186 = llvm.mul %116, %78  : i64
    %187 = llvm.add %111, %186  : i64
    %188 = llvm.add %187, %183  : i64
    %189 = llvm.getelementptr %85[%188] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %190 = llvm.bitcast %189 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %191 = llvm.load %190 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %192 = llvm.mul %118, %78  : i64
    %193 = llvm.add %111, %192  : i64
    %194 = llvm.add %193, %183  : i64
    %195 = llvm.getelementptr %85[%194] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %196 = llvm.bitcast %195 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %197 = llvm.load %196 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %198 = llvm.mul %119, %78  : i64
    %199 = llvm.add %111, %198  : i64
    %200 = llvm.add %199, %183  : i64
    %201 = llvm.getelementptr %85[%200] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %202 = llvm.bitcast %201 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %203 = llvm.load %202 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %204 = llvm.mul %120, %78  : i64
    %205 = llvm.add %111, %204  : i64
    %206 = llvm.add %205, %183  : i64
    %207 = llvm.getelementptr %85[%206] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %208 = llvm.bitcast %207 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %209 = llvm.load %208 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %210 = llvm.mul %121, %78  : i64
    %211 = llvm.add %111, %210  : i64
    %212 = llvm.add %211, %183  : i64
    %213 = llvm.getelementptr %85[%212] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %214 = llvm.bitcast %213 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %215 = llvm.load %214 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %216 = llvm.mul %122, %78  : i64
    %217 = llvm.add %111, %216  : i64
    %218 = llvm.add %217, %183  : i64
    %219 = llvm.getelementptr %85[%218] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %220 = llvm.bitcast %219 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %221 = llvm.load %220 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %222 = llvm.mul %123, %78  : i64
    %223 = llvm.add %111, %222  : i64
    %224 = llvm.add %223, %183  : i64
    %225 = llvm.getelementptr %85[%224] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %226 = llvm.bitcast %225 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %227 = llvm.load %226 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %228 = llvm.mul %124, %78  : i64
    %229 = llvm.add %111, %228  : i64
    %230 = llvm.add %229, %183  : i64
    %231 = llvm.getelementptr %85[%230] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %232 = llvm.bitcast %231 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %233 = llvm.load %232 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %234 = llvm.mul %183, %71  : i64
    %235 = llvm.add %112, %234  : i64
    %236 = llvm.add %235, %125  : i64
    %237 = llvm.getelementptr %93[%236] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %238 = llvm.bitcast %237 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %239 = llvm.load %238 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %240 = llvm.add %183, %74  : i64
    %241 = llvm.mul %240, %71  : i64
    %242 = llvm.add %112, %241  : i64
    %243 = llvm.add %242, %125  : i64
    %244 = llvm.getelementptr %93[%243] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %245 = llvm.bitcast %244 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %246 = llvm.load %245 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %247 = llvm.add %183, %67  : i64
    %248 = llvm.mul %247, %71  : i64
    %249 = llvm.add %112, %248  : i64
    %250 = llvm.add %249, %125  : i64
    %251 = llvm.getelementptr %93[%250] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %252 = llvm.bitcast %251 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %253 = llvm.load %252 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %254 = llvm.add %183, %66  : i64
    %255 = llvm.mul %254, %71  : i64
    %256 = llvm.add %112, %255  : i64
    %257 = llvm.add %256, %125  : i64
    %258 = llvm.getelementptr %93[%257] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %259 = llvm.bitcast %258 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %260 = llvm.load %259 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %261 = llvm.add %183, %65  : i64
    %262 = llvm.mul %261, %71  : i64
    %263 = llvm.add %112, %262  : i64
    %264 = llvm.add %263, %125  : i64
    %265 = llvm.getelementptr %93[%264] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %266 = llvm.bitcast %265 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %267 = llvm.load %266 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %268 = llvm.add %183, %64  : i64
    %269 = llvm.mul %268, %71  : i64
    %270 = llvm.add %112, %269  : i64
    %271 = llvm.add %270, %125  : i64
    %272 = llvm.getelementptr %93[%271] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %273 = llvm.bitcast %272 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %274 = llvm.load %273 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %275 = llvm.add %183, %63  : i64
    %276 = llvm.mul %275, %71  : i64
    %277 = llvm.add %112, %276  : i64
    %278 = llvm.add %277, %125  : i64
    %279 = llvm.getelementptr %93[%278] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %280 = llvm.bitcast %279 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %281 = llvm.load %280 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %282 = llvm.add %183, %62  : i64
    %283 = llvm.mul %282, %71  : i64
    %284 = llvm.add %112, %283  : i64
    %285 = llvm.add %284, %125  : i64
    %286 = llvm.getelementptr %93[%285] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %287 = llvm.bitcast %286 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %288 = llvm.load %287 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %289 = llvm.shufflevector %191, %191 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %290 = llvm.shufflevector %289, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %291 = llvm.shufflevector %197, %197 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %293 = llvm.shufflevector %203, %203 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %295 = llvm.shufflevector %209, %209 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %297 = llvm.shufflevector %215, %215 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %299 = llvm.shufflevector %221, %221 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %301 = llvm.shufflevector %227, %227 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %303 = llvm.shufflevector %233, %233 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %304 = llvm.shufflevector %303, %302 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
    %305 = llvm.shufflevector %304, %304 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
    %306 = llvm.extractelement %305[%75 : i64] : vector<64xf32>
    %307 = llvm.mlir.undef : vector<8xf32>
    %308 = llvm.insertelement %306, %307[%61 : i32] : vector<8xf32>
    %309 = llvm.shufflevector %308, %307 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %310 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %311 = llvm.intr.fmuladd(%309, %239, %310)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %312 = llvm.extractelement %305[%72 : i64] : vector<64xf32>
    %313 = llvm.mlir.undef : vector<8xf32>
    %314 = llvm.insertelement %312, %313[%61 : i32] : vector<8xf32>
    %315 = llvm.shufflevector %314, %313 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %316 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %317 = llvm.intr.fmuladd(%315, %239, %316)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %318 = llvm.extractelement %305[%70 : i64] : vector<64xf32>
    %319 = llvm.mlir.undef : vector<8xf32>
    %320 = llvm.insertelement %318, %319[%61 : i32] : vector<8xf32>
    %321 = llvm.shufflevector %320, %319 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %322 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %323 = llvm.intr.fmuladd(%321, %239, %322)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %324 = llvm.extractelement %305[%60 : i64] : vector<64xf32>
    %325 = llvm.mlir.undef : vector<8xf32>
    %326 = llvm.insertelement %324, %325[%61 : i32] : vector<8xf32>
    %327 = llvm.shufflevector %326, %325 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %328 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %329 = llvm.intr.fmuladd(%327, %239, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %330 = llvm.extractelement %305[%59 : i64] : vector<64xf32>
    %331 = llvm.mlir.undef : vector<8xf32>
    %332 = llvm.insertelement %330, %331[%61 : i32] : vector<8xf32>
    %333 = llvm.shufflevector %332, %331 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %334 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %335 = llvm.intr.fmuladd(%333, %239, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %336 = llvm.extractelement %305[%58 : i64] : vector<64xf32>
    %337 = llvm.mlir.undef : vector<8xf32>
    %338 = llvm.insertelement %336, %337[%61 : i32] : vector<8xf32>
    %339 = llvm.shufflevector %338, %337 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %340 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %341 = llvm.intr.fmuladd(%339, %239, %340)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %342 = llvm.extractelement %305[%57 : i64] : vector<64xf32>
    %343 = llvm.mlir.undef : vector<8xf32>
    %344 = llvm.insertelement %342, %343[%61 : i32] : vector<8xf32>
    %345 = llvm.shufflevector %344, %343 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %346 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %347 = llvm.intr.fmuladd(%345, %239, %346)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %348 = llvm.extractelement %305[%56 : i64] : vector<64xf32>
    %349 = llvm.mlir.undef : vector<8xf32>
    %350 = llvm.insertelement %348, %349[%61 : i32] : vector<8xf32>
    %351 = llvm.shufflevector %350, %349 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %352 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %353 = llvm.intr.fmuladd(%351, %239, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %354 = llvm.extractelement %305[%55 : i64] : vector<64xf32>
    %355 = llvm.mlir.undef : vector<8xf32>
    %356 = llvm.insertelement %354, %355[%61 : i32] : vector<8xf32>
    %357 = llvm.shufflevector %356, %355 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %358 = llvm.intr.fmuladd(%357, %246, %311)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %359 = llvm.extractelement %305[%54 : i64] : vector<64xf32>
    %360 = llvm.mlir.undef : vector<8xf32>
    %361 = llvm.insertelement %359, %360[%61 : i32] : vector<8xf32>
    %362 = llvm.shufflevector %361, %360 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %363 = llvm.intr.fmuladd(%362, %246, %317)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %364 = llvm.extractelement %305[%53 : i64] : vector<64xf32>
    %365 = llvm.mlir.undef : vector<8xf32>
    %366 = llvm.insertelement %364, %365[%61 : i32] : vector<8xf32>
    %367 = llvm.shufflevector %366, %365 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %368 = llvm.intr.fmuladd(%367, %246, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %369 = llvm.extractelement %305[%52 : i64] : vector<64xf32>
    %370 = llvm.mlir.undef : vector<8xf32>
    %371 = llvm.insertelement %369, %370[%61 : i32] : vector<8xf32>
    %372 = llvm.shufflevector %371, %370 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %373 = llvm.intr.fmuladd(%372, %246, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %374 = llvm.extractelement %305[%51 : i64] : vector<64xf32>
    %375 = llvm.mlir.undef : vector<8xf32>
    %376 = llvm.insertelement %374, %375[%61 : i32] : vector<8xf32>
    %377 = llvm.shufflevector %376, %375 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %378 = llvm.intr.fmuladd(%377, %246, %335)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %379 = llvm.extractelement %305[%50 : i64] : vector<64xf32>
    %380 = llvm.mlir.undef : vector<8xf32>
    %381 = llvm.insertelement %379, %380[%61 : i32] : vector<8xf32>
    %382 = llvm.shufflevector %381, %380 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %383 = llvm.intr.fmuladd(%382, %246, %341)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %384 = llvm.extractelement %305[%49 : i64] : vector<64xf32>
    %385 = llvm.mlir.undef : vector<8xf32>
    %386 = llvm.insertelement %384, %385[%61 : i32] : vector<8xf32>
    %387 = llvm.shufflevector %386, %385 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %388 = llvm.intr.fmuladd(%387, %246, %347)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %389 = llvm.extractelement %305[%48 : i64] : vector<64xf32>
    %390 = llvm.mlir.undef : vector<8xf32>
    %391 = llvm.insertelement %389, %390[%61 : i32] : vector<8xf32>
    %392 = llvm.shufflevector %391, %390 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %393 = llvm.intr.fmuladd(%392, %246, %353)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %394 = llvm.extractelement %305[%47 : i64] : vector<64xf32>
    %395 = llvm.mlir.undef : vector<8xf32>
    %396 = llvm.insertelement %394, %395[%61 : i32] : vector<8xf32>
    %397 = llvm.shufflevector %396, %395 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %398 = llvm.intr.fmuladd(%397, %253, %358)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %399 = llvm.extractelement %305[%46 : i64] : vector<64xf32>
    %400 = llvm.mlir.undef : vector<8xf32>
    %401 = llvm.insertelement %399, %400[%61 : i32] : vector<8xf32>
    %402 = llvm.shufflevector %401, %400 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %403 = llvm.intr.fmuladd(%402, %253, %363)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %404 = llvm.extractelement %305[%45 : i64] : vector<64xf32>
    %405 = llvm.mlir.undef : vector<8xf32>
    %406 = llvm.insertelement %404, %405[%61 : i32] : vector<8xf32>
    %407 = llvm.shufflevector %406, %405 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %408 = llvm.intr.fmuladd(%407, %253, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %409 = llvm.extractelement %305[%44 : i64] : vector<64xf32>
    %410 = llvm.mlir.undef : vector<8xf32>
    %411 = llvm.insertelement %409, %410[%61 : i32] : vector<8xf32>
    %412 = llvm.shufflevector %411, %410 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %413 = llvm.intr.fmuladd(%412, %253, %373)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %414 = llvm.extractelement %305[%43 : i64] : vector<64xf32>
    %415 = llvm.mlir.undef : vector<8xf32>
    %416 = llvm.insertelement %414, %415[%61 : i32] : vector<8xf32>
    %417 = llvm.shufflevector %416, %415 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %418 = llvm.intr.fmuladd(%417, %253, %378)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %419 = llvm.extractelement %305[%42 : i64] : vector<64xf32>
    %420 = llvm.mlir.undef : vector<8xf32>
    %421 = llvm.insertelement %419, %420[%61 : i32] : vector<8xf32>
    %422 = llvm.shufflevector %421, %420 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %423 = llvm.intr.fmuladd(%422, %253, %383)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %424 = llvm.extractelement %305[%41 : i64] : vector<64xf32>
    %425 = llvm.mlir.undef : vector<8xf32>
    %426 = llvm.insertelement %424, %425[%61 : i32] : vector<8xf32>
    %427 = llvm.shufflevector %426, %425 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %428 = llvm.intr.fmuladd(%427, %253, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %429 = llvm.extractelement %305[%40 : i64] : vector<64xf32>
    %430 = llvm.mlir.undef : vector<8xf32>
    %431 = llvm.insertelement %429, %430[%61 : i32] : vector<8xf32>
    %432 = llvm.shufflevector %431, %430 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %433 = llvm.intr.fmuladd(%432, %253, %393)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %434 = llvm.extractelement %305[%39 : i64] : vector<64xf32>
    %435 = llvm.mlir.undef : vector<8xf32>
    %436 = llvm.insertelement %434, %435[%61 : i32] : vector<8xf32>
    %437 = llvm.shufflevector %436, %435 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %438 = llvm.intr.fmuladd(%437, %260, %398)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %439 = llvm.extractelement %305[%38 : i64] : vector<64xf32>
    %440 = llvm.mlir.undef : vector<8xf32>
    %441 = llvm.insertelement %439, %440[%61 : i32] : vector<8xf32>
    %442 = llvm.shufflevector %441, %440 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %443 = llvm.intr.fmuladd(%442, %260, %403)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %444 = llvm.extractelement %305[%37 : i64] : vector<64xf32>
    %445 = llvm.mlir.undef : vector<8xf32>
    %446 = llvm.insertelement %444, %445[%61 : i32] : vector<8xf32>
    %447 = llvm.shufflevector %446, %445 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %448 = llvm.intr.fmuladd(%447, %260, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %449 = llvm.extractelement %305[%36 : i64] : vector<64xf32>
    %450 = llvm.mlir.undef : vector<8xf32>
    %451 = llvm.insertelement %449, %450[%61 : i32] : vector<8xf32>
    %452 = llvm.shufflevector %451, %450 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %453 = llvm.intr.fmuladd(%452, %260, %413)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %454 = llvm.extractelement %305[%35 : i64] : vector<64xf32>
    %455 = llvm.mlir.undef : vector<8xf32>
    %456 = llvm.insertelement %454, %455[%61 : i32] : vector<8xf32>
    %457 = llvm.shufflevector %456, %455 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %458 = llvm.intr.fmuladd(%457, %260, %418)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %459 = llvm.extractelement %305[%34 : i64] : vector<64xf32>
    %460 = llvm.mlir.undef : vector<8xf32>
    %461 = llvm.insertelement %459, %460[%61 : i32] : vector<8xf32>
    %462 = llvm.shufflevector %461, %460 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %463 = llvm.intr.fmuladd(%462, %260, %423)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %464 = llvm.extractelement %305[%33 : i64] : vector<64xf32>
    %465 = llvm.mlir.undef : vector<8xf32>
    %466 = llvm.insertelement %464, %465[%61 : i32] : vector<8xf32>
    %467 = llvm.shufflevector %466, %465 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %468 = llvm.intr.fmuladd(%467, %260, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %469 = llvm.extractelement %305[%32 : i64] : vector<64xf32>
    %470 = llvm.mlir.undef : vector<8xf32>
    %471 = llvm.insertelement %469, %470[%61 : i32] : vector<8xf32>
    %472 = llvm.shufflevector %471, %470 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %473 = llvm.intr.fmuladd(%472, %260, %433)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %474 = llvm.extractelement %305[%31 : i64] : vector<64xf32>
    %475 = llvm.mlir.undef : vector<8xf32>
    %476 = llvm.insertelement %474, %475[%61 : i32] : vector<8xf32>
    %477 = llvm.shufflevector %476, %475 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %478 = llvm.intr.fmuladd(%477, %267, %438)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %479 = llvm.extractelement %305[%30 : i64] : vector<64xf32>
    %480 = llvm.mlir.undef : vector<8xf32>
    %481 = llvm.insertelement %479, %480[%61 : i32] : vector<8xf32>
    %482 = llvm.shufflevector %481, %480 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %483 = llvm.intr.fmuladd(%482, %267, %443)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %484 = llvm.extractelement %305[%29 : i64] : vector<64xf32>
    %485 = llvm.mlir.undef : vector<8xf32>
    %486 = llvm.insertelement %484, %485[%61 : i32] : vector<8xf32>
    %487 = llvm.shufflevector %486, %485 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %488 = llvm.intr.fmuladd(%487, %267, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %489 = llvm.extractelement %305[%28 : i64] : vector<64xf32>
    %490 = llvm.mlir.undef : vector<8xf32>
    %491 = llvm.insertelement %489, %490[%61 : i32] : vector<8xf32>
    %492 = llvm.shufflevector %491, %490 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %493 = llvm.intr.fmuladd(%492, %267, %453)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %494 = llvm.extractelement %305[%27 : i64] : vector<64xf32>
    %495 = llvm.mlir.undef : vector<8xf32>
    %496 = llvm.insertelement %494, %495[%61 : i32] : vector<8xf32>
    %497 = llvm.shufflevector %496, %495 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %498 = llvm.intr.fmuladd(%497, %267, %458)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %499 = llvm.extractelement %305[%26 : i64] : vector<64xf32>
    %500 = llvm.mlir.undef : vector<8xf32>
    %501 = llvm.insertelement %499, %500[%61 : i32] : vector<8xf32>
    %502 = llvm.shufflevector %501, %500 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %503 = llvm.intr.fmuladd(%502, %267, %463)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %504 = llvm.extractelement %305[%25 : i64] : vector<64xf32>
    %505 = llvm.mlir.undef : vector<8xf32>
    %506 = llvm.insertelement %504, %505[%61 : i32] : vector<8xf32>
    %507 = llvm.shufflevector %506, %505 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %508 = llvm.intr.fmuladd(%507, %267, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %509 = llvm.extractelement %305[%24 : i64] : vector<64xf32>
    %510 = llvm.mlir.undef : vector<8xf32>
    %511 = llvm.insertelement %509, %510[%61 : i32] : vector<8xf32>
    %512 = llvm.shufflevector %511, %510 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %513 = llvm.intr.fmuladd(%512, %267, %473)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %514 = llvm.extractelement %305[%23 : i64] : vector<64xf32>
    %515 = llvm.mlir.undef : vector<8xf32>
    %516 = llvm.insertelement %514, %515[%61 : i32] : vector<8xf32>
    %517 = llvm.shufflevector %516, %515 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %518 = llvm.intr.fmuladd(%517, %274, %478)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %519 = llvm.extractelement %305[%22 : i64] : vector<64xf32>
    %520 = llvm.mlir.undef : vector<8xf32>
    %521 = llvm.insertelement %519, %520[%61 : i32] : vector<8xf32>
    %522 = llvm.shufflevector %521, %520 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %523 = llvm.intr.fmuladd(%522, %274, %483)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %524 = llvm.extractelement %305[%21 : i64] : vector<64xf32>
    %525 = llvm.mlir.undef : vector<8xf32>
    %526 = llvm.insertelement %524, %525[%61 : i32] : vector<8xf32>
    %527 = llvm.shufflevector %526, %525 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %528 = llvm.intr.fmuladd(%527, %274, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %529 = llvm.extractelement %305[%20 : i64] : vector<64xf32>
    %530 = llvm.mlir.undef : vector<8xf32>
    %531 = llvm.insertelement %529, %530[%61 : i32] : vector<8xf32>
    %532 = llvm.shufflevector %531, %530 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %533 = llvm.intr.fmuladd(%532, %274, %493)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %534 = llvm.extractelement %305[%19 : i64] : vector<64xf32>
    %535 = llvm.mlir.undef : vector<8xf32>
    %536 = llvm.insertelement %534, %535[%61 : i32] : vector<8xf32>
    %537 = llvm.shufflevector %536, %535 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %538 = llvm.intr.fmuladd(%537, %274, %498)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %539 = llvm.extractelement %305[%18 : i64] : vector<64xf32>
    %540 = llvm.mlir.undef : vector<8xf32>
    %541 = llvm.insertelement %539, %540[%61 : i32] : vector<8xf32>
    %542 = llvm.shufflevector %541, %540 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %543 = llvm.intr.fmuladd(%542, %274, %503)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %544 = llvm.extractelement %305[%17 : i64] : vector<64xf32>
    %545 = llvm.mlir.undef : vector<8xf32>
    %546 = llvm.insertelement %544, %545[%61 : i32] : vector<8xf32>
    %547 = llvm.shufflevector %546, %545 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %548 = llvm.intr.fmuladd(%547, %274, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %549 = llvm.extractelement %305[%16 : i64] : vector<64xf32>
    %550 = llvm.mlir.undef : vector<8xf32>
    %551 = llvm.insertelement %549, %550[%61 : i32] : vector<8xf32>
    %552 = llvm.shufflevector %551, %550 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %553 = llvm.intr.fmuladd(%552, %274, %513)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %554 = llvm.extractelement %305[%15 : i64] : vector<64xf32>
    %555 = llvm.mlir.undef : vector<8xf32>
    %556 = llvm.insertelement %554, %555[%61 : i32] : vector<8xf32>
    %557 = llvm.shufflevector %556, %555 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %558 = llvm.intr.fmuladd(%557, %281, %518)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %559 = llvm.extractelement %305[%14 : i64] : vector<64xf32>
    %560 = llvm.mlir.undef : vector<8xf32>
    %561 = llvm.insertelement %559, %560[%61 : i32] : vector<8xf32>
    %562 = llvm.shufflevector %561, %560 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %563 = llvm.intr.fmuladd(%562, %281, %523)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %564 = llvm.extractelement %305[%13 : i64] : vector<64xf32>
    %565 = llvm.mlir.undef : vector<8xf32>
    %566 = llvm.insertelement %564, %565[%61 : i32] : vector<8xf32>
    %567 = llvm.shufflevector %566, %565 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %568 = llvm.intr.fmuladd(%567, %281, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %569 = llvm.extractelement %305[%12 : i64] : vector<64xf32>
    %570 = llvm.mlir.undef : vector<8xf32>
    %571 = llvm.insertelement %569, %570[%61 : i32] : vector<8xf32>
    %572 = llvm.shufflevector %571, %570 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %573 = llvm.intr.fmuladd(%572, %281, %533)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %574 = llvm.extractelement %305[%11 : i64] : vector<64xf32>
    %575 = llvm.mlir.undef : vector<8xf32>
    %576 = llvm.insertelement %574, %575[%61 : i32] : vector<8xf32>
    %577 = llvm.shufflevector %576, %575 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %578 = llvm.intr.fmuladd(%577, %281, %538)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %579 = llvm.extractelement %305[%10 : i64] : vector<64xf32>
    %580 = llvm.mlir.undef : vector<8xf32>
    %581 = llvm.insertelement %579, %580[%61 : i32] : vector<8xf32>
    %582 = llvm.shufflevector %581, %580 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %583 = llvm.intr.fmuladd(%582, %281, %543)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %584 = llvm.extractelement %305[%9 : i64] : vector<64xf32>
    %585 = llvm.mlir.undef : vector<8xf32>
    %586 = llvm.insertelement %584, %585[%61 : i32] : vector<8xf32>
    %587 = llvm.shufflevector %586, %585 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %588 = llvm.intr.fmuladd(%587, %281, %548)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %589 = llvm.extractelement %305[%8 : i64] : vector<64xf32>
    %590 = llvm.mlir.undef : vector<8xf32>
    %591 = llvm.insertelement %589, %590[%61 : i32] : vector<8xf32>
    %592 = llvm.shufflevector %591, %590 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %593 = llvm.intr.fmuladd(%592, %281, %553)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %594 = llvm.extractelement %305[%7 : i64] : vector<64xf32>
    %595 = llvm.mlir.undef : vector<8xf32>
    %596 = llvm.insertelement %594, %595[%61 : i32] : vector<8xf32>
    %597 = llvm.shufflevector %596, %595 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %598 = llvm.intr.fmuladd(%597, %288, %558)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %599 = llvm.insertvalue %598, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %600 = llvm.extractelement %305[%6 : i64] : vector<64xf32>
    %601 = llvm.mlir.undef : vector<8xf32>
    %602 = llvm.insertelement %600, %601[%61 : i32] : vector<8xf32>
    %603 = llvm.shufflevector %602, %601 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %604 = llvm.intr.fmuladd(%603, %288, %563)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %605 = llvm.insertvalue %604, %599[1] : !llvm.array<8 x vector<8xf32>> 
    %606 = llvm.extractelement %305[%5 : i64] : vector<64xf32>
    %607 = llvm.mlir.undef : vector<8xf32>
    %608 = llvm.insertelement %606, %607[%61 : i32] : vector<8xf32>
    %609 = llvm.shufflevector %608, %607 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %610 = llvm.intr.fmuladd(%609, %288, %568)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %611 = llvm.insertvalue %610, %605[2] : !llvm.array<8 x vector<8xf32>> 
    %612 = llvm.extractelement %305[%4 : i64] : vector<64xf32>
    %613 = llvm.mlir.undef : vector<8xf32>
    %614 = llvm.insertelement %612, %613[%61 : i32] : vector<8xf32>
    %615 = llvm.shufflevector %614, %613 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %616 = llvm.intr.fmuladd(%615, %288, %573)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %617 = llvm.insertvalue %616, %611[3] : !llvm.array<8 x vector<8xf32>> 
    %618 = llvm.extractelement %305[%3 : i64] : vector<64xf32>
    %619 = llvm.mlir.undef : vector<8xf32>
    %620 = llvm.insertelement %618, %619[%61 : i32] : vector<8xf32>
    %621 = llvm.shufflevector %620, %619 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %622 = llvm.intr.fmuladd(%621, %288, %578)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %623 = llvm.insertvalue %622, %617[4] : !llvm.array<8 x vector<8xf32>> 
    %624 = llvm.extractelement %305[%2 : i64] : vector<64xf32>
    %625 = llvm.mlir.undef : vector<8xf32>
    %626 = llvm.insertelement %624, %625[%61 : i32] : vector<8xf32>
    %627 = llvm.shufflevector %626, %625 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %628 = llvm.intr.fmuladd(%627, %288, %583)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %629 = llvm.insertvalue %628, %623[5] : !llvm.array<8 x vector<8xf32>> 
    %630 = llvm.extractelement %305[%1 : i64] : vector<64xf32>
    %631 = llvm.mlir.undef : vector<8xf32>
    %632 = llvm.insertelement %630, %631[%61 : i32] : vector<8xf32>
    %633 = llvm.shufflevector %632, %631 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %634 = llvm.intr.fmuladd(%633, %288, %588)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %635 = llvm.insertvalue %634, %629[6] : !llvm.array<8 x vector<8xf32>> 
    %636 = llvm.extractelement %305[%0 : i64] : vector<64xf32>
    %637 = llvm.mlir.undef : vector<8xf32>
    %638 = llvm.insertelement %636, %637[%61 : i32] : vector<8xf32>
    %639 = llvm.shufflevector %638, %637 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %640 = llvm.intr.fmuladd(%639, %288, %593)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %641 = llvm.insertvalue %640, %635[7] : !llvm.array<8 x vector<8xf32>> 
    %642 = llvm.add %183, %79  : i64
    llvm.br ^bb5(%642, %641 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb7:  // pred: ^bb5
    %643 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %644 = llvm.mul %116, %71  : i64
    %645 = llvm.add %115, %644  : i64
    %646 = llvm.add %645, %125  : i64
    %647 = llvm.getelementptr %101[%646] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %648 = llvm.bitcast %647 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %643, %648 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %649 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %650 = llvm.mul %118, %71  : i64
    %651 = llvm.add %115, %650  : i64
    %652 = llvm.add %651, %125  : i64
    %653 = llvm.getelementptr %101[%652] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %654 = llvm.bitcast %653 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %649, %654 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %655 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %656 = llvm.mul %119, %71  : i64
    %657 = llvm.add %115, %656  : i64
    %658 = llvm.add %657, %125  : i64
    %659 = llvm.getelementptr %101[%658] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %660 = llvm.bitcast %659 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %655, %660 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %661 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %662 = llvm.mul %120, %71  : i64
    %663 = llvm.add %115, %662  : i64
    %664 = llvm.add %663, %125  : i64
    %665 = llvm.getelementptr %101[%664] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %666 = llvm.bitcast %665 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %661, %666 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %667 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %668 = llvm.mul %121, %71  : i64
    %669 = llvm.add %115, %668  : i64
    %670 = llvm.add %669, %125  : i64
    %671 = llvm.getelementptr %101[%670] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %672 = llvm.bitcast %671 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %667, %672 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %673 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %674 = llvm.mul %122, %71  : i64
    %675 = llvm.add %115, %674  : i64
    %676 = llvm.add %675, %125  : i64
    %677 = llvm.getelementptr %101[%676] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %678 = llvm.bitcast %677 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %673, %678 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %679 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %680 = llvm.mul %123, %71  : i64
    %681 = llvm.add %115, %680  : i64
    %682 = llvm.add %681, %125  : i64
    %683 = llvm.getelementptr %101[%682] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %684 = llvm.bitcast %683 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %679, %684 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %685 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %686 = llvm.mul %124, %71  : i64
    %687 = llvm.add %115, %686  : i64
    %688 = llvm.add %687, %125  : i64
    %689 = llvm.getelementptr %101[%688] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %690 = llvm.bitcast %689 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %685, %690 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %691 = llvm.add %125, %79  : i64
    llvm.br ^bb3(%691 : i64)
  ^bb8:  // pred: ^bb3
    %692 = llvm.add %116, %79  : i64
    llvm.br ^bb1(%692 : i64)
  ^bb9:  // pred: ^bb1
    llvm.return %61 : i32
  }
}

// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(63 : i64) : i64
    %1 = llvm.mlir.constant(62 : i64) : i64
    %2 = llvm.mlir.constant(61 : i64) : i64
    %3 = llvm.mlir.constant(60 : i64) : i64
    %4 = llvm.mlir.constant(59 : i64) : i64
    %5 = llvm.mlir.constant(58 : i64) : i64
    %6 = llvm.mlir.constant(57 : i64) : i64
    %7 = llvm.mlir.constant(56 : i64) : i64
    %8 = llvm.mlir.constant(55 : i64) : i64
    %9 = llvm.mlir.constant(54 : i64) : i64
    %10 = llvm.mlir.constant(53 : i64) : i64
    %11 = llvm.mlir.constant(52 : i64) : i64
    %12 = llvm.mlir.constant(51 : i64) : i64
    %13 = llvm.mlir.constant(50 : i64) : i64
    %14 = llvm.mlir.constant(49 : i64) : i64
    %15 = llvm.mlir.constant(48 : i64) : i64
    %16 = llvm.mlir.constant(47 : i64) : i64
    %17 = llvm.mlir.constant(46 : i64) : i64
    %18 = llvm.mlir.constant(45 : i64) : i64
    %19 = llvm.mlir.constant(44 : i64) : i64
    %20 = llvm.mlir.constant(43 : i64) : i64
    %21 = llvm.mlir.constant(42 : i64) : i64
    %22 = llvm.mlir.constant(41 : i64) : i64
    %23 = llvm.mlir.constant(40 : i64) : i64
    %24 = llvm.mlir.constant(39 : i64) : i64
    %25 = llvm.mlir.constant(38 : i64) : i64
    %26 = llvm.mlir.constant(37 : i64) : i64
    %27 = llvm.mlir.constant(36 : i64) : i64
    %28 = llvm.mlir.constant(35 : i64) : i64
    %29 = llvm.mlir.constant(34 : i64) : i64
    %30 = llvm.mlir.constant(33 : i64) : i64
    %31 = llvm.mlir.constant(32 : i64) : i64
    %32 = llvm.mlir.constant(31 : i64) : i64
    %33 = llvm.mlir.constant(30 : i64) : i64
    %34 = llvm.mlir.constant(29 : i64) : i64
    %35 = llvm.mlir.constant(28 : i64) : i64
    %36 = llvm.mlir.constant(27 : i64) : i64
    %37 = llvm.mlir.constant(26 : i64) : i64
    %38 = llvm.mlir.constant(25 : i64) : i64
    %39 = llvm.mlir.constant(24 : i64) : i64
    %40 = llvm.mlir.constant(23 : i64) : i64
    %41 = llvm.mlir.constant(22 : i64) : i64
    %42 = llvm.mlir.constant(21 : i64) : i64
    %43 = llvm.mlir.constant(20 : i64) : i64
    %44 = llvm.mlir.constant(19 : i64) : i64
    %45 = llvm.mlir.constant(18 : i64) : i64
    %46 = llvm.mlir.constant(17 : i64) : i64
    %47 = llvm.mlir.constant(16 : i64) : i64
    %48 = llvm.mlir.constant(15 : i64) : i64
    %49 = llvm.mlir.constant(14 : i64) : i64
    %50 = llvm.mlir.constant(13 : i64) : i64
    %51 = llvm.mlir.constant(12 : i64) : i64
    %52 = llvm.mlir.constant(11 : i64) : i64
    %53 = llvm.mlir.constant(10 : i64) : i64
    %54 = llvm.mlir.constant(9 : i64) : i64
    %55 = llvm.mlir.constant(8 : i64) : i64
    %56 = llvm.mlir.constant(7 : i64) : i64
    %57 = llvm.mlir.constant(6 : i64) : i64
    %58 = llvm.mlir.constant(5 : i64) : i64
    %59 = llvm.mlir.constant(4 : i64) : i64
    %60 = llvm.mlir.constant(3 : i64) : i64
    %61 = llvm.mlir.constant(0 : i32) : i32
    %62 = llvm.mlir.constant(7 : index) : i64
    %63 = llvm.mlir.constant(6 : index) : i64
    %64 = llvm.mlir.constant(5 : index) : i64
    %65 = llvm.mlir.constant(4 : index) : i64
    %66 = llvm.mlir.constant(3 : index) : i64
    %67 = llvm.mlir.constant(2 : index) : i64
    %68 = llvm.mlir.constant(32768 : index) : i64
    %69 = llvm.mlir.constant(8192 : index) : i64
    %70 = llvm.mlir.constant(2 : i64) : i64
    %71 = llvm.mlir.constant(1024 : index) : i64
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.constant(63 : index) : i64
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.mlir.constant(0 : i64) : i64
    %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
    %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
    %78 = llvm.mlir.constant(256 : index) : i64
    %79 = llvm.mlir.constant(8 : index) : i64
    %80 = llvm.mlir.constant(32 : index) : i64
    %81 = llvm.mlir.constant(0 : index) : i64
    %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
    %87 = llvm.and %86, %73  : i64
    %88 = llvm.icmp "eq" %87, %81 : i64
    "llvm.intr.assume"(%88) : (i1) -> ()
    %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
    %95 = llvm.and %94, %73  : i64
    %96 = llvm.icmp "eq" %95, %81 : i64
    "llvm.intr.assume"(%96) : (i1) -> ()
    %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
    %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
    %103 = llvm.and %102, %73  : i64
    %104 = llvm.icmp "eq" %103, %81 : i64
    "llvm.intr.assume"(%104) : (i1) -> ()
    %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %107 = llvm.zext %106 : i32 to i64
    %108 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %109 = llvm.extractvalue %108[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %110 = llvm.zext %109 : i32 to i64
    %111 = llvm.mul %110, %69  : i64
    %112 = llvm.mul %107, %80  : i64
    %113 = llvm.mul %110, %68  : i64
    %114 = llvm.mul %107, %80  : i64
    %115 = llvm.add %113, %114  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb1(%116: i64):  // 2 preds: ^bb0, ^bb8
    %117 = llvm.icmp "slt" %116, %80 : i64
    llvm.cond_br %117, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %118 = llvm.add %116, %74  : i64
    %119 = llvm.add %116, %67  : i64
    %120 = llvm.add %116, %66  : i64
    %121 = llvm.add %116, %65  : i64
    %122 = llvm.add %116, %64  : i64
    %123 = llvm.add %116, %63  : i64
    %124 = llvm.add %116, %62  : i64
    llvm.br ^bb3(%81 : i64)
  ^bb3(%125: i64):  // 2 preds: ^bb2, ^bb7
    %126 = llvm.icmp "slt" %125, %80 : i64
    llvm.cond_br %126, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %127 = llvm.mul %116, %71  : i64
    %128 = llvm.add %115, %127  : i64
    %129 = llvm.add %128, %125  : i64
    %130 = llvm.getelementptr %101[%129] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %131 = llvm.bitcast %130 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %132 = llvm.load %131 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %133 = llvm.insertvalue %132, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %134 = llvm.mul %118, %71  : i64
    %135 = llvm.add %115, %134  : i64
    %136 = llvm.add %135, %125  : i64
    %137 = llvm.getelementptr %101[%136] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %138 = llvm.bitcast %137 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %139 = llvm.load %138 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %140 = llvm.insertvalue %139, %133[1] : !llvm.array<8 x vector<8xf32>> 
    %141 = llvm.mul %119, %71  : i64
    %142 = llvm.add %115, %141  : i64
    %143 = llvm.add %142, %125  : i64
    %144 = llvm.getelementptr %101[%143] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %145 = llvm.bitcast %144 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %146 = llvm.load %145 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %147 = llvm.insertvalue %146, %140[2] : !llvm.array<8 x vector<8xf32>> 
    %148 = llvm.mul %120, %71  : i64
    %149 = llvm.add %115, %148  : i64
    %150 = llvm.add %149, %125  : i64
    %151 = llvm.getelementptr %101[%150] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %152 = llvm.bitcast %151 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %153 = llvm.load %152 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %154 = llvm.insertvalue %153, %147[3] : !llvm.array<8 x vector<8xf32>> 
    %155 = llvm.mul %121, %71  : i64
    %156 = llvm.add %115, %155  : i64
    %157 = llvm.add %156, %125  : i64
    %158 = llvm.getelementptr %101[%157] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %159 = llvm.bitcast %158 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %160 = llvm.load %159 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %161 = llvm.insertvalue %160, %154[4] : !llvm.array<8 x vector<8xf32>> 
    %162 = llvm.mul %122, %71  : i64
    %163 = llvm.add %115, %162  : i64
    %164 = llvm.add %163, %125  : i64
    %165 = llvm.getelementptr %101[%164] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %166 = llvm.bitcast %165 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %167 = llvm.load %166 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %168 = llvm.insertvalue %167, %161[5] : !llvm.array<8 x vector<8xf32>> 
    %169 = llvm.mul %123, %71  : i64
    %170 = llvm.add %115, %169  : i64
    %171 = llvm.add %170, %125  : i64
    %172 = llvm.getelementptr %101[%171] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %173 = llvm.bitcast %172 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %174 = llvm.load %173 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %175 = llvm.insertvalue %174, %168[6] : !llvm.array<8 x vector<8xf32>> 
    %176 = llvm.mul %124, %71  : i64
    %177 = llvm.add %115, %176  : i64
    %178 = llvm.add %177, %125  : i64
    %179 = llvm.getelementptr %101[%178] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %180 = llvm.bitcast %179 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %181 = llvm.load %180 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %182 = llvm.insertvalue %181, %175[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.br ^bb5(%81, %182 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb5(%183: i64, %184: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
    %185 = llvm.icmp "slt" %183, %78 : i64
    llvm.cond_br %185, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %186 = llvm.mul %116, %78  : i64
    %187 = llvm.add %111, %186  : i64
    %188 = llvm.add %187, %183  : i64
    %189 = llvm.getelementptr %85[%188] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %190 = llvm.bitcast %189 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %191 = llvm.load %190 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %192 = llvm.mul %118, %78  : i64
    %193 = llvm.add %111, %192  : i64
    %194 = llvm.add %193, %183  : i64
    %195 = llvm.getelementptr %85[%194] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %196 = llvm.bitcast %195 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %197 = llvm.load %196 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %198 = llvm.mul %119, %78  : i64
    %199 = llvm.add %111, %198  : i64
    %200 = llvm.add %199, %183  : i64
    %201 = llvm.getelementptr %85[%200] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %202 = llvm.bitcast %201 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %203 = llvm.load %202 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %204 = llvm.mul %120, %78  : i64
    %205 = llvm.add %111, %204  : i64
    %206 = llvm.add %205, %183  : i64
    %207 = llvm.getelementptr %85[%206] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %208 = llvm.bitcast %207 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %209 = llvm.load %208 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %210 = llvm.mul %121, %78  : i64
    %211 = llvm.add %111, %210  : i64
    %212 = llvm.add %211, %183  : i64
    %213 = llvm.getelementptr %85[%212] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %214 = llvm.bitcast %213 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %215 = llvm.load %214 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %216 = llvm.mul %122, %78  : i64
    %217 = llvm.add %111, %216  : i64
    %218 = llvm.add %217, %183  : i64
    %219 = llvm.getelementptr %85[%218] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %220 = llvm.bitcast %219 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %221 = llvm.load %220 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %222 = llvm.mul %123, %78  : i64
    %223 = llvm.add %111, %222  : i64
    %224 = llvm.add %223, %183  : i64
    %225 = llvm.getelementptr %85[%224] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %226 = llvm.bitcast %225 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %227 = llvm.load %226 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %228 = llvm.mul %124, %78  : i64
    %229 = llvm.add %111, %228  : i64
    %230 = llvm.add %229, %183  : i64
    %231 = llvm.getelementptr %85[%230] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %232 = llvm.bitcast %231 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %233 = llvm.load %232 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %234 = llvm.mul %183, %71  : i64
    %235 = llvm.add %112, %234  : i64
    %236 = llvm.add %235, %125  : i64
    %237 = llvm.getelementptr %93[%236] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %238 = llvm.bitcast %237 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %239 = llvm.load %238 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %240 = llvm.add %183, %74  : i64
    %241 = llvm.mul %240, %71  : i64
    %242 = llvm.add %112, %241  : i64
    %243 = llvm.add %242, %125  : i64
    %244 = llvm.getelementptr %93[%243] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %245 = llvm.bitcast %244 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %246 = llvm.load %245 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %247 = llvm.add %183, %67  : i64
    %248 = llvm.mul %247, %71  : i64
    %249 = llvm.add %112, %248  : i64
    %250 = llvm.add %249, %125  : i64
    %251 = llvm.getelementptr %93[%250] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %252 = llvm.bitcast %251 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %253 = llvm.load %252 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %254 = llvm.add %183, %66  : i64
    %255 = llvm.mul %254, %71  : i64
    %256 = llvm.add %112, %255  : i64
    %257 = llvm.add %256, %125  : i64
    %258 = llvm.getelementptr %93[%257] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %259 = llvm.bitcast %258 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %260 = llvm.load %259 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %261 = llvm.add %183, %65  : i64
    %262 = llvm.mul %261, %71  : i64
    %263 = llvm.add %112, %262  : i64
    %264 = llvm.add %263, %125  : i64
    %265 = llvm.getelementptr %93[%264] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %266 = llvm.bitcast %265 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %267 = llvm.load %266 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %268 = llvm.add %183, %64  : i64
    %269 = llvm.mul %268, %71  : i64
    %270 = llvm.add %112, %269  : i64
    %271 = llvm.add %270, %125  : i64
    %272 = llvm.getelementptr %93[%271] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %273 = llvm.bitcast %272 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %274 = llvm.load %273 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %275 = llvm.add %183, %63  : i64
    %276 = llvm.mul %275, %71  : i64
    %277 = llvm.add %112, %276  : i64
    %278 = llvm.add %277, %125  : i64
    %279 = llvm.getelementptr %93[%278] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %280 = llvm.bitcast %279 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %281 = llvm.load %280 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %282 = llvm.add %183, %62  : i64
    %283 = llvm.mul %282, %71  : i64
    %284 = llvm.add %112, %283  : i64
    %285 = llvm.add %284, %125  : i64
    %286 = llvm.getelementptr %93[%285] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %287 = llvm.bitcast %286 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %288 = llvm.load %287 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %289 = llvm.shufflevector %191, %191 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %290 = llvm.shufflevector %289, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %291 = llvm.shufflevector %197, %197 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %293 = llvm.shufflevector %203, %203 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %295 = llvm.shufflevector %209, %209 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %297 = llvm.shufflevector %215, %215 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %299 = llvm.shufflevector %221, %221 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %301 = llvm.shufflevector %227, %227 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %303 = llvm.shufflevector %233, %233 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %304 = llvm.shufflevector %303, %302 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
    %305 = llvm.shufflevector %304, %304 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
    %306 = llvm.extractelement %305[%75 : i64] : vector<64xf32>
    %307 = llvm.mlir.undef : vector<8xf32>
    %308 = llvm.insertelement %306, %307[%61 : i32] : vector<8xf32>
    %309 = llvm.shufflevector %308, %307 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %310 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %311 = llvm.intr.fmuladd(%309, %239, %310)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %312 = llvm.extractelement %305[%72 : i64] : vector<64xf32>
    %313 = llvm.mlir.undef : vector<8xf32>
    %314 = llvm.insertelement %312, %313[%61 : i32] : vector<8xf32>
    %315 = llvm.shufflevector %314, %313 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %316 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %317 = llvm.intr.fmuladd(%315, %239, %316)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %318 = llvm.extractelement %305[%70 : i64] : vector<64xf32>
    %319 = llvm.mlir.undef : vector<8xf32>
    %320 = llvm.insertelement %318, %319[%61 : i32] : vector<8xf32>
    %321 = llvm.shufflevector %320, %319 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %322 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %323 = llvm.intr.fmuladd(%321, %239, %322)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %324 = llvm.extractelement %305[%60 : i64] : vector<64xf32>
    %325 = llvm.mlir.undef : vector<8xf32>
    %326 = llvm.insertelement %324, %325[%61 : i32] : vector<8xf32>
    %327 = llvm.shufflevector %326, %325 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %328 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %329 = llvm.intr.fmuladd(%327, %239, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %330 = llvm.extractelement %305[%59 : i64] : vector<64xf32>
    %331 = llvm.mlir.undef : vector<8xf32>
    %332 = llvm.insertelement %330, %331[%61 : i32] : vector<8xf32>
    %333 = llvm.shufflevector %332, %331 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %334 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %335 = llvm.intr.fmuladd(%333, %239, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %336 = llvm.extractelement %305[%58 : i64] : vector<64xf32>
    %337 = llvm.mlir.undef : vector<8xf32>
    %338 = llvm.insertelement %336, %337[%61 : i32] : vector<8xf32>
    %339 = llvm.shufflevector %338, %337 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %340 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %341 = llvm.intr.fmuladd(%339, %239, %340)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %342 = llvm.extractelement %305[%57 : i64] : vector<64xf32>
    %343 = llvm.mlir.undef : vector<8xf32>
    %344 = llvm.insertelement %342, %343[%61 : i32] : vector<8xf32>
    %345 = llvm.shufflevector %344, %343 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %346 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %347 = llvm.intr.fmuladd(%345, %239, %346)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %348 = llvm.extractelement %305[%56 : i64] : vector<64xf32>
    %349 = llvm.mlir.undef : vector<8xf32>
    %350 = llvm.insertelement %348, %349[%61 : i32] : vector<8xf32>
    %351 = llvm.shufflevector %350, %349 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %352 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %353 = llvm.intr.fmuladd(%351, %239, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %354 = llvm.extractelement %305[%55 : i64] : vector<64xf32>
    %355 = llvm.mlir.undef : vector<8xf32>
    %356 = llvm.insertelement %354, %355[%61 : i32] : vector<8xf32>
    %357 = llvm.shufflevector %356, %355 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %358 = llvm.intr.fmuladd(%357, %246, %311)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %359 = llvm.extractelement %305[%54 : i64] : vector<64xf32>
    %360 = llvm.mlir.undef : vector<8xf32>
    %361 = llvm.insertelement %359, %360[%61 : i32] : vector<8xf32>
    %362 = llvm.shufflevector %361, %360 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %363 = llvm.intr.fmuladd(%362, %246, %317)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %364 = llvm.extractelement %305[%53 : i64] : vector<64xf32>
    %365 = llvm.mlir.undef : vector<8xf32>
    %366 = llvm.insertelement %364, %365[%61 : i32] : vector<8xf32>
    %367 = llvm.shufflevector %366, %365 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %368 = llvm.intr.fmuladd(%367, %246, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %369 = llvm.extractelement %305[%52 : i64] : vector<64xf32>
    %370 = llvm.mlir.undef : vector<8xf32>
    %371 = llvm.insertelement %369, %370[%61 : i32] : vector<8xf32>
    %372 = llvm.shufflevector %371, %370 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %373 = llvm.intr.fmuladd(%372, %246, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %374 = llvm.extractelement %305[%51 : i64] : vector<64xf32>
    %375 = llvm.mlir.undef : vector<8xf32>
    %376 = llvm.insertelement %374, %375[%61 : i32] : vector<8xf32>
    %377 = llvm.shufflevector %376, %375 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %378 = llvm.intr.fmuladd(%377, %246, %335)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %379 = llvm.extractelement %305[%50 : i64] : vector<64xf32>
    %380 = llvm.mlir.undef : vector<8xf32>
    %381 = llvm.insertelement %379, %380[%61 : i32] : vector<8xf32>
    %382 = llvm.shufflevector %381, %380 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %383 = llvm.intr.fmuladd(%382, %246, %341)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %384 = llvm.extractelement %305[%49 : i64] : vector<64xf32>
    %385 = llvm.mlir.undef : vector<8xf32>
    %386 = llvm.insertelement %384, %385[%61 : i32] : vector<8xf32>
    %387 = llvm.shufflevector %386, %385 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %388 = llvm.intr.fmuladd(%387, %246, %347)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %389 = llvm.extractelement %305[%48 : i64] : vector<64xf32>
    %390 = llvm.mlir.undef : vector<8xf32>
    %391 = llvm.insertelement %389, %390[%61 : i32] : vector<8xf32>
    %392 = llvm.shufflevector %391, %390 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %393 = llvm.intr.fmuladd(%392, %246, %353)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %394 = llvm.extractelement %305[%47 : i64] : vector<64xf32>
    %395 = llvm.mlir.undef : vector<8xf32>
    %396 = llvm.insertelement %394, %395[%61 : i32] : vector<8xf32>
    %397 = llvm.shufflevector %396, %395 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %398 = llvm.intr.fmuladd(%397, %253, %358)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %399 = llvm.extractelement %305[%46 : i64] : vector<64xf32>
    %400 = llvm.mlir.undef : vector<8xf32>
    %401 = llvm.insertelement %399, %400[%61 : i32] : vector<8xf32>
    %402 = llvm.shufflevector %401, %400 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %403 = llvm.intr.fmuladd(%402, %253, %363)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %404 = llvm.extractelement %305[%45 : i64] : vector<64xf32>
    %405 = llvm.mlir.undef : vector<8xf32>
    %406 = llvm.insertelement %404, %405[%61 : i32] : vector<8xf32>
    %407 = llvm.shufflevector %406, %405 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %408 = llvm.intr.fmuladd(%407, %253, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %409 = llvm.extractelement %305[%44 : i64] : vector<64xf32>
    %410 = llvm.mlir.undef : vector<8xf32>
    %411 = llvm.insertelement %409, %410[%61 : i32] : vector<8xf32>
    %412 = llvm.shufflevector %411, %410 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %413 = llvm.intr.fmuladd(%412, %253, %373)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %414 = llvm.extractelement %305[%43 : i64] : vector<64xf32>
    %415 = llvm.mlir.undef : vector<8xf32>
    %416 = llvm.insertelement %414, %415[%61 : i32] : vector<8xf32>
    %417 = llvm.shufflevector %416, %415 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %418 = llvm.intr.fmuladd(%417, %253, %378)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %419 = llvm.extractelement %305[%42 : i64] : vector<64xf32>
    %420 = llvm.mlir.undef : vector<8xf32>
    %421 = llvm.insertelement %419, %420[%61 : i32] : vector<8xf32>
    %422 = llvm.shufflevector %421, %420 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %423 = llvm.intr.fmuladd(%422, %253, %383)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %424 = llvm.extractelement %305[%41 : i64] : vector<64xf32>
    %425 = llvm.mlir.undef : vector<8xf32>
    %426 = llvm.insertelement %424, %425[%61 : i32] : vector<8xf32>
    %427 = llvm.shufflevector %426, %425 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %428 = llvm.intr.fmuladd(%427, %253, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %429 = llvm.extractelement %305[%40 : i64] : vector<64xf32>
    %430 = llvm.mlir.undef : vector<8xf32>
    %431 = llvm.insertelement %429, %430[%61 : i32] : vector<8xf32>
    %432 = llvm.shufflevector %431, %430 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %433 = llvm.intr.fmuladd(%432, %253, %393)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %434 = llvm.extractelement %305[%39 : i64] : vector<64xf32>
    %435 = llvm.mlir.undef : vector<8xf32>
    %436 = llvm.insertelement %434, %435[%61 : i32] : vector<8xf32>
    %437 = llvm.shufflevector %436, %435 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %438 = llvm.intr.fmuladd(%437, %260, %398)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %439 = llvm.extractelement %305[%38 : i64] : vector<64xf32>
    %440 = llvm.mlir.undef : vector<8xf32>
    %441 = llvm.insertelement %439, %440[%61 : i32] : vector<8xf32>
    %442 = llvm.shufflevector %441, %440 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %443 = llvm.intr.fmuladd(%442, %260, %403)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %444 = llvm.extractelement %305[%37 : i64] : vector<64xf32>
    %445 = llvm.mlir.undef : vector<8xf32>
    %446 = llvm.insertelement %444, %445[%61 : i32] : vector<8xf32>
    %447 = llvm.shufflevector %446, %445 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %448 = llvm.intr.fmuladd(%447, %260, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %449 = llvm.extractelement %305[%36 : i64] : vector<64xf32>
    %450 = llvm.mlir.undef : vector<8xf32>
    %451 = llvm.insertelement %449, %450[%61 : i32] : vector<8xf32>
    %452 = llvm.shufflevector %451, %450 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %453 = llvm.intr.fmuladd(%452, %260, %413)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %454 = llvm.extractelement %305[%35 : i64] : vector<64xf32>
    %455 = llvm.mlir.undef : vector<8xf32>
    %456 = llvm.insertelement %454, %455[%61 : i32] : vector<8xf32>
    %457 = llvm.shufflevector %456, %455 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %458 = llvm.intr.fmuladd(%457, %260, %418)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %459 = llvm.extractelement %305[%34 : i64] : vector<64xf32>
    %460 = llvm.mlir.undef : vector<8xf32>
    %461 = llvm.insertelement %459, %460[%61 : i32] : vector<8xf32>
    %462 = llvm.shufflevector %461, %460 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %463 = llvm.intr.fmuladd(%462, %260, %423)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %464 = llvm.extractelement %305[%33 : i64] : vector<64xf32>
    %465 = llvm.mlir.undef : vector<8xf32>
    %466 = llvm.insertelement %464, %465[%61 : i32] : vector<8xf32>
    %467 = llvm.shufflevector %466, %465 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %468 = llvm.intr.fmuladd(%467, %260, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %469 = llvm.extractelement %305[%32 : i64] : vector<64xf32>
    %470 = llvm.mlir.undef : vector<8xf32>
    %471 = llvm.insertelement %469, %470[%61 : i32] : vector<8xf32>
    %472 = llvm.shufflevector %471, %470 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %473 = llvm.intr.fmuladd(%472, %260, %433)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %474 = llvm.extractelement %305[%31 : i64] : vector<64xf32>
    %475 = llvm.mlir.undef : vector<8xf32>
    %476 = llvm.insertelement %474, %475[%61 : i32] : vector<8xf32>
    %477 = llvm.shufflevector %476, %475 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %478 = llvm.intr.fmuladd(%477, %267, %438)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %479 = llvm.extractelement %305[%30 : i64] : vector<64xf32>
    %480 = llvm.mlir.undef : vector<8xf32>
    %481 = llvm.insertelement %479, %480[%61 : i32] : vector<8xf32>
    %482 = llvm.shufflevector %481, %480 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %483 = llvm.intr.fmuladd(%482, %267, %443)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %484 = llvm.extractelement %305[%29 : i64] : vector<64xf32>
    %485 = llvm.mlir.undef : vector<8xf32>
    %486 = llvm.insertelement %484, %485[%61 : i32] : vector<8xf32>
    %487 = llvm.shufflevector %486, %485 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %488 = llvm.intr.fmuladd(%487, %267, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %489 = llvm.extractelement %305[%28 : i64] : vector<64xf32>
    %490 = llvm.mlir.undef : vector<8xf32>
    %491 = llvm.insertelement %489, %490[%61 : i32] : vector<8xf32>
    %492 = llvm.shufflevector %491, %490 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %493 = llvm.intr.fmuladd(%492, %267, %453)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %494 = llvm.extractelement %305[%27 : i64] : vector<64xf32>
    %495 = llvm.mlir.undef : vector<8xf32>
    %496 = llvm.insertelement %494, %495[%61 : i32] : vector<8xf32>
    %497 = llvm.shufflevector %496, %495 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %498 = llvm.intr.fmuladd(%497, %267, %458)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %499 = llvm.extractelement %305[%26 : i64] : vector<64xf32>
    %500 = llvm.mlir.undef : vector<8xf32>
    %501 = llvm.insertelement %499, %500[%61 : i32] : vector<8xf32>
    %502 = llvm.shufflevector %501, %500 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %503 = llvm.intr.fmuladd(%502, %267, %463)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %504 = llvm.extractelement %305[%25 : i64] : vector<64xf32>
    %505 = llvm.mlir.undef : vector<8xf32>
    %506 = llvm.insertelement %504, %505[%61 : i32] : vector<8xf32>
    %507 = llvm.shufflevector %506, %505 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %508 = llvm.intr.fmuladd(%507, %267, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %509 = llvm.extractelement %305[%24 : i64] : vector<64xf32>
    %510 = llvm.mlir.undef : vector<8xf32>
    %511 = llvm.insertelement %509, %510[%61 : i32] : vector<8xf32>
    %512 = llvm.shufflevector %511, %510 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %513 = llvm.intr.fmuladd(%512, %267, %473)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %514 = llvm.extractelement %305[%23 : i64] : vector<64xf32>
    %515 = llvm.mlir.undef : vector<8xf32>
    %516 = llvm.insertelement %514, %515[%61 : i32] : vector<8xf32>
    %517 = llvm.shufflevector %516, %515 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %518 = llvm.intr.fmuladd(%517, %274, %478)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %519 = llvm.extractelement %305[%22 : i64] : vector<64xf32>
    %520 = llvm.mlir.undef : vector<8xf32>
    %521 = llvm.insertelement %519, %520[%61 : i32] : vector<8xf32>
    %522 = llvm.shufflevector %521, %520 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %523 = llvm.intr.fmuladd(%522, %274, %483)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %524 = llvm.extractelement %305[%21 : i64] : vector<64xf32>
    %525 = llvm.mlir.undef : vector<8xf32>
    %526 = llvm.insertelement %524, %525[%61 : i32] : vector<8xf32>
    %527 = llvm.shufflevector %526, %525 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %528 = llvm.intr.fmuladd(%527, %274, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %529 = llvm.extractelement %305[%20 : i64] : vector<64xf32>
    %530 = llvm.mlir.undef : vector<8xf32>
    %531 = llvm.insertelement %529, %530[%61 : i32] : vector<8xf32>
    %532 = llvm.shufflevector %531, %530 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %533 = llvm.intr.fmuladd(%532, %274, %493)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %534 = llvm.extractelement %305[%19 : i64] : vector<64xf32>
    %535 = llvm.mlir.undef : vector<8xf32>
    %536 = llvm.insertelement %534, %535[%61 : i32] : vector<8xf32>
    %537 = llvm.shufflevector %536, %535 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %538 = llvm.intr.fmuladd(%537, %274, %498)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %539 = llvm.extractelement %305[%18 : i64] : vector<64xf32>
    %540 = llvm.mlir.undef : vector<8xf32>
    %541 = llvm.insertelement %539, %540[%61 : i32] : vector<8xf32>
    %542 = llvm.shufflevector %541, %540 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %543 = llvm.intr.fmuladd(%542, %274, %503)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %544 = llvm.extractelement %305[%17 : i64] : vector<64xf32>
    %545 = llvm.mlir.undef : vector<8xf32>
    %546 = llvm.insertelement %544, %545[%61 : i32] : vector<8xf32>
    %547 = llvm.shufflevector %546, %545 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %548 = llvm.intr.fmuladd(%547, %274, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %549 = llvm.extractelement %305[%16 : i64] : vector<64xf32>
    %550 = llvm.mlir.undef : vector<8xf32>
    %551 = llvm.insertelement %549, %550[%61 : i32] : vector<8xf32>
    %552 = llvm.shufflevector %551, %550 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %553 = llvm.intr.fmuladd(%552, %274, %513)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %554 = llvm.extractelement %305[%15 : i64] : vector<64xf32>
    %555 = llvm.mlir.undef : vector<8xf32>
    %556 = llvm.insertelement %554, %555[%61 : i32] : vector<8xf32>
    %557 = llvm.shufflevector %556, %555 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %558 = llvm.intr.fmuladd(%557, %281, %518)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %559 = llvm.extractelement %305[%14 : i64] : vector<64xf32>
    %560 = llvm.mlir.undef : vector<8xf32>
    %561 = llvm.insertelement %559, %560[%61 : i32] : vector<8xf32>
    %562 = llvm.shufflevector %561, %560 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %563 = llvm.intr.fmuladd(%562, %281, %523)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %564 = llvm.extractelement %305[%13 : i64] : vector<64xf32>
    %565 = llvm.mlir.undef : vector<8xf32>
    %566 = llvm.insertelement %564, %565[%61 : i32] : vector<8xf32>
    %567 = llvm.shufflevector %566, %565 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %568 = llvm.intr.fmuladd(%567, %281, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %569 = llvm.extractelement %305[%12 : i64] : vector<64xf32>
    %570 = llvm.mlir.undef : vector<8xf32>
    %571 = llvm.insertelement %569, %570[%61 : i32] : vector<8xf32>
    %572 = llvm.shufflevector %571, %570 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %573 = llvm.intr.fmuladd(%572, %281, %533)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %574 = llvm.extractelement %305[%11 : i64] : vector<64xf32>
    %575 = llvm.mlir.undef : vector<8xf32>
    %576 = llvm.insertelement %574, %575[%61 : i32] : vector<8xf32>
    %577 = llvm.shufflevector %576, %575 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %578 = llvm.intr.fmuladd(%577, %281, %538)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %579 = llvm.extractelement %305[%10 : i64] : vector<64xf32>
    %580 = llvm.mlir.undef : vector<8xf32>
    %581 = llvm.insertelement %579, %580[%61 : i32] : vector<8xf32>
    %582 = llvm.shufflevector %581, %580 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %583 = llvm.intr.fmuladd(%582, %281, %543)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %584 = llvm.extractelement %305[%9 : i64] : vector<64xf32>
    %585 = llvm.mlir.undef : vector<8xf32>
    %586 = llvm.insertelement %584, %585[%61 : i32] : vector<8xf32>
    %587 = llvm.shufflevector %586, %585 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %588 = llvm.intr.fmuladd(%587, %281, %548)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %589 = llvm.extractelement %305[%8 : i64] : vector<64xf32>
    %590 = llvm.mlir.undef : vector<8xf32>
    %591 = llvm.insertelement %589, %590[%61 : i32] : vector<8xf32>
    %592 = llvm.shufflevector %591, %590 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %593 = llvm.intr.fmuladd(%592, %281, %553)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %594 = llvm.extractelement %305[%7 : i64] : vector<64xf32>
    %595 = llvm.mlir.undef : vector<8xf32>
    %596 = llvm.insertelement %594, %595[%61 : i32] : vector<8xf32>
    %597 = llvm.shufflevector %596, %595 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %598 = llvm.intr.fmuladd(%597, %288, %558)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %599 = llvm.insertvalue %598, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %600 = llvm.extractelement %305[%6 : i64] : vector<64xf32>
    %601 = llvm.mlir.undef : vector<8xf32>
    %602 = llvm.insertelement %600, %601[%61 : i32] : vector<8xf32>
    %603 = llvm.shufflevector %602, %601 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %604 = llvm.intr.fmuladd(%603, %288, %563)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %605 = llvm.insertvalue %604, %599[1] : !llvm.array<8 x vector<8xf32>> 
    %606 = llvm.extractelement %305[%5 : i64] : vector<64xf32>
    %607 = llvm.mlir.undef : vector<8xf32>
    %608 = llvm.insertelement %606, %607[%61 : i32] : vector<8xf32>
    %609 = llvm.shufflevector %608, %607 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %610 = llvm.intr.fmuladd(%609, %288, %568)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %611 = llvm.insertvalue %610, %605[2] : !llvm.array<8 x vector<8xf32>> 
    %612 = llvm.extractelement %305[%4 : i64] : vector<64xf32>
    %613 = llvm.mlir.undef : vector<8xf32>
    %614 = llvm.insertelement %612, %613[%61 : i32] : vector<8xf32>
    %615 = llvm.shufflevector %614, %613 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %616 = llvm.intr.fmuladd(%615, %288, %573)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %617 = llvm.insertvalue %616, %611[3] : !llvm.array<8 x vector<8xf32>> 
    %618 = llvm.extractelement %305[%3 : i64] : vector<64xf32>
    %619 = llvm.mlir.undef : vector<8xf32>
    %620 = llvm.insertelement %618, %619[%61 : i32] : vector<8xf32>
    %621 = llvm.shufflevector %620, %619 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %622 = llvm.intr.fmuladd(%621, %288, %578)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %623 = llvm.insertvalue %622, %617[4] : !llvm.array<8 x vector<8xf32>> 
    %624 = llvm.extractelement %305[%2 : i64] : vector<64xf32>
    %625 = llvm.mlir.undef : vector<8xf32>
    %626 = llvm.insertelement %624, %625[%61 : i32] : vector<8xf32>
    %627 = llvm.shufflevector %626, %625 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %628 = llvm.intr.fmuladd(%627, %288, %583)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %629 = llvm.insertvalue %628, %623[5] : !llvm.array<8 x vector<8xf32>> 
    %630 = llvm.extractelement %305[%1 : i64] : vector<64xf32>
    %631 = llvm.mlir.undef : vector<8xf32>
    %632 = llvm.insertelement %630, %631[%61 : i32] : vector<8xf32>
    %633 = llvm.shufflevector %632, %631 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %634 = llvm.intr.fmuladd(%633, %288, %588)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %635 = llvm.insertvalue %634, %629[6] : !llvm.array<8 x vector<8xf32>> 
    %636 = llvm.extractelement %305[%0 : i64] : vector<64xf32>
    %637 = llvm.mlir.undef : vector<8xf32>
    %638 = llvm.insertelement %636, %637[%61 : i32] : vector<8xf32>
    %639 = llvm.shufflevector %638, %637 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %640 = llvm.intr.fmuladd(%639, %288, %593)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %641 = llvm.insertvalue %640, %635[7] : !llvm.array<8 x vector<8xf32>> 
    %642 = llvm.add %183, %79  : i64
    llvm.br ^bb5(%642, %641 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb7:  // pred: ^bb5
    %643 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %644 = llvm.mul %116, %71  : i64
    %645 = llvm.add %115, %644  : i64
    %646 = llvm.add %645, %125  : i64
    %647 = llvm.getelementptr %101[%646] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %648 = llvm.bitcast %647 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %643, %648 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %649 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %650 = llvm.mul %118, %71  : i64
    %651 = llvm.add %115, %650  : i64
    %652 = llvm.add %651, %125  : i64
    %653 = llvm.getelementptr %101[%652] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %654 = llvm.bitcast %653 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %649, %654 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %655 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %656 = llvm.mul %119, %71  : i64
    %657 = llvm.add %115, %656  : i64
    %658 = llvm.add %657, %125  : i64
    %659 = llvm.getelementptr %101[%658] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %660 = llvm.bitcast %659 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %655, %660 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %661 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %662 = llvm.mul %120, %71  : i64
    %663 = llvm.add %115, %662  : i64
    %664 = llvm.add %663, %125  : i64
    %665 = llvm.getelementptr %101[%664] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %666 = llvm.bitcast %665 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %661, %666 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %667 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %668 = llvm.mul %121, %71  : i64
    %669 = llvm.add %115, %668  : i64
    %670 = llvm.add %669, %125  : i64
    %671 = llvm.getelementptr %101[%670] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %672 = llvm.bitcast %671 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %667, %672 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %673 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %674 = llvm.mul %122, %71  : i64
    %675 = llvm.add %115, %674  : i64
    %676 = llvm.add %675, %125  : i64
    %677 = llvm.getelementptr %101[%676] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %678 = llvm.bitcast %677 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %673, %678 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %679 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %680 = llvm.mul %123, %71  : i64
    %681 = llvm.add %115, %680  : i64
    %682 = llvm.add %681, %125  : i64
    %683 = llvm.getelementptr %101[%682] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %684 = llvm.bitcast %683 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %679, %684 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %685 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %686 = llvm.mul %124, %71  : i64
    %687 = llvm.add %115, %686  : i64
    %688 = llvm.add %687, %125  : i64
    %689 = llvm.getelementptr %101[%688] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %690 = llvm.bitcast %689 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %685, %690 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %691 = llvm.add %125, %79  : i64
    llvm.br ^bb3(%691 : i64)
  ^bb8:  // pred: ^bb3
    %692 = llvm.add %116, %79  : i64
    llvm.br ^bb1(%692 : i64)
  ^bb9:  // pred: ^bb1
    llvm.return %61 : i32
  }
}

// -----// IR Dump After LLVMCPUSynchronizeSymbolVisibility (iree-llvmcpu-synchronize-symbol-visibility) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(63 : i64) : i64
    %1 = llvm.mlir.constant(62 : i64) : i64
    %2 = llvm.mlir.constant(61 : i64) : i64
    %3 = llvm.mlir.constant(60 : i64) : i64
    %4 = llvm.mlir.constant(59 : i64) : i64
    %5 = llvm.mlir.constant(58 : i64) : i64
    %6 = llvm.mlir.constant(57 : i64) : i64
    %7 = llvm.mlir.constant(56 : i64) : i64
    %8 = llvm.mlir.constant(55 : i64) : i64
    %9 = llvm.mlir.constant(54 : i64) : i64
    %10 = llvm.mlir.constant(53 : i64) : i64
    %11 = llvm.mlir.constant(52 : i64) : i64
    %12 = llvm.mlir.constant(51 : i64) : i64
    %13 = llvm.mlir.constant(50 : i64) : i64
    %14 = llvm.mlir.constant(49 : i64) : i64
    %15 = llvm.mlir.constant(48 : i64) : i64
    %16 = llvm.mlir.constant(47 : i64) : i64
    %17 = llvm.mlir.constant(46 : i64) : i64
    %18 = llvm.mlir.constant(45 : i64) : i64
    %19 = llvm.mlir.constant(44 : i64) : i64
    %20 = llvm.mlir.constant(43 : i64) : i64
    %21 = llvm.mlir.constant(42 : i64) : i64
    %22 = llvm.mlir.constant(41 : i64) : i64
    %23 = llvm.mlir.constant(40 : i64) : i64
    %24 = llvm.mlir.constant(39 : i64) : i64
    %25 = llvm.mlir.constant(38 : i64) : i64
    %26 = llvm.mlir.constant(37 : i64) : i64
    %27 = llvm.mlir.constant(36 : i64) : i64
    %28 = llvm.mlir.constant(35 : i64) : i64
    %29 = llvm.mlir.constant(34 : i64) : i64
    %30 = llvm.mlir.constant(33 : i64) : i64
    %31 = llvm.mlir.constant(32 : i64) : i64
    %32 = llvm.mlir.constant(31 : i64) : i64
    %33 = llvm.mlir.constant(30 : i64) : i64
    %34 = llvm.mlir.constant(29 : i64) : i64
    %35 = llvm.mlir.constant(28 : i64) : i64
    %36 = llvm.mlir.constant(27 : i64) : i64
    %37 = llvm.mlir.constant(26 : i64) : i64
    %38 = llvm.mlir.constant(25 : i64) : i64
    %39 = llvm.mlir.constant(24 : i64) : i64
    %40 = llvm.mlir.constant(23 : i64) : i64
    %41 = llvm.mlir.constant(22 : i64) : i64
    %42 = llvm.mlir.constant(21 : i64) : i64
    %43 = llvm.mlir.constant(20 : i64) : i64
    %44 = llvm.mlir.constant(19 : i64) : i64
    %45 = llvm.mlir.constant(18 : i64) : i64
    %46 = llvm.mlir.constant(17 : i64) : i64
    %47 = llvm.mlir.constant(16 : i64) : i64
    %48 = llvm.mlir.constant(15 : i64) : i64
    %49 = llvm.mlir.constant(14 : i64) : i64
    %50 = llvm.mlir.constant(13 : i64) : i64
    %51 = llvm.mlir.constant(12 : i64) : i64
    %52 = llvm.mlir.constant(11 : i64) : i64
    %53 = llvm.mlir.constant(10 : i64) : i64
    %54 = llvm.mlir.constant(9 : i64) : i64
    %55 = llvm.mlir.constant(8 : i64) : i64
    %56 = llvm.mlir.constant(7 : i64) : i64
    %57 = llvm.mlir.constant(6 : i64) : i64
    %58 = llvm.mlir.constant(5 : i64) : i64
    %59 = llvm.mlir.constant(4 : i64) : i64
    %60 = llvm.mlir.constant(3 : i64) : i64
    %61 = llvm.mlir.constant(0 : i32) : i32
    %62 = llvm.mlir.constant(7 : index) : i64
    %63 = llvm.mlir.constant(6 : index) : i64
    %64 = llvm.mlir.constant(5 : index) : i64
    %65 = llvm.mlir.constant(4 : index) : i64
    %66 = llvm.mlir.constant(3 : index) : i64
    %67 = llvm.mlir.constant(2 : index) : i64
    %68 = llvm.mlir.constant(32768 : index) : i64
    %69 = llvm.mlir.constant(8192 : index) : i64
    %70 = llvm.mlir.constant(2 : i64) : i64
    %71 = llvm.mlir.constant(1024 : index) : i64
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.constant(63 : index) : i64
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.mlir.constant(0 : i64) : i64
    %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
    %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
    %78 = llvm.mlir.constant(256 : index) : i64
    %79 = llvm.mlir.constant(8 : index) : i64
    %80 = llvm.mlir.constant(32 : index) : i64
    %81 = llvm.mlir.constant(0 : index) : i64
    %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
    %87 = llvm.and %86, %73  : i64
    %88 = llvm.icmp "eq" %87, %81 : i64
    "llvm.intr.assume"(%88) : (i1) -> ()
    %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
    %95 = llvm.and %94, %73  : i64
    %96 = llvm.icmp "eq" %95, %81 : i64
    "llvm.intr.assume"(%96) : (i1) -> ()
    %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
    %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
    %103 = llvm.and %102, %73  : i64
    %104 = llvm.icmp "eq" %103, %81 : i64
    "llvm.intr.assume"(%104) : (i1) -> ()
    %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %107 = llvm.zext %106 : i32 to i64
    %108 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %109 = llvm.extractvalue %108[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %110 = llvm.zext %109 : i32 to i64
    %111 = llvm.mul %110, %69  : i64
    %112 = llvm.mul %107, %80  : i64
    %113 = llvm.mul %110, %68  : i64
    %114 = llvm.mul %107, %80  : i64
    %115 = llvm.add %113, %114  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb1(%116: i64):  // 2 preds: ^bb0, ^bb8
    %117 = llvm.icmp "slt" %116, %80 : i64
    llvm.cond_br %117, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %118 = llvm.add %116, %74  : i64
    %119 = llvm.add %116, %67  : i64
    %120 = llvm.add %116, %66  : i64
    %121 = llvm.add %116, %65  : i64
    %122 = llvm.add %116, %64  : i64
    %123 = llvm.add %116, %63  : i64
    %124 = llvm.add %116, %62  : i64
    llvm.br ^bb3(%81 : i64)
  ^bb3(%125: i64):  // 2 preds: ^bb2, ^bb7
    %126 = llvm.icmp "slt" %125, %80 : i64
    llvm.cond_br %126, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %127 = llvm.mul %116, %71  : i64
    %128 = llvm.add %115, %127  : i64
    %129 = llvm.add %128, %125  : i64
    %130 = llvm.getelementptr %101[%129] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %131 = llvm.bitcast %130 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %132 = llvm.load %131 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %133 = llvm.insertvalue %132, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %134 = llvm.mul %118, %71  : i64
    %135 = llvm.add %115, %134  : i64
    %136 = llvm.add %135, %125  : i64
    %137 = llvm.getelementptr %101[%136] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %138 = llvm.bitcast %137 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %139 = llvm.load %138 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %140 = llvm.insertvalue %139, %133[1] : !llvm.array<8 x vector<8xf32>> 
    %141 = llvm.mul %119, %71  : i64
    %142 = llvm.add %115, %141  : i64
    %143 = llvm.add %142, %125  : i64
    %144 = llvm.getelementptr %101[%143] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %145 = llvm.bitcast %144 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %146 = llvm.load %145 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %147 = llvm.insertvalue %146, %140[2] : !llvm.array<8 x vector<8xf32>> 
    %148 = llvm.mul %120, %71  : i64
    %149 = llvm.add %115, %148  : i64
    %150 = llvm.add %149, %125  : i64
    %151 = llvm.getelementptr %101[%150] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %152 = llvm.bitcast %151 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %153 = llvm.load %152 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %154 = llvm.insertvalue %153, %147[3] : !llvm.array<8 x vector<8xf32>> 
    %155 = llvm.mul %121, %71  : i64
    %156 = llvm.add %115, %155  : i64
    %157 = llvm.add %156, %125  : i64
    %158 = llvm.getelementptr %101[%157] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %159 = llvm.bitcast %158 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %160 = llvm.load %159 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %161 = llvm.insertvalue %160, %154[4] : !llvm.array<8 x vector<8xf32>> 
    %162 = llvm.mul %122, %71  : i64
    %163 = llvm.add %115, %162  : i64
    %164 = llvm.add %163, %125  : i64
    %165 = llvm.getelementptr %101[%164] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %166 = llvm.bitcast %165 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %167 = llvm.load %166 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %168 = llvm.insertvalue %167, %161[5] : !llvm.array<8 x vector<8xf32>> 
    %169 = llvm.mul %123, %71  : i64
    %170 = llvm.add %115, %169  : i64
    %171 = llvm.add %170, %125  : i64
    %172 = llvm.getelementptr %101[%171] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %173 = llvm.bitcast %172 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %174 = llvm.load %173 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %175 = llvm.insertvalue %174, %168[6] : !llvm.array<8 x vector<8xf32>> 
    %176 = llvm.mul %124, %71  : i64
    %177 = llvm.add %115, %176  : i64
    %178 = llvm.add %177, %125  : i64
    %179 = llvm.getelementptr %101[%178] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %180 = llvm.bitcast %179 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %181 = llvm.load %180 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %182 = llvm.insertvalue %181, %175[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.br ^bb5(%81, %182 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb5(%183: i64, %184: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
    %185 = llvm.icmp "slt" %183, %78 : i64
    llvm.cond_br %185, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %186 = llvm.mul %116, %78  : i64
    %187 = llvm.add %111, %186  : i64
    %188 = llvm.add %187, %183  : i64
    %189 = llvm.getelementptr %85[%188] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %190 = llvm.bitcast %189 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %191 = llvm.load %190 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %192 = llvm.mul %118, %78  : i64
    %193 = llvm.add %111, %192  : i64
    %194 = llvm.add %193, %183  : i64
    %195 = llvm.getelementptr %85[%194] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %196 = llvm.bitcast %195 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %197 = llvm.load %196 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %198 = llvm.mul %119, %78  : i64
    %199 = llvm.add %111, %198  : i64
    %200 = llvm.add %199, %183  : i64
    %201 = llvm.getelementptr %85[%200] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %202 = llvm.bitcast %201 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %203 = llvm.load %202 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %204 = llvm.mul %120, %78  : i64
    %205 = llvm.add %111, %204  : i64
    %206 = llvm.add %205, %183  : i64
    %207 = llvm.getelementptr %85[%206] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %208 = llvm.bitcast %207 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %209 = llvm.load %208 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %210 = llvm.mul %121, %78  : i64
    %211 = llvm.add %111, %210  : i64
    %212 = llvm.add %211, %183  : i64
    %213 = llvm.getelementptr %85[%212] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %214 = llvm.bitcast %213 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %215 = llvm.load %214 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %216 = llvm.mul %122, %78  : i64
    %217 = llvm.add %111, %216  : i64
    %218 = llvm.add %217, %183  : i64
    %219 = llvm.getelementptr %85[%218] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %220 = llvm.bitcast %219 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %221 = llvm.load %220 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %222 = llvm.mul %123, %78  : i64
    %223 = llvm.add %111, %222  : i64
    %224 = llvm.add %223, %183  : i64
    %225 = llvm.getelementptr %85[%224] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %226 = llvm.bitcast %225 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %227 = llvm.load %226 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %228 = llvm.mul %124, %78  : i64
    %229 = llvm.add %111, %228  : i64
    %230 = llvm.add %229, %183  : i64
    %231 = llvm.getelementptr %85[%230] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %232 = llvm.bitcast %231 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %233 = llvm.load %232 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %234 = llvm.mul %183, %71  : i64
    %235 = llvm.add %112, %234  : i64
    %236 = llvm.add %235, %125  : i64
    %237 = llvm.getelementptr %93[%236] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %238 = llvm.bitcast %237 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %239 = llvm.load %238 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %240 = llvm.add %183, %74  : i64
    %241 = llvm.mul %240, %71  : i64
    %242 = llvm.add %112, %241  : i64
    %243 = llvm.add %242, %125  : i64
    %244 = llvm.getelementptr %93[%243] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %245 = llvm.bitcast %244 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %246 = llvm.load %245 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %247 = llvm.add %183, %67  : i64
    %248 = llvm.mul %247, %71  : i64
    %249 = llvm.add %112, %248  : i64
    %250 = llvm.add %249, %125  : i64
    %251 = llvm.getelementptr %93[%250] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %252 = llvm.bitcast %251 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %253 = llvm.load %252 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %254 = llvm.add %183, %66  : i64
    %255 = llvm.mul %254, %71  : i64
    %256 = llvm.add %112, %255  : i64
    %257 = llvm.add %256, %125  : i64
    %258 = llvm.getelementptr %93[%257] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %259 = llvm.bitcast %258 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %260 = llvm.load %259 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %261 = llvm.add %183, %65  : i64
    %262 = llvm.mul %261, %71  : i64
    %263 = llvm.add %112, %262  : i64
    %264 = llvm.add %263, %125  : i64
    %265 = llvm.getelementptr %93[%264] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %266 = llvm.bitcast %265 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %267 = llvm.load %266 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %268 = llvm.add %183, %64  : i64
    %269 = llvm.mul %268, %71  : i64
    %270 = llvm.add %112, %269  : i64
    %271 = llvm.add %270, %125  : i64
    %272 = llvm.getelementptr %93[%271] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %273 = llvm.bitcast %272 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %274 = llvm.load %273 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %275 = llvm.add %183, %63  : i64
    %276 = llvm.mul %275, %71  : i64
    %277 = llvm.add %112, %276  : i64
    %278 = llvm.add %277, %125  : i64
    %279 = llvm.getelementptr %93[%278] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %280 = llvm.bitcast %279 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %281 = llvm.load %280 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %282 = llvm.add %183, %62  : i64
    %283 = llvm.mul %282, %71  : i64
    %284 = llvm.add %112, %283  : i64
    %285 = llvm.add %284, %125  : i64
    %286 = llvm.getelementptr %93[%285] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %287 = llvm.bitcast %286 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %288 = llvm.load %287 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %289 = llvm.shufflevector %191, %191 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %290 = llvm.shufflevector %289, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %291 = llvm.shufflevector %197, %197 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %293 = llvm.shufflevector %203, %203 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %295 = llvm.shufflevector %209, %209 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %297 = llvm.shufflevector %215, %215 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %299 = llvm.shufflevector %221, %221 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %301 = llvm.shufflevector %227, %227 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %303 = llvm.shufflevector %233, %233 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %304 = llvm.shufflevector %303, %302 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
    %305 = llvm.shufflevector %304, %304 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
    %306 = llvm.extractelement %305[%75 : i64] : vector<64xf32>
    %307 = llvm.mlir.undef : vector<8xf32>
    %308 = llvm.insertelement %306, %307[%61 : i32] : vector<8xf32>
    %309 = llvm.shufflevector %308, %307 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %310 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %311 = llvm.intr.fmuladd(%309, %239, %310)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %312 = llvm.extractelement %305[%72 : i64] : vector<64xf32>
    %313 = llvm.mlir.undef : vector<8xf32>
    %314 = llvm.insertelement %312, %313[%61 : i32] : vector<8xf32>
    %315 = llvm.shufflevector %314, %313 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %316 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %317 = llvm.intr.fmuladd(%315, %239, %316)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %318 = llvm.extractelement %305[%70 : i64] : vector<64xf32>
    %319 = llvm.mlir.undef : vector<8xf32>
    %320 = llvm.insertelement %318, %319[%61 : i32] : vector<8xf32>
    %321 = llvm.shufflevector %320, %319 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %322 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %323 = llvm.intr.fmuladd(%321, %239, %322)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %324 = llvm.extractelement %305[%60 : i64] : vector<64xf32>
    %325 = llvm.mlir.undef : vector<8xf32>
    %326 = llvm.insertelement %324, %325[%61 : i32] : vector<8xf32>
    %327 = llvm.shufflevector %326, %325 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %328 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %329 = llvm.intr.fmuladd(%327, %239, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %330 = llvm.extractelement %305[%59 : i64] : vector<64xf32>
    %331 = llvm.mlir.undef : vector<8xf32>
    %332 = llvm.insertelement %330, %331[%61 : i32] : vector<8xf32>
    %333 = llvm.shufflevector %332, %331 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %334 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %335 = llvm.intr.fmuladd(%333, %239, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %336 = llvm.extractelement %305[%58 : i64] : vector<64xf32>
    %337 = llvm.mlir.undef : vector<8xf32>
    %338 = llvm.insertelement %336, %337[%61 : i32] : vector<8xf32>
    %339 = llvm.shufflevector %338, %337 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %340 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %341 = llvm.intr.fmuladd(%339, %239, %340)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %342 = llvm.extractelement %305[%57 : i64] : vector<64xf32>
    %343 = llvm.mlir.undef : vector<8xf32>
    %344 = llvm.insertelement %342, %343[%61 : i32] : vector<8xf32>
    %345 = llvm.shufflevector %344, %343 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %346 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %347 = llvm.intr.fmuladd(%345, %239, %346)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %348 = llvm.extractelement %305[%56 : i64] : vector<64xf32>
    %349 = llvm.mlir.undef : vector<8xf32>
    %350 = llvm.insertelement %348, %349[%61 : i32] : vector<8xf32>
    %351 = llvm.shufflevector %350, %349 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %352 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %353 = llvm.intr.fmuladd(%351, %239, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %354 = llvm.extractelement %305[%55 : i64] : vector<64xf32>
    %355 = llvm.mlir.undef : vector<8xf32>
    %356 = llvm.insertelement %354, %355[%61 : i32] : vector<8xf32>
    %357 = llvm.shufflevector %356, %355 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %358 = llvm.intr.fmuladd(%357, %246, %311)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %359 = llvm.extractelement %305[%54 : i64] : vector<64xf32>
    %360 = llvm.mlir.undef : vector<8xf32>
    %361 = llvm.insertelement %359, %360[%61 : i32] : vector<8xf32>
    %362 = llvm.shufflevector %361, %360 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %363 = llvm.intr.fmuladd(%362, %246, %317)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %364 = llvm.extractelement %305[%53 : i64] : vector<64xf32>
    %365 = llvm.mlir.undef : vector<8xf32>
    %366 = llvm.insertelement %364, %365[%61 : i32] : vector<8xf32>
    %367 = llvm.shufflevector %366, %365 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %368 = llvm.intr.fmuladd(%367, %246, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %369 = llvm.extractelement %305[%52 : i64] : vector<64xf32>
    %370 = llvm.mlir.undef : vector<8xf32>
    %371 = llvm.insertelement %369, %370[%61 : i32] : vector<8xf32>
    %372 = llvm.shufflevector %371, %370 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %373 = llvm.intr.fmuladd(%372, %246, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %374 = llvm.extractelement %305[%51 : i64] : vector<64xf32>
    %375 = llvm.mlir.undef : vector<8xf32>
    %376 = llvm.insertelement %374, %375[%61 : i32] : vector<8xf32>
    %377 = llvm.shufflevector %376, %375 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %378 = llvm.intr.fmuladd(%377, %246, %335)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %379 = llvm.extractelement %305[%50 : i64] : vector<64xf32>
    %380 = llvm.mlir.undef : vector<8xf32>
    %381 = llvm.insertelement %379, %380[%61 : i32] : vector<8xf32>
    %382 = llvm.shufflevector %381, %380 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %383 = llvm.intr.fmuladd(%382, %246, %341)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %384 = llvm.extractelement %305[%49 : i64] : vector<64xf32>
    %385 = llvm.mlir.undef : vector<8xf32>
    %386 = llvm.insertelement %384, %385[%61 : i32] : vector<8xf32>
    %387 = llvm.shufflevector %386, %385 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %388 = llvm.intr.fmuladd(%387, %246, %347)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %389 = llvm.extractelement %305[%48 : i64] : vector<64xf32>
    %390 = llvm.mlir.undef : vector<8xf32>
    %391 = llvm.insertelement %389, %390[%61 : i32] : vector<8xf32>
    %392 = llvm.shufflevector %391, %390 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %393 = llvm.intr.fmuladd(%392, %246, %353)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %394 = llvm.extractelement %305[%47 : i64] : vector<64xf32>
    %395 = llvm.mlir.undef : vector<8xf32>
    %396 = llvm.insertelement %394, %395[%61 : i32] : vector<8xf32>
    %397 = llvm.shufflevector %396, %395 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %398 = llvm.intr.fmuladd(%397, %253, %358)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %399 = llvm.extractelement %305[%46 : i64] : vector<64xf32>
    %400 = llvm.mlir.undef : vector<8xf32>
    %401 = llvm.insertelement %399, %400[%61 : i32] : vector<8xf32>
    %402 = llvm.shufflevector %401, %400 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %403 = llvm.intr.fmuladd(%402, %253, %363)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %404 = llvm.extractelement %305[%45 : i64] : vector<64xf32>
    %405 = llvm.mlir.undef : vector<8xf32>
    %406 = llvm.insertelement %404, %405[%61 : i32] : vector<8xf32>
    %407 = llvm.shufflevector %406, %405 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %408 = llvm.intr.fmuladd(%407, %253, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %409 = llvm.extractelement %305[%44 : i64] : vector<64xf32>
    %410 = llvm.mlir.undef : vector<8xf32>
    %411 = llvm.insertelement %409, %410[%61 : i32] : vector<8xf32>
    %412 = llvm.shufflevector %411, %410 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %413 = llvm.intr.fmuladd(%412, %253, %373)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %414 = llvm.extractelement %305[%43 : i64] : vector<64xf32>
    %415 = llvm.mlir.undef : vector<8xf32>
    %416 = llvm.insertelement %414, %415[%61 : i32] : vector<8xf32>
    %417 = llvm.shufflevector %416, %415 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %418 = llvm.intr.fmuladd(%417, %253, %378)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %419 = llvm.extractelement %305[%42 : i64] : vector<64xf32>
    %420 = llvm.mlir.undef : vector<8xf32>
    %421 = llvm.insertelement %419, %420[%61 : i32] : vector<8xf32>
    %422 = llvm.shufflevector %421, %420 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %423 = llvm.intr.fmuladd(%422, %253, %383)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %424 = llvm.extractelement %305[%41 : i64] : vector<64xf32>
    %425 = llvm.mlir.undef : vector<8xf32>
    %426 = llvm.insertelement %424, %425[%61 : i32] : vector<8xf32>
    %427 = llvm.shufflevector %426, %425 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %428 = llvm.intr.fmuladd(%427, %253, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %429 = llvm.extractelement %305[%40 : i64] : vector<64xf32>
    %430 = llvm.mlir.undef : vector<8xf32>
    %431 = llvm.insertelement %429, %430[%61 : i32] : vector<8xf32>
    %432 = llvm.shufflevector %431, %430 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %433 = llvm.intr.fmuladd(%432, %253, %393)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %434 = llvm.extractelement %305[%39 : i64] : vector<64xf32>
    %435 = llvm.mlir.undef : vector<8xf32>
    %436 = llvm.insertelement %434, %435[%61 : i32] : vector<8xf32>
    %437 = llvm.shufflevector %436, %435 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %438 = llvm.intr.fmuladd(%437, %260, %398)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %439 = llvm.extractelement %305[%38 : i64] : vector<64xf32>
    %440 = llvm.mlir.undef : vector<8xf32>
    %441 = llvm.insertelement %439, %440[%61 : i32] : vector<8xf32>
    %442 = llvm.shufflevector %441, %440 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %443 = llvm.intr.fmuladd(%442, %260, %403)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %444 = llvm.extractelement %305[%37 : i64] : vector<64xf32>
    %445 = llvm.mlir.undef : vector<8xf32>
    %446 = llvm.insertelement %444, %445[%61 : i32] : vector<8xf32>
    %447 = llvm.shufflevector %446, %445 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %448 = llvm.intr.fmuladd(%447, %260, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %449 = llvm.extractelement %305[%36 : i64] : vector<64xf32>
    %450 = llvm.mlir.undef : vector<8xf32>
    %451 = llvm.insertelement %449, %450[%61 : i32] : vector<8xf32>
    %452 = llvm.shufflevector %451, %450 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %453 = llvm.intr.fmuladd(%452, %260, %413)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %454 = llvm.extractelement %305[%35 : i64] : vector<64xf32>
    %455 = llvm.mlir.undef : vector<8xf32>
    %456 = llvm.insertelement %454, %455[%61 : i32] : vector<8xf32>
    %457 = llvm.shufflevector %456, %455 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %458 = llvm.intr.fmuladd(%457, %260, %418)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %459 = llvm.extractelement %305[%34 : i64] : vector<64xf32>
    %460 = llvm.mlir.undef : vector<8xf32>
    %461 = llvm.insertelement %459, %460[%61 : i32] : vector<8xf32>
    %462 = llvm.shufflevector %461, %460 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %463 = llvm.intr.fmuladd(%462, %260, %423)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %464 = llvm.extractelement %305[%33 : i64] : vector<64xf32>
    %465 = llvm.mlir.undef : vector<8xf32>
    %466 = llvm.insertelement %464, %465[%61 : i32] : vector<8xf32>
    %467 = llvm.shufflevector %466, %465 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %468 = llvm.intr.fmuladd(%467, %260, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %469 = llvm.extractelement %305[%32 : i64] : vector<64xf32>
    %470 = llvm.mlir.undef : vector<8xf32>
    %471 = llvm.insertelement %469, %470[%61 : i32] : vector<8xf32>
    %472 = llvm.shufflevector %471, %470 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %473 = llvm.intr.fmuladd(%472, %260, %433)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %474 = llvm.extractelement %305[%31 : i64] : vector<64xf32>
    %475 = llvm.mlir.undef : vector<8xf32>
    %476 = llvm.insertelement %474, %475[%61 : i32] : vector<8xf32>
    %477 = llvm.shufflevector %476, %475 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %478 = llvm.intr.fmuladd(%477, %267, %438)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %479 = llvm.extractelement %305[%30 : i64] : vector<64xf32>
    %480 = llvm.mlir.undef : vector<8xf32>
    %481 = llvm.insertelement %479, %480[%61 : i32] : vector<8xf32>
    %482 = llvm.shufflevector %481, %480 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %483 = llvm.intr.fmuladd(%482, %267, %443)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %484 = llvm.extractelement %305[%29 : i64] : vector<64xf32>
    %485 = llvm.mlir.undef : vector<8xf32>
    %486 = llvm.insertelement %484, %485[%61 : i32] : vector<8xf32>
    %487 = llvm.shufflevector %486, %485 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %488 = llvm.intr.fmuladd(%487, %267, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %489 = llvm.extractelement %305[%28 : i64] : vector<64xf32>
    %490 = llvm.mlir.undef : vector<8xf32>
    %491 = llvm.insertelement %489, %490[%61 : i32] : vector<8xf32>
    %492 = llvm.shufflevector %491, %490 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %493 = llvm.intr.fmuladd(%492, %267, %453)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %494 = llvm.extractelement %305[%27 : i64] : vector<64xf32>
    %495 = llvm.mlir.undef : vector<8xf32>
    %496 = llvm.insertelement %494, %495[%61 : i32] : vector<8xf32>
    %497 = llvm.shufflevector %496, %495 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %498 = llvm.intr.fmuladd(%497, %267, %458)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %499 = llvm.extractelement %305[%26 : i64] : vector<64xf32>
    %500 = llvm.mlir.undef : vector<8xf32>
    %501 = llvm.insertelement %499, %500[%61 : i32] : vector<8xf32>
    %502 = llvm.shufflevector %501, %500 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %503 = llvm.intr.fmuladd(%502, %267, %463)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %504 = llvm.extractelement %305[%25 : i64] : vector<64xf32>
    %505 = llvm.mlir.undef : vector<8xf32>
    %506 = llvm.insertelement %504, %505[%61 : i32] : vector<8xf32>
    %507 = llvm.shufflevector %506, %505 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %508 = llvm.intr.fmuladd(%507, %267, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %509 = llvm.extractelement %305[%24 : i64] : vector<64xf32>
    %510 = llvm.mlir.undef : vector<8xf32>
    %511 = llvm.insertelement %509, %510[%61 : i32] : vector<8xf32>
    %512 = llvm.shufflevector %511, %510 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %513 = llvm.intr.fmuladd(%512, %267, %473)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %514 = llvm.extractelement %305[%23 : i64] : vector<64xf32>
    %515 = llvm.mlir.undef : vector<8xf32>
    %516 = llvm.insertelement %514, %515[%61 : i32] : vector<8xf32>
    %517 = llvm.shufflevector %516, %515 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %518 = llvm.intr.fmuladd(%517, %274, %478)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %519 = llvm.extractelement %305[%22 : i64] : vector<64xf32>
    %520 = llvm.mlir.undef : vector<8xf32>
    %521 = llvm.insertelement %519, %520[%61 : i32] : vector<8xf32>
    %522 = llvm.shufflevector %521, %520 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %523 = llvm.intr.fmuladd(%522, %274, %483)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %524 = llvm.extractelement %305[%21 : i64] : vector<64xf32>
    %525 = llvm.mlir.undef : vector<8xf32>
    %526 = llvm.insertelement %524, %525[%61 : i32] : vector<8xf32>
    %527 = llvm.shufflevector %526, %525 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %528 = llvm.intr.fmuladd(%527, %274, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %529 = llvm.extractelement %305[%20 : i64] : vector<64xf32>
    %530 = llvm.mlir.undef : vector<8xf32>
    %531 = llvm.insertelement %529, %530[%61 : i32] : vector<8xf32>
    %532 = llvm.shufflevector %531, %530 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %533 = llvm.intr.fmuladd(%532, %274, %493)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %534 = llvm.extractelement %305[%19 : i64] : vector<64xf32>
    %535 = llvm.mlir.undef : vector<8xf32>
    %536 = llvm.insertelement %534, %535[%61 : i32] : vector<8xf32>
    %537 = llvm.shufflevector %536, %535 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %538 = llvm.intr.fmuladd(%537, %274, %498)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %539 = llvm.extractelement %305[%18 : i64] : vector<64xf32>
    %540 = llvm.mlir.undef : vector<8xf32>
    %541 = llvm.insertelement %539, %540[%61 : i32] : vector<8xf32>
    %542 = llvm.shufflevector %541, %540 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %543 = llvm.intr.fmuladd(%542, %274, %503)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %544 = llvm.extractelement %305[%17 : i64] : vector<64xf32>
    %545 = llvm.mlir.undef : vector<8xf32>
    %546 = llvm.insertelement %544, %545[%61 : i32] : vector<8xf32>
    %547 = llvm.shufflevector %546, %545 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %548 = llvm.intr.fmuladd(%547, %274, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %549 = llvm.extractelement %305[%16 : i64] : vector<64xf32>
    %550 = llvm.mlir.undef : vector<8xf32>
    %551 = llvm.insertelement %549, %550[%61 : i32] : vector<8xf32>
    %552 = llvm.shufflevector %551, %550 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %553 = llvm.intr.fmuladd(%552, %274, %513)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %554 = llvm.extractelement %305[%15 : i64] : vector<64xf32>
    %555 = llvm.mlir.undef : vector<8xf32>
    %556 = llvm.insertelement %554, %555[%61 : i32] : vector<8xf32>
    %557 = llvm.shufflevector %556, %555 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %558 = llvm.intr.fmuladd(%557, %281, %518)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %559 = llvm.extractelement %305[%14 : i64] : vector<64xf32>
    %560 = llvm.mlir.undef : vector<8xf32>
    %561 = llvm.insertelement %559, %560[%61 : i32] : vector<8xf32>
    %562 = llvm.shufflevector %561, %560 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %563 = llvm.intr.fmuladd(%562, %281, %523)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %564 = llvm.extractelement %305[%13 : i64] : vector<64xf32>
    %565 = llvm.mlir.undef : vector<8xf32>
    %566 = llvm.insertelement %564, %565[%61 : i32] : vector<8xf32>
    %567 = llvm.shufflevector %566, %565 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %568 = llvm.intr.fmuladd(%567, %281, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %569 = llvm.extractelement %305[%12 : i64] : vector<64xf32>
    %570 = llvm.mlir.undef : vector<8xf32>
    %571 = llvm.insertelement %569, %570[%61 : i32] : vector<8xf32>
    %572 = llvm.shufflevector %571, %570 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %573 = llvm.intr.fmuladd(%572, %281, %533)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %574 = llvm.extractelement %305[%11 : i64] : vector<64xf32>
    %575 = llvm.mlir.undef : vector<8xf32>
    %576 = llvm.insertelement %574, %575[%61 : i32] : vector<8xf32>
    %577 = llvm.shufflevector %576, %575 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %578 = llvm.intr.fmuladd(%577, %281, %538)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %579 = llvm.extractelement %305[%10 : i64] : vector<64xf32>
    %580 = llvm.mlir.undef : vector<8xf32>
    %581 = llvm.insertelement %579, %580[%61 : i32] : vector<8xf32>
    %582 = llvm.shufflevector %581, %580 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %583 = llvm.intr.fmuladd(%582, %281, %543)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %584 = llvm.extractelement %305[%9 : i64] : vector<64xf32>
    %585 = llvm.mlir.undef : vector<8xf32>
    %586 = llvm.insertelement %584, %585[%61 : i32] : vector<8xf32>
    %587 = llvm.shufflevector %586, %585 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %588 = llvm.intr.fmuladd(%587, %281, %548)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %589 = llvm.extractelement %305[%8 : i64] : vector<64xf32>
    %590 = llvm.mlir.undef : vector<8xf32>
    %591 = llvm.insertelement %589, %590[%61 : i32] : vector<8xf32>
    %592 = llvm.shufflevector %591, %590 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %593 = llvm.intr.fmuladd(%592, %281, %553)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %594 = llvm.extractelement %305[%7 : i64] : vector<64xf32>
    %595 = llvm.mlir.undef : vector<8xf32>
    %596 = llvm.insertelement %594, %595[%61 : i32] : vector<8xf32>
    %597 = llvm.shufflevector %596, %595 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %598 = llvm.intr.fmuladd(%597, %288, %558)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %599 = llvm.insertvalue %598, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %600 = llvm.extractelement %305[%6 : i64] : vector<64xf32>
    %601 = llvm.mlir.undef : vector<8xf32>
    %602 = llvm.insertelement %600, %601[%61 : i32] : vector<8xf32>
    %603 = llvm.shufflevector %602, %601 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %604 = llvm.intr.fmuladd(%603, %288, %563)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %605 = llvm.insertvalue %604, %599[1] : !llvm.array<8 x vector<8xf32>> 
    %606 = llvm.extractelement %305[%5 : i64] : vector<64xf32>
    %607 = llvm.mlir.undef : vector<8xf32>
    %608 = llvm.insertelement %606, %607[%61 : i32] : vector<8xf32>
    %609 = llvm.shufflevector %608, %607 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %610 = llvm.intr.fmuladd(%609, %288, %568)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %611 = llvm.insertvalue %610, %605[2] : !llvm.array<8 x vector<8xf32>> 
    %612 = llvm.extractelement %305[%4 : i64] : vector<64xf32>
    %613 = llvm.mlir.undef : vector<8xf32>
    %614 = llvm.insertelement %612, %613[%61 : i32] : vector<8xf32>
    %615 = llvm.shufflevector %614, %613 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %616 = llvm.intr.fmuladd(%615, %288, %573)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %617 = llvm.insertvalue %616, %611[3] : !llvm.array<8 x vector<8xf32>> 
    %618 = llvm.extractelement %305[%3 : i64] : vector<64xf32>
    %619 = llvm.mlir.undef : vector<8xf32>
    %620 = llvm.insertelement %618, %619[%61 : i32] : vector<8xf32>
    %621 = llvm.shufflevector %620, %619 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %622 = llvm.intr.fmuladd(%621, %288, %578)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %623 = llvm.insertvalue %622, %617[4] : !llvm.array<8 x vector<8xf32>> 
    %624 = llvm.extractelement %305[%2 : i64] : vector<64xf32>
    %625 = llvm.mlir.undef : vector<8xf32>
    %626 = llvm.insertelement %624, %625[%61 : i32] : vector<8xf32>
    %627 = llvm.shufflevector %626, %625 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %628 = llvm.intr.fmuladd(%627, %288, %583)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %629 = llvm.insertvalue %628, %623[5] : !llvm.array<8 x vector<8xf32>> 
    %630 = llvm.extractelement %305[%1 : i64] : vector<64xf32>
    %631 = llvm.mlir.undef : vector<8xf32>
    %632 = llvm.insertelement %630, %631[%61 : i32] : vector<8xf32>
    %633 = llvm.shufflevector %632, %631 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %634 = llvm.intr.fmuladd(%633, %288, %588)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %635 = llvm.insertvalue %634, %629[6] : !llvm.array<8 x vector<8xf32>> 
    %636 = llvm.extractelement %305[%0 : i64] : vector<64xf32>
    %637 = llvm.mlir.undef : vector<8xf32>
    %638 = llvm.insertelement %636, %637[%61 : i32] : vector<8xf32>
    %639 = llvm.shufflevector %638, %637 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %640 = llvm.intr.fmuladd(%639, %288, %593)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %641 = llvm.insertvalue %640, %635[7] : !llvm.array<8 x vector<8xf32>> 
    %642 = llvm.add %183, %79  : i64
    llvm.br ^bb5(%642, %641 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb7:  // pred: ^bb5
    %643 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %644 = llvm.mul %116, %71  : i64
    %645 = llvm.add %115, %644  : i64
    %646 = llvm.add %645, %125  : i64
    %647 = llvm.getelementptr %101[%646] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %648 = llvm.bitcast %647 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %643, %648 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %649 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %650 = llvm.mul %118, %71  : i64
    %651 = llvm.add %115, %650  : i64
    %652 = llvm.add %651, %125  : i64
    %653 = llvm.getelementptr %101[%652] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %654 = llvm.bitcast %653 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %649, %654 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %655 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %656 = llvm.mul %119, %71  : i64
    %657 = llvm.add %115, %656  : i64
    %658 = llvm.add %657, %125  : i64
    %659 = llvm.getelementptr %101[%658] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %660 = llvm.bitcast %659 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %655, %660 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %661 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %662 = llvm.mul %120, %71  : i64
    %663 = llvm.add %115, %662  : i64
    %664 = llvm.add %663, %125  : i64
    %665 = llvm.getelementptr %101[%664] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %666 = llvm.bitcast %665 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %661, %666 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %667 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %668 = llvm.mul %121, %71  : i64
    %669 = llvm.add %115, %668  : i64
    %670 = llvm.add %669, %125  : i64
    %671 = llvm.getelementptr %101[%670] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %672 = llvm.bitcast %671 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %667, %672 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %673 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %674 = llvm.mul %122, %71  : i64
    %675 = llvm.add %115, %674  : i64
    %676 = llvm.add %675, %125  : i64
    %677 = llvm.getelementptr %101[%676] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %678 = llvm.bitcast %677 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %673, %678 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %679 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %680 = llvm.mul %123, %71  : i64
    %681 = llvm.add %115, %680  : i64
    %682 = llvm.add %681, %125  : i64
    %683 = llvm.getelementptr %101[%682] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %684 = llvm.bitcast %683 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %679, %684 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %685 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %686 = llvm.mul %124, %71  : i64
    %687 = llvm.add %115, %686  : i64
    %688 = llvm.add %687, %125  : i64
    %689 = llvm.getelementptr %101[%688] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %690 = llvm.bitcast %689 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %685, %690 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %691 = llvm.add %125, %79  : i64
    llvm.br ^bb3(%691 : i64)
  ^bb8:  // pred: ^bb3
    %692 = llvm.add %116, %79  : i64
    llvm.br ^bb1(%692 : i64)
  ^bb9:  // pred: ^bb1
    llvm.return %61 : i32
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(63 : i64) : i64
    %1 = llvm.mlir.constant(62 : i64) : i64
    %2 = llvm.mlir.constant(61 : i64) : i64
    %3 = llvm.mlir.constant(60 : i64) : i64
    %4 = llvm.mlir.constant(59 : i64) : i64
    %5 = llvm.mlir.constant(58 : i64) : i64
    %6 = llvm.mlir.constant(57 : i64) : i64
    %7 = llvm.mlir.constant(56 : i64) : i64
    %8 = llvm.mlir.constant(55 : i64) : i64
    %9 = llvm.mlir.constant(54 : i64) : i64
    %10 = llvm.mlir.constant(53 : i64) : i64
    %11 = llvm.mlir.constant(52 : i64) : i64
    %12 = llvm.mlir.constant(51 : i64) : i64
    %13 = llvm.mlir.constant(50 : i64) : i64
    %14 = llvm.mlir.constant(49 : i64) : i64
    %15 = llvm.mlir.constant(48 : i64) : i64
    %16 = llvm.mlir.constant(47 : i64) : i64
    %17 = llvm.mlir.constant(46 : i64) : i64
    %18 = llvm.mlir.constant(45 : i64) : i64
    %19 = llvm.mlir.constant(44 : i64) : i64
    %20 = llvm.mlir.constant(43 : i64) : i64
    %21 = llvm.mlir.constant(42 : i64) : i64
    %22 = llvm.mlir.constant(41 : i64) : i64
    %23 = llvm.mlir.constant(40 : i64) : i64
    %24 = llvm.mlir.constant(39 : i64) : i64
    %25 = llvm.mlir.constant(38 : i64) : i64
    %26 = llvm.mlir.constant(37 : i64) : i64
    %27 = llvm.mlir.constant(36 : i64) : i64
    %28 = llvm.mlir.constant(35 : i64) : i64
    %29 = llvm.mlir.constant(34 : i64) : i64
    %30 = llvm.mlir.constant(33 : i64) : i64
    %31 = llvm.mlir.constant(32 : i64) : i64
    %32 = llvm.mlir.constant(31 : i64) : i64
    %33 = llvm.mlir.constant(30 : i64) : i64
    %34 = llvm.mlir.constant(29 : i64) : i64
    %35 = llvm.mlir.constant(28 : i64) : i64
    %36 = llvm.mlir.constant(27 : i64) : i64
    %37 = llvm.mlir.constant(26 : i64) : i64
    %38 = llvm.mlir.constant(25 : i64) : i64
    %39 = llvm.mlir.constant(24 : i64) : i64
    %40 = llvm.mlir.constant(23 : i64) : i64
    %41 = llvm.mlir.constant(22 : i64) : i64
    %42 = llvm.mlir.constant(21 : i64) : i64
    %43 = llvm.mlir.constant(20 : i64) : i64
    %44 = llvm.mlir.constant(19 : i64) : i64
    %45 = llvm.mlir.constant(18 : i64) : i64
    %46 = llvm.mlir.constant(17 : i64) : i64
    %47 = llvm.mlir.constant(16 : i64) : i64
    %48 = llvm.mlir.constant(15 : i64) : i64
    %49 = llvm.mlir.constant(14 : i64) : i64
    %50 = llvm.mlir.constant(13 : i64) : i64
    %51 = llvm.mlir.constant(12 : i64) : i64
    %52 = llvm.mlir.constant(11 : i64) : i64
    %53 = llvm.mlir.constant(10 : i64) : i64
    %54 = llvm.mlir.constant(9 : i64) : i64
    %55 = llvm.mlir.constant(8 : i64) : i64
    %56 = llvm.mlir.constant(7 : i64) : i64
    %57 = llvm.mlir.constant(6 : i64) : i64
    %58 = llvm.mlir.constant(5 : i64) : i64
    %59 = llvm.mlir.constant(4 : i64) : i64
    %60 = llvm.mlir.constant(3 : i64) : i64
    %61 = llvm.mlir.constant(0 : i32) : i32
    %62 = llvm.mlir.constant(7 : index) : i64
    %63 = llvm.mlir.constant(6 : index) : i64
    %64 = llvm.mlir.constant(5 : index) : i64
    %65 = llvm.mlir.constant(4 : index) : i64
    %66 = llvm.mlir.constant(3 : index) : i64
    %67 = llvm.mlir.constant(2 : index) : i64
    %68 = llvm.mlir.constant(32768 : index) : i64
    %69 = llvm.mlir.constant(8192 : index) : i64
    %70 = llvm.mlir.constant(2 : i64) : i64
    %71 = llvm.mlir.constant(1024 : index) : i64
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.constant(63 : index) : i64
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.mlir.constant(0 : i64) : i64
    %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
    %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
    %78 = llvm.mlir.constant(256 : index) : i64
    %79 = llvm.mlir.constant(8 : index) : i64
    %80 = llvm.mlir.constant(32 : index) : i64
    %81 = llvm.mlir.constant(0 : index) : i64
    %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
    %87 = llvm.and %86, %73  : i64
    %88 = llvm.icmp "eq" %87, %81 : i64
    "llvm.intr.assume"(%88) : (i1) -> ()
    %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
    %95 = llvm.and %94, %73  : i64
    %96 = llvm.icmp "eq" %95, %81 : i64
    "llvm.intr.assume"(%96) : (i1) -> ()
    %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
    %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
    %103 = llvm.and %102, %73  : i64
    %104 = llvm.icmp "eq" %103, %81 : i64
    "llvm.intr.assume"(%104) : (i1) -> ()
    %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %107 = llvm.zext %106 : i32 to i64
    %108 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %109 = llvm.extractvalue %108[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %110 = llvm.zext %109 : i32 to i64
    %111 = llvm.mul %110, %69  : i64
    %112 = llvm.mul %107, %80  : i64
    %113 = llvm.mul %110, %68  : i64
    %114 = llvm.mul %107, %80  : i64
    %115 = llvm.add %113, %114  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb1(%116: i64):  // 2 preds: ^bb0, ^bb8
    %117 = llvm.icmp "slt" %116, %80 : i64
    llvm.cond_br %117, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %118 = llvm.add %116, %74  : i64
    %119 = llvm.add %116, %67  : i64
    %120 = llvm.add %116, %66  : i64
    %121 = llvm.add %116, %65  : i64
    %122 = llvm.add %116, %64  : i64
    %123 = llvm.add %116, %63  : i64
    %124 = llvm.add %116, %62  : i64
    llvm.br ^bb3(%81 : i64)
  ^bb3(%125: i64):  // 2 preds: ^bb2, ^bb7
    %126 = llvm.icmp "slt" %125, %80 : i64
    llvm.cond_br %126, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %127 = llvm.mul %116, %71  : i64
    %128 = llvm.add %115, %127  : i64
    %129 = llvm.add %128, %125  : i64
    %130 = llvm.getelementptr %101[%129] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %131 = llvm.bitcast %130 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %132 = llvm.load %131 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %133 = llvm.insertvalue %132, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %134 = llvm.mul %118, %71  : i64
    %135 = llvm.add %115, %134  : i64
    %136 = llvm.add %135, %125  : i64
    %137 = llvm.getelementptr %101[%136] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %138 = llvm.bitcast %137 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %139 = llvm.load %138 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %140 = llvm.insertvalue %139, %133[1] : !llvm.array<8 x vector<8xf32>> 
    %141 = llvm.mul %119, %71  : i64
    %142 = llvm.add %115, %141  : i64
    %143 = llvm.add %142, %125  : i64
    %144 = llvm.getelementptr %101[%143] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %145 = llvm.bitcast %144 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %146 = llvm.load %145 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %147 = llvm.insertvalue %146, %140[2] : !llvm.array<8 x vector<8xf32>> 
    %148 = llvm.mul %120, %71  : i64
    %149 = llvm.add %115, %148  : i64
    %150 = llvm.add %149, %125  : i64
    %151 = llvm.getelementptr %101[%150] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %152 = llvm.bitcast %151 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %153 = llvm.load %152 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %154 = llvm.insertvalue %153, %147[3] : !llvm.array<8 x vector<8xf32>> 
    %155 = llvm.mul %121, %71  : i64
    %156 = llvm.add %115, %155  : i64
    %157 = llvm.add %156, %125  : i64
    %158 = llvm.getelementptr %101[%157] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %159 = llvm.bitcast %158 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %160 = llvm.load %159 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %161 = llvm.insertvalue %160, %154[4] : !llvm.array<8 x vector<8xf32>> 
    %162 = llvm.mul %122, %71  : i64
    %163 = llvm.add %115, %162  : i64
    %164 = llvm.add %163, %125  : i64
    %165 = llvm.getelementptr %101[%164] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %166 = llvm.bitcast %165 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %167 = llvm.load %166 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %168 = llvm.insertvalue %167, %161[5] : !llvm.array<8 x vector<8xf32>> 
    %169 = llvm.mul %123, %71  : i64
    %170 = llvm.add %115, %169  : i64
    %171 = llvm.add %170, %125  : i64
    %172 = llvm.getelementptr %101[%171] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %173 = llvm.bitcast %172 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %174 = llvm.load %173 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %175 = llvm.insertvalue %174, %168[6] : !llvm.array<8 x vector<8xf32>> 
    %176 = llvm.mul %124, %71  : i64
    %177 = llvm.add %115, %176  : i64
    %178 = llvm.add %177, %125  : i64
    %179 = llvm.getelementptr %101[%178] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %180 = llvm.bitcast %179 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %181 = llvm.load %180 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %182 = llvm.insertvalue %181, %175[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.br ^bb5(%81, %182 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb5(%183: i64, %184: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
    %185 = llvm.icmp "slt" %183, %78 : i64
    llvm.cond_br %185, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %186 = llvm.mul %116, %78  : i64
    %187 = llvm.add %111, %186  : i64
    %188 = llvm.add %187, %183  : i64
    %189 = llvm.getelementptr %85[%188] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %190 = llvm.bitcast %189 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %191 = llvm.load %190 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %192 = llvm.mul %118, %78  : i64
    %193 = llvm.add %111, %192  : i64
    %194 = llvm.add %193, %183  : i64
    %195 = llvm.getelementptr %85[%194] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %196 = llvm.bitcast %195 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %197 = llvm.load %196 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %198 = llvm.mul %119, %78  : i64
    %199 = llvm.add %111, %198  : i64
    %200 = llvm.add %199, %183  : i64
    %201 = llvm.getelementptr %85[%200] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %202 = llvm.bitcast %201 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %203 = llvm.load %202 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %204 = llvm.mul %120, %78  : i64
    %205 = llvm.add %111, %204  : i64
    %206 = llvm.add %205, %183  : i64
    %207 = llvm.getelementptr %85[%206] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %208 = llvm.bitcast %207 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %209 = llvm.load %208 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %210 = llvm.mul %121, %78  : i64
    %211 = llvm.add %111, %210  : i64
    %212 = llvm.add %211, %183  : i64
    %213 = llvm.getelementptr %85[%212] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %214 = llvm.bitcast %213 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %215 = llvm.load %214 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %216 = llvm.mul %122, %78  : i64
    %217 = llvm.add %111, %216  : i64
    %218 = llvm.add %217, %183  : i64
    %219 = llvm.getelementptr %85[%218] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %220 = llvm.bitcast %219 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %221 = llvm.load %220 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %222 = llvm.mul %123, %78  : i64
    %223 = llvm.add %111, %222  : i64
    %224 = llvm.add %223, %183  : i64
    %225 = llvm.getelementptr %85[%224] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %226 = llvm.bitcast %225 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %227 = llvm.load %226 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %228 = llvm.mul %124, %78  : i64
    %229 = llvm.add %111, %228  : i64
    %230 = llvm.add %229, %183  : i64
    %231 = llvm.getelementptr %85[%230] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %232 = llvm.bitcast %231 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %233 = llvm.load %232 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %234 = llvm.mul %183, %71  : i64
    %235 = llvm.add %112, %234  : i64
    %236 = llvm.add %235, %125  : i64
    %237 = llvm.getelementptr %93[%236] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %238 = llvm.bitcast %237 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %239 = llvm.load %238 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %240 = llvm.add %183, %74  : i64
    %241 = llvm.mul %240, %71  : i64
    %242 = llvm.add %112, %241  : i64
    %243 = llvm.add %242, %125  : i64
    %244 = llvm.getelementptr %93[%243] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %245 = llvm.bitcast %244 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %246 = llvm.load %245 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %247 = llvm.add %183, %67  : i64
    %248 = llvm.mul %247, %71  : i64
    %249 = llvm.add %112, %248  : i64
    %250 = llvm.add %249, %125  : i64
    %251 = llvm.getelementptr %93[%250] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %252 = llvm.bitcast %251 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %253 = llvm.load %252 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %254 = llvm.add %183, %66  : i64
    %255 = llvm.mul %254, %71  : i64
    %256 = llvm.add %112, %255  : i64
    %257 = llvm.add %256, %125  : i64
    %258 = llvm.getelementptr %93[%257] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %259 = llvm.bitcast %258 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %260 = llvm.load %259 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %261 = llvm.add %183, %65  : i64
    %262 = llvm.mul %261, %71  : i64
    %263 = llvm.add %112, %262  : i64
    %264 = llvm.add %263, %125  : i64
    %265 = llvm.getelementptr %93[%264] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %266 = llvm.bitcast %265 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %267 = llvm.load %266 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %268 = llvm.add %183, %64  : i64
    %269 = llvm.mul %268, %71  : i64
    %270 = llvm.add %112, %269  : i64
    %271 = llvm.add %270, %125  : i64
    %272 = llvm.getelementptr %93[%271] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %273 = llvm.bitcast %272 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %274 = llvm.load %273 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %275 = llvm.add %183, %63  : i64
    %276 = llvm.mul %275, %71  : i64
    %277 = llvm.add %112, %276  : i64
    %278 = llvm.add %277, %125  : i64
    %279 = llvm.getelementptr %93[%278] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %280 = llvm.bitcast %279 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %281 = llvm.load %280 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %282 = llvm.add %183, %62  : i64
    %283 = llvm.mul %282, %71  : i64
    %284 = llvm.add %112, %283  : i64
    %285 = llvm.add %284, %125  : i64
    %286 = llvm.getelementptr %93[%285] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %287 = llvm.bitcast %286 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %288 = llvm.load %287 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %289 = llvm.shufflevector %191, %191 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %290 = llvm.shufflevector %289, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %291 = llvm.shufflevector %197, %197 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %293 = llvm.shufflevector %203, %203 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %295 = llvm.shufflevector %209, %209 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %297 = llvm.shufflevector %215, %215 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %299 = llvm.shufflevector %221, %221 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %301 = llvm.shufflevector %227, %227 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %303 = llvm.shufflevector %233, %233 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %304 = llvm.shufflevector %303, %302 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
    %305 = llvm.shufflevector %304, %304 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
    %306 = llvm.extractelement %305[%75 : i64] : vector<64xf32>
    %307 = llvm.mlir.undef : vector<8xf32>
    %308 = llvm.insertelement %306, %307[%61 : i32] : vector<8xf32>
    %309 = llvm.shufflevector %308, %307 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %310 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %311 = llvm.intr.fmuladd(%309, %239, %310)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %312 = llvm.extractelement %305[%72 : i64] : vector<64xf32>
    %313 = llvm.mlir.undef : vector<8xf32>
    %314 = llvm.insertelement %312, %313[%61 : i32] : vector<8xf32>
    %315 = llvm.shufflevector %314, %313 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %316 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %317 = llvm.intr.fmuladd(%315, %239, %316)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %318 = llvm.extractelement %305[%70 : i64] : vector<64xf32>
    %319 = llvm.mlir.undef : vector<8xf32>
    %320 = llvm.insertelement %318, %319[%61 : i32] : vector<8xf32>
    %321 = llvm.shufflevector %320, %319 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %322 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %323 = llvm.intr.fmuladd(%321, %239, %322)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %324 = llvm.extractelement %305[%60 : i64] : vector<64xf32>
    %325 = llvm.mlir.undef : vector<8xf32>
    %326 = llvm.insertelement %324, %325[%61 : i32] : vector<8xf32>
    %327 = llvm.shufflevector %326, %325 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %328 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %329 = llvm.intr.fmuladd(%327, %239, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %330 = llvm.extractelement %305[%59 : i64] : vector<64xf32>
    %331 = llvm.mlir.undef : vector<8xf32>
    %332 = llvm.insertelement %330, %331[%61 : i32] : vector<8xf32>
    %333 = llvm.shufflevector %332, %331 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %334 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %335 = llvm.intr.fmuladd(%333, %239, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %336 = llvm.extractelement %305[%58 : i64] : vector<64xf32>
    %337 = llvm.mlir.undef : vector<8xf32>
    %338 = llvm.insertelement %336, %337[%61 : i32] : vector<8xf32>
    %339 = llvm.shufflevector %338, %337 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %340 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %341 = llvm.intr.fmuladd(%339, %239, %340)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %342 = llvm.extractelement %305[%57 : i64] : vector<64xf32>
    %343 = llvm.mlir.undef : vector<8xf32>
    %344 = llvm.insertelement %342, %343[%61 : i32] : vector<8xf32>
    %345 = llvm.shufflevector %344, %343 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %346 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %347 = llvm.intr.fmuladd(%345, %239, %346)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %348 = llvm.extractelement %305[%56 : i64] : vector<64xf32>
    %349 = llvm.mlir.undef : vector<8xf32>
    %350 = llvm.insertelement %348, %349[%61 : i32] : vector<8xf32>
    %351 = llvm.shufflevector %350, %349 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %352 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %353 = llvm.intr.fmuladd(%351, %239, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %354 = llvm.extractelement %305[%55 : i64] : vector<64xf32>
    %355 = llvm.mlir.undef : vector<8xf32>
    %356 = llvm.insertelement %354, %355[%61 : i32] : vector<8xf32>
    %357 = llvm.shufflevector %356, %355 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %358 = llvm.intr.fmuladd(%357, %246, %311)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %359 = llvm.extractelement %305[%54 : i64] : vector<64xf32>
    %360 = llvm.mlir.undef : vector<8xf32>
    %361 = llvm.insertelement %359, %360[%61 : i32] : vector<8xf32>
    %362 = llvm.shufflevector %361, %360 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %363 = llvm.intr.fmuladd(%362, %246, %317)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %364 = llvm.extractelement %305[%53 : i64] : vector<64xf32>
    %365 = llvm.mlir.undef : vector<8xf32>
    %366 = llvm.insertelement %364, %365[%61 : i32] : vector<8xf32>
    %367 = llvm.shufflevector %366, %365 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %368 = llvm.intr.fmuladd(%367, %246, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %369 = llvm.extractelement %305[%52 : i64] : vector<64xf32>
    %370 = llvm.mlir.undef : vector<8xf32>
    %371 = llvm.insertelement %369, %370[%61 : i32] : vector<8xf32>
    %372 = llvm.shufflevector %371, %370 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %373 = llvm.intr.fmuladd(%372, %246, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %374 = llvm.extractelement %305[%51 : i64] : vector<64xf32>
    %375 = llvm.mlir.undef : vector<8xf32>
    %376 = llvm.insertelement %374, %375[%61 : i32] : vector<8xf32>
    %377 = llvm.shufflevector %376, %375 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %378 = llvm.intr.fmuladd(%377, %246, %335)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %379 = llvm.extractelement %305[%50 : i64] : vector<64xf32>
    %380 = llvm.mlir.undef : vector<8xf32>
    %381 = llvm.insertelement %379, %380[%61 : i32] : vector<8xf32>
    %382 = llvm.shufflevector %381, %380 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %383 = llvm.intr.fmuladd(%382, %246, %341)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %384 = llvm.extractelement %305[%49 : i64] : vector<64xf32>
    %385 = llvm.mlir.undef : vector<8xf32>
    %386 = llvm.insertelement %384, %385[%61 : i32] : vector<8xf32>
    %387 = llvm.shufflevector %386, %385 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %388 = llvm.intr.fmuladd(%387, %246, %347)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %389 = llvm.extractelement %305[%48 : i64] : vector<64xf32>
    %390 = llvm.mlir.undef : vector<8xf32>
    %391 = llvm.insertelement %389, %390[%61 : i32] : vector<8xf32>
    %392 = llvm.shufflevector %391, %390 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %393 = llvm.intr.fmuladd(%392, %246, %353)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %394 = llvm.extractelement %305[%47 : i64] : vector<64xf32>
    %395 = llvm.mlir.undef : vector<8xf32>
    %396 = llvm.insertelement %394, %395[%61 : i32] : vector<8xf32>
    %397 = llvm.shufflevector %396, %395 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %398 = llvm.intr.fmuladd(%397, %253, %358)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %399 = llvm.extractelement %305[%46 : i64] : vector<64xf32>
    %400 = llvm.mlir.undef : vector<8xf32>
    %401 = llvm.insertelement %399, %400[%61 : i32] : vector<8xf32>
    %402 = llvm.shufflevector %401, %400 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %403 = llvm.intr.fmuladd(%402, %253, %363)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %404 = llvm.extractelement %305[%45 : i64] : vector<64xf32>
    %405 = llvm.mlir.undef : vector<8xf32>
    %406 = llvm.insertelement %404, %405[%61 : i32] : vector<8xf32>
    %407 = llvm.shufflevector %406, %405 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %408 = llvm.intr.fmuladd(%407, %253, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %409 = llvm.extractelement %305[%44 : i64] : vector<64xf32>
    %410 = llvm.mlir.undef : vector<8xf32>
    %411 = llvm.insertelement %409, %410[%61 : i32] : vector<8xf32>
    %412 = llvm.shufflevector %411, %410 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %413 = llvm.intr.fmuladd(%412, %253, %373)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %414 = llvm.extractelement %305[%43 : i64] : vector<64xf32>
    %415 = llvm.mlir.undef : vector<8xf32>
    %416 = llvm.insertelement %414, %415[%61 : i32] : vector<8xf32>
    %417 = llvm.shufflevector %416, %415 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %418 = llvm.intr.fmuladd(%417, %253, %378)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %419 = llvm.extractelement %305[%42 : i64] : vector<64xf32>
    %420 = llvm.mlir.undef : vector<8xf32>
    %421 = llvm.insertelement %419, %420[%61 : i32] : vector<8xf32>
    %422 = llvm.shufflevector %421, %420 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %423 = llvm.intr.fmuladd(%422, %253, %383)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %424 = llvm.extractelement %305[%41 : i64] : vector<64xf32>
    %425 = llvm.mlir.undef : vector<8xf32>
    %426 = llvm.insertelement %424, %425[%61 : i32] : vector<8xf32>
    %427 = llvm.shufflevector %426, %425 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %428 = llvm.intr.fmuladd(%427, %253, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %429 = llvm.extractelement %305[%40 : i64] : vector<64xf32>
    %430 = llvm.mlir.undef : vector<8xf32>
    %431 = llvm.insertelement %429, %430[%61 : i32] : vector<8xf32>
    %432 = llvm.shufflevector %431, %430 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %433 = llvm.intr.fmuladd(%432, %253, %393)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %434 = llvm.extractelement %305[%39 : i64] : vector<64xf32>
    %435 = llvm.mlir.undef : vector<8xf32>
    %436 = llvm.insertelement %434, %435[%61 : i32] : vector<8xf32>
    %437 = llvm.shufflevector %436, %435 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %438 = llvm.intr.fmuladd(%437, %260, %398)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %439 = llvm.extractelement %305[%38 : i64] : vector<64xf32>
    %440 = llvm.mlir.undef : vector<8xf32>
    %441 = llvm.insertelement %439, %440[%61 : i32] : vector<8xf32>
    %442 = llvm.shufflevector %441, %440 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %443 = llvm.intr.fmuladd(%442, %260, %403)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %444 = llvm.extractelement %305[%37 : i64] : vector<64xf32>
    %445 = llvm.mlir.undef : vector<8xf32>
    %446 = llvm.insertelement %444, %445[%61 : i32] : vector<8xf32>
    %447 = llvm.shufflevector %446, %445 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %448 = llvm.intr.fmuladd(%447, %260, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %449 = llvm.extractelement %305[%36 : i64] : vector<64xf32>
    %450 = llvm.mlir.undef : vector<8xf32>
    %451 = llvm.insertelement %449, %450[%61 : i32] : vector<8xf32>
    %452 = llvm.shufflevector %451, %450 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %453 = llvm.intr.fmuladd(%452, %260, %413)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %454 = llvm.extractelement %305[%35 : i64] : vector<64xf32>
    %455 = llvm.mlir.undef : vector<8xf32>
    %456 = llvm.insertelement %454, %455[%61 : i32] : vector<8xf32>
    %457 = llvm.shufflevector %456, %455 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %458 = llvm.intr.fmuladd(%457, %260, %418)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %459 = llvm.extractelement %305[%34 : i64] : vector<64xf32>
    %460 = llvm.mlir.undef : vector<8xf32>
    %461 = llvm.insertelement %459, %460[%61 : i32] : vector<8xf32>
    %462 = llvm.shufflevector %461, %460 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %463 = llvm.intr.fmuladd(%462, %260, %423)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %464 = llvm.extractelement %305[%33 : i64] : vector<64xf32>
    %465 = llvm.mlir.undef : vector<8xf32>
    %466 = llvm.insertelement %464, %465[%61 : i32] : vector<8xf32>
    %467 = llvm.shufflevector %466, %465 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %468 = llvm.intr.fmuladd(%467, %260, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %469 = llvm.extractelement %305[%32 : i64] : vector<64xf32>
    %470 = llvm.mlir.undef : vector<8xf32>
    %471 = llvm.insertelement %469, %470[%61 : i32] : vector<8xf32>
    %472 = llvm.shufflevector %471, %470 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %473 = llvm.intr.fmuladd(%472, %260, %433)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %474 = llvm.extractelement %305[%31 : i64] : vector<64xf32>
    %475 = llvm.mlir.undef : vector<8xf32>
    %476 = llvm.insertelement %474, %475[%61 : i32] : vector<8xf32>
    %477 = llvm.shufflevector %476, %475 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %478 = llvm.intr.fmuladd(%477, %267, %438)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %479 = llvm.extractelement %305[%30 : i64] : vector<64xf32>
    %480 = llvm.mlir.undef : vector<8xf32>
    %481 = llvm.insertelement %479, %480[%61 : i32] : vector<8xf32>
    %482 = llvm.shufflevector %481, %480 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %483 = llvm.intr.fmuladd(%482, %267, %443)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %484 = llvm.extractelement %305[%29 : i64] : vector<64xf32>
    %485 = llvm.mlir.undef : vector<8xf32>
    %486 = llvm.insertelement %484, %485[%61 : i32] : vector<8xf32>
    %487 = llvm.shufflevector %486, %485 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %488 = llvm.intr.fmuladd(%487, %267, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %489 = llvm.extractelement %305[%28 : i64] : vector<64xf32>
    %490 = llvm.mlir.undef : vector<8xf32>
    %491 = llvm.insertelement %489, %490[%61 : i32] : vector<8xf32>
    %492 = llvm.shufflevector %491, %490 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %493 = llvm.intr.fmuladd(%492, %267, %453)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %494 = llvm.extractelement %305[%27 : i64] : vector<64xf32>
    %495 = llvm.mlir.undef : vector<8xf32>
    %496 = llvm.insertelement %494, %495[%61 : i32] : vector<8xf32>
    %497 = llvm.shufflevector %496, %495 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %498 = llvm.intr.fmuladd(%497, %267, %458)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %499 = llvm.extractelement %305[%26 : i64] : vector<64xf32>
    %500 = llvm.mlir.undef : vector<8xf32>
    %501 = llvm.insertelement %499, %500[%61 : i32] : vector<8xf32>
    %502 = llvm.shufflevector %501, %500 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %503 = llvm.intr.fmuladd(%502, %267, %463)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %504 = llvm.extractelement %305[%25 : i64] : vector<64xf32>
    %505 = llvm.mlir.undef : vector<8xf32>
    %506 = llvm.insertelement %504, %505[%61 : i32] : vector<8xf32>
    %507 = llvm.shufflevector %506, %505 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %508 = llvm.intr.fmuladd(%507, %267, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %509 = llvm.extractelement %305[%24 : i64] : vector<64xf32>
    %510 = llvm.mlir.undef : vector<8xf32>
    %511 = llvm.insertelement %509, %510[%61 : i32] : vector<8xf32>
    %512 = llvm.shufflevector %511, %510 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %513 = llvm.intr.fmuladd(%512, %267, %473)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %514 = llvm.extractelement %305[%23 : i64] : vector<64xf32>
    %515 = llvm.mlir.undef : vector<8xf32>
    %516 = llvm.insertelement %514, %515[%61 : i32] : vector<8xf32>
    %517 = llvm.shufflevector %516, %515 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %518 = llvm.intr.fmuladd(%517, %274, %478)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %519 = llvm.extractelement %305[%22 : i64] : vector<64xf32>
    %520 = llvm.mlir.undef : vector<8xf32>
    %521 = llvm.insertelement %519, %520[%61 : i32] : vector<8xf32>
    %522 = llvm.shufflevector %521, %520 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %523 = llvm.intr.fmuladd(%522, %274, %483)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %524 = llvm.extractelement %305[%21 : i64] : vector<64xf32>
    %525 = llvm.mlir.undef : vector<8xf32>
    %526 = llvm.insertelement %524, %525[%61 : i32] : vector<8xf32>
    %527 = llvm.shufflevector %526, %525 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %528 = llvm.intr.fmuladd(%527, %274, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %529 = llvm.extractelement %305[%20 : i64] : vector<64xf32>
    %530 = llvm.mlir.undef : vector<8xf32>
    %531 = llvm.insertelement %529, %530[%61 : i32] : vector<8xf32>
    %532 = llvm.shufflevector %531, %530 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %533 = llvm.intr.fmuladd(%532, %274, %493)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %534 = llvm.extractelement %305[%19 : i64] : vector<64xf32>
    %535 = llvm.mlir.undef : vector<8xf32>
    %536 = llvm.insertelement %534, %535[%61 : i32] : vector<8xf32>
    %537 = llvm.shufflevector %536, %535 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %538 = llvm.intr.fmuladd(%537, %274, %498)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %539 = llvm.extractelement %305[%18 : i64] : vector<64xf32>
    %540 = llvm.mlir.undef : vector<8xf32>
    %541 = llvm.insertelement %539, %540[%61 : i32] : vector<8xf32>
    %542 = llvm.shufflevector %541, %540 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %543 = llvm.intr.fmuladd(%542, %274, %503)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %544 = llvm.extractelement %305[%17 : i64] : vector<64xf32>
    %545 = llvm.mlir.undef : vector<8xf32>
    %546 = llvm.insertelement %544, %545[%61 : i32] : vector<8xf32>
    %547 = llvm.shufflevector %546, %545 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %548 = llvm.intr.fmuladd(%547, %274, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %549 = llvm.extractelement %305[%16 : i64] : vector<64xf32>
    %550 = llvm.mlir.undef : vector<8xf32>
    %551 = llvm.insertelement %549, %550[%61 : i32] : vector<8xf32>
    %552 = llvm.shufflevector %551, %550 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %553 = llvm.intr.fmuladd(%552, %274, %513)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %554 = llvm.extractelement %305[%15 : i64] : vector<64xf32>
    %555 = llvm.mlir.undef : vector<8xf32>
    %556 = llvm.insertelement %554, %555[%61 : i32] : vector<8xf32>
    %557 = llvm.shufflevector %556, %555 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %558 = llvm.intr.fmuladd(%557, %281, %518)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %559 = llvm.extractelement %305[%14 : i64] : vector<64xf32>
    %560 = llvm.mlir.undef : vector<8xf32>
    %561 = llvm.insertelement %559, %560[%61 : i32] : vector<8xf32>
    %562 = llvm.shufflevector %561, %560 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %563 = llvm.intr.fmuladd(%562, %281, %523)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %564 = llvm.extractelement %305[%13 : i64] : vector<64xf32>
    %565 = llvm.mlir.undef : vector<8xf32>
    %566 = llvm.insertelement %564, %565[%61 : i32] : vector<8xf32>
    %567 = llvm.shufflevector %566, %565 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %568 = llvm.intr.fmuladd(%567, %281, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %569 = llvm.extractelement %305[%12 : i64] : vector<64xf32>
    %570 = llvm.mlir.undef : vector<8xf32>
    %571 = llvm.insertelement %569, %570[%61 : i32] : vector<8xf32>
    %572 = llvm.shufflevector %571, %570 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %573 = llvm.intr.fmuladd(%572, %281, %533)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %574 = llvm.extractelement %305[%11 : i64] : vector<64xf32>
    %575 = llvm.mlir.undef : vector<8xf32>
    %576 = llvm.insertelement %574, %575[%61 : i32] : vector<8xf32>
    %577 = llvm.shufflevector %576, %575 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %578 = llvm.intr.fmuladd(%577, %281, %538)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %579 = llvm.extractelement %305[%10 : i64] : vector<64xf32>
    %580 = llvm.mlir.undef : vector<8xf32>
    %581 = llvm.insertelement %579, %580[%61 : i32] : vector<8xf32>
    %582 = llvm.shufflevector %581, %580 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %583 = llvm.intr.fmuladd(%582, %281, %543)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %584 = llvm.extractelement %305[%9 : i64] : vector<64xf32>
    %585 = llvm.mlir.undef : vector<8xf32>
    %586 = llvm.insertelement %584, %585[%61 : i32] : vector<8xf32>
    %587 = llvm.shufflevector %586, %585 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %588 = llvm.intr.fmuladd(%587, %281, %548)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %589 = llvm.extractelement %305[%8 : i64] : vector<64xf32>
    %590 = llvm.mlir.undef : vector<8xf32>
    %591 = llvm.insertelement %589, %590[%61 : i32] : vector<8xf32>
    %592 = llvm.shufflevector %591, %590 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %593 = llvm.intr.fmuladd(%592, %281, %553)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %594 = llvm.extractelement %305[%7 : i64] : vector<64xf32>
    %595 = llvm.mlir.undef : vector<8xf32>
    %596 = llvm.insertelement %594, %595[%61 : i32] : vector<8xf32>
    %597 = llvm.shufflevector %596, %595 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %598 = llvm.intr.fmuladd(%597, %288, %558)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %599 = llvm.insertvalue %598, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %600 = llvm.extractelement %305[%6 : i64] : vector<64xf32>
    %601 = llvm.mlir.undef : vector<8xf32>
    %602 = llvm.insertelement %600, %601[%61 : i32] : vector<8xf32>
    %603 = llvm.shufflevector %602, %601 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %604 = llvm.intr.fmuladd(%603, %288, %563)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %605 = llvm.insertvalue %604, %599[1] : !llvm.array<8 x vector<8xf32>> 
    %606 = llvm.extractelement %305[%5 : i64] : vector<64xf32>
    %607 = llvm.mlir.undef : vector<8xf32>
    %608 = llvm.insertelement %606, %607[%61 : i32] : vector<8xf32>
    %609 = llvm.shufflevector %608, %607 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %610 = llvm.intr.fmuladd(%609, %288, %568)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %611 = llvm.insertvalue %610, %605[2] : !llvm.array<8 x vector<8xf32>> 
    %612 = llvm.extractelement %305[%4 : i64] : vector<64xf32>
    %613 = llvm.mlir.undef : vector<8xf32>
    %614 = llvm.insertelement %612, %613[%61 : i32] : vector<8xf32>
    %615 = llvm.shufflevector %614, %613 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %616 = llvm.intr.fmuladd(%615, %288, %573)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %617 = llvm.insertvalue %616, %611[3] : !llvm.array<8 x vector<8xf32>> 
    %618 = llvm.extractelement %305[%3 : i64] : vector<64xf32>
    %619 = llvm.mlir.undef : vector<8xf32>
    %620 = llvm.insertelement %618, %619[%61 : i32] : vector<8xf32>
    %621 = llvm.shufflevector %620, %619 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %622 = llvm.intr.fmuladd(%621, %288, %578)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %623 = llvm.insertvalue %622, %617[4] : !llvm.array<8 x vector<8xf32>> 
    %624 = llvm.extractelement %305[%2 : i64] : vector<64xf32>
    %625 = llvm.mlir.undef : vector<8xf32>
    %626 = llvm.insertelement %624, %625[%61 : i32] : vector<8xf32>
    %627 = llvm.shufflevector %626, %625 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %628 = llvm.intr.fmuladd(%627, %288, %583)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %629 = llvm.insertvalue %628, %623[5] : !llvm.array<8 x vector<8xf32>> 
    %630 = llvm.extractelement %305[%1 : i64] : vector<64xf32>
    %631 = llvm.mlir.undef : vector<8xf32>
    %632 = llvm.insertelement %630, %631[%61 : i32] : vector<8xf32>
    %633 = llvm.shufflevector %632, %631 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %634 = llvm.intr.fmuladd(%633, %288, %588)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %635 = llvm.insertvalue %634, %629[6] : !llvm.array<8 x vector<8xf32>> 
    %636 = llvm.extractelement %305[%0 : i64] : vector<64xf32>
    %637 = llvm.mlir.undef : vector<8xf32>
    %638 = llvm.insertelement %636, %637[%61 : i32] : vector<8xf32>
    %639 = llvm.shufflevector %638, %637 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %640 = llvm.intr.fmuladd(%639, %288, %593)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %641 = llvm.insertvalue %640, %635[7] : !llvm.array<8 x vector<8xf32>> 
    %642 = llvm.add %183, %79  : i64
    llvm.br ^bb5(%642, %641 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb7:  // pred: ^bb5
    %643 = llvm.extractvalue %184[0] : !llvm.array<8 x vector<8xf32>> 
    %644 = llvm.mul %116, %71  : i64
    %645 = llvm.add %115, %644  : i64
    %646 = llvm.add %645, %125  : i64
    %647 = llvm.getelementptr %101[%646] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %648 = llvm.bitcast %647 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %643, %648 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %649 = llvm.extractvalue %184[1] : !llvm.array<8 x vector<8xf32>> 
    %650 = llvm.mul %118, %71  : i64
    %651 = llvm.add %115, %650  : i64
    %652 = llvm.add %651, %125  : i64
    %653 = llvm.getelementptr %101[%652] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %654 = llvm.bitcast %653 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %649, %654 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %655 = llvm.extractvalue %184[2] : !llvm.array<8 x vector<8xf32>> 
    %656 = llvm.mul %119, %71  : i64
    %657 = llvm.add %115, %656  : i64
    %658 = llvm.add %657, %125  : i64
    %659 = llvm.getelementptr %101[%658] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %660 = llvm.bitcast %659 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %655, %660 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %661 = llvm.extractvalue %184[3] : !llvm.array<8 x vector<8xf32>> 
    %662 = llvm.mul %120, %71  : i64
    %663 = llvm.add %115, %662  : i64
    %664 = llvm.add %663, %125  : i64
    %665 = llvm.getelementptr %101[%664] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %666 = llvm.bitcast %665 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %661, %666 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %667 = llvm.extractvalue %184[4] : !llvm.array<8 x vector<8xf32>> 
    %668 = llvm.mul %121, %71  : i64
    %669 = llvm.add %115, %668  : i64
    %670 = llvm.add %669, %125  : i64
    %671 = llvm.getelementptr %101[%670] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %672 = llvm.bitcast %671 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %667, %672 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %673 = llvm.extractvalue %184[5] : !llvm.array<8 x vector<8xf32>> 
    %674 = llvm.mul %122, %71  : i64
    %675 = llvm.add %115, %674  : i64
    %676 = llvm.add %675, %125  : i64
    %677 = llvm.getelementptr %101[%676] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %678 = llvm.bitcast %677 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %673, %678 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %679 = llvm.extractvalue %184[6] : !llvm.array<8 x vector<8xf32>> 
    %680 = llvm.mul %123, %71  : i64
    %681 = llvm.add %115, %680  : i64
    %682 = llvm.add %681, %125  : i64
    %683 = llvm.getelementptr %101[%682] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %684 = llvm.bitcast %683 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %679, %684 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %685 = llvm.extractvalue %184[7] : !llvm.array<8 x vector<8xf32>> 
    %686 = llvm.mul %124, %71  : i64
    %687 = llvm.add %115, %686  : i64
    %688 = llvm.add %687, %125  : i64
    %689 = llvm.getelementptr %101[%688] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %690 = llvm.bitcast %689 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    llvm.store %685, %690 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %691 = llvm.add %125, %79  : i64
    llvm.br ^bb3(%691 : i64)
  ^bb8:  // pred: ^bb3
    %692 = llvm.add %116, %79  : i64
    llvm.br ^bb1(%692 : i64)
  ^bb9:  // pred: ^bb1
    llvm.return %61 : i32
  }
}

// -----// IR Dump After CSE (cse) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(63 : i64) : i64
    %1 = llvm.mlir.constant(62 : i64) : i64
    %2 = llvm.mlir.constant(61 : i64) : i64
    %3 = llvm.mlir.constant(60 : i64) : i64
    %4 = llvm.mlir.constant(59 : i64) : i64
    %5 = llvm.mlir.constant(58 : i64) : i64
    %6 = llvm.mlir.constant(57 : i64) : i64
    %7 = llvm.mlir.constant(56 : i64) : i64
    %8 = llvm.mlir.constant(55 : i64) : i64
    %9 = llvm.mlir.constant(54 : i64) : i64
    %10 = llvm.mlir.constant(53 : i64) : i64
    %11 = llvm.mlir.constant(52 : i64) : i64
    %12 = llvm.mlir.constant(51 : i64) : i64
    %13 = llvm.mlir.constant(50 : i64) : i64
    %14 = llvm.mlir.constant(49 : i64) : i64
    %15 = llvm.mlir.constant(48 : i64) : i64
    %16 = llvm.mlir.constant(47 : i64) : i64
    %17 = llvm.mlir.constant(46 : i64) : i64
    %18 = llvm.mlir.constant(45 : i64) : i64
    %19 = llvm.mlir.constant(44 : i64) : i64
    %20 = llvm.mlir.constant(43 : i64) : i64
    %21 = llvm.mlir.constant(42 : i64) : i64
    %22 = llvm.mlir.constant(41 : i64) : i64
    %23 = llvm.mlir.constant(40 : i64) : i64
    %24 = llvm.mlir.constant(39 : i64) : i64
    %25 = llvm.mlir.constant(38 : i64) : i64
    %26 = llvm.mlir.constant(37 : i64) : i64
    %27 = llvm.mlir.constant(36 : i64) : i64
    %28 = llvm.mlir.constant(35 : i64) : i64
    %29 = llvm.mlir.constant(34 : i64) : i64
    %30 = llvm.mlir.constant(33 : i64) : i64
    %31 = llvm.mlir.constant(32 : i64) : i64
    %32 = llvm.mlir.constant(31 : i64) : i64
    %33 = llvm.mlir.constant(30 : i64) : i64
    %34 = llvm.mlir.constant(29 : i64) : i64
    %35 = llvm.mlir.constant(28 : i64) : i64
    %36 = llvm.mlir.constant(27 : i64) : i64
    %37 = llvm.mlir.constant(26 : i64) : i64
    %38 = llvm.mlir.constant(25 : i64) : i64
    %39 = llvm.mlir.constant(24 : i64) : i64
    %40 = llvm.mlir.constant(23 : i64) : i64
    %41 = llvm.mlir.constant(22 : i64) : i64
    %42 = llvm.mlir.constant(21 : i64) : i64
    %43 = llvm.mlir.constant(20 : i64) : i64
    %44 = llvm.mlir.constant(19 : i64) : i64
    %45 = llvm.mlir.constant(18 : i64) : i64
    %46 = llvm.mlir.constant(17 : i64) : i64
    %47 = llvm.mlir.constant(16 : i64) : i64
    %48 = llvm.mlir.constant(15 : i64) : i64
    %49 = llvm.mlir.constant(14 : i64) : i64
    %50 = llvm.mlir.constant(13 : i64) : i64
    %51 = llvm.mlir.constant(12 : i64) : i64
    %52 = llvm.mlir.constant(11 : i64) : i64
    %53 = llvm.mlir.constant(10 : i64) : i64
    %54 = llvm.mlir.constant(9 : i64) : i64
    %55 = llvm.mlir.constant(8 : i64) : i64
    %56 = llvm.mlir.constant(7 : i64) : i64
    %57 = llvm.mlir.constant(6 : i64) : i64
    %58 = llvm.mlir.constant(5 : i64) : i64
    %59 = llvm.mlir.constant(4 : i64) : i64
    %60 = llvm.mlir.constant(3 : i64) : i64
    %61 = llvm.mlir.constant(0 : i32) : i32
    %62 = llvm.mlir.constant(7 : index) : i64
    %63 = llvm.mlir.constant(6 : index) : i64
    %64 = llvm.mlir.constant(5 : index) : i64
    %65 = llvm.mlir.constant(4 : index) : i64
    %66 = llvm.mlir.constant(3 : index) : i64
    %67 = llvm.mlir.constant(2 : index) : i64
    %68 = llvm.mlir.constant(32768 : index) : i64
    %69 = llvm.mlir.constant(8192 : index) : i64
    %70 = llvm.mlir.constant(2 : i64) : i64
    %71 = llvm.mlir.constant(1024 : index) : i64
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.constant(63 : index) : i64
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.mlir.constant(0 : i64) : i64
    %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
    %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
    %78 = llvm.mlir.constant(256 : index) : i64
    %79 = llvm.mlir.constant(8 : index) : i64
    %80 = llvm.mlir.constant(32 : index) : i64
    %81 = llvm.mlir.constant(0 : index) : i64
    %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
    %87 = llvm.and %86, %73  : i64
    %88 = llvm.icmp "eq" %87, %81 : i64
    "llvm.intr.assume"(%88) : (i1) -> ()
    %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
    %95 = llvm.and %94, %73  : i64
    %96 = llvm.icmp "eq" %95, %81 : i64
    "llvm.intr.assume"(%96) : (i1) -> ()
    %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
    %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
    %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
    %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
    %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
    %103 = llvm.and %102, %73  : i64
    %104 = llvm.icmp "eq" %103, %81 : i64
    "llvm.intr.assume"(%104) : (i1) -> ()
    %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
    %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %107 = llvm.zext %106 : i32 to i64
    %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
    %109 = llvm.zext %108 : i32 to i64
    %110 = llvm.mul %109, %69  : i64
    %111 = llvm.mul %107, %80  : i64
    %112 = llvm.mul %109, %68  : i64
    %113 = llvm.add %112, %111  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
    %115 = llvm.icmp "slt" %114, %80 : i64
    llvm.cond_br %115, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %116 = llvm.add %114, %74  : i64
    %117 = llvm.add %114, %67  : i64
    %118 = llvm.add %114, %66  : i64
    %119 = llvm.add %114, %65  : i64
    %120 = llvm.add %114, %64  : i64
    %121 = llvm.add %114, %63  : i64
    %122 = llvm.add %114, %62  : i64
    llvm.br ^bb3(%81 : i64)
  ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
    %124 = llvm.icmp "slt" %123, %80 : i64
    llvm.cond_br %124, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %125 = llvm.mul %114, %71  : i64
    %126 = llvm.add %113, %125  : i64
    %127 = llvm.add %126, %123  : i64
    %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %132 = llvm.mul %116, %71  : i64
    %133 = llvm.add %113, %132  : i64
    %134 = llvm.add %133, %123  : i64
    %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
    %139 = llvm.mul %117, %71  : i64
    %140 = llvm.add %113, %139  : i64
    %141 = llvm.add %140, %123  : i64
    %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
    %146 = llvm.mul %118, %71  : i64
    %147 = llvm.add %113, %146  : i64
    %148 = llvm.add %147, %123  : i64
    %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
    %153 = llvm.mul %119, %71  : i64
    %154 = llvm.add %113, %153  : i64
    %155 = llvm.add %154, %123  : i64
    %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
    %160 = llvm.mul %120, %71  : i64
    %161 = llvm.add %113, %160  : i64
    %162 = llvm.add %161, %123  : i64
    %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
    %167 = llvm.mul %121, %71  : i64
    %168 = llvm.add %113, %167  : i64
    %169 = llvm.add %168, %123  : i64
    %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
    %174 = llvm.mul %122, %71  : i64
    %175 = llvm.add %113, %174  : i64
    %176 = llvm.add %175, %123  : i64
    %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
    %183 = llvm.icmp "slt" %181, %78 : i64
    llvm.cond_br %183, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %184 = llvm.mul %114, %78  : i64
    %185 = llvm.add %110, %184  : i64
    %186 = llvm.add %185, %181  : i64
    %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %190 = llvm.mul %116, %78  : i64
    %191 = llvm.add %110, %190  : i64
    %192 = llvm.add %191, %181  : i64
    %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %196 = llvm.mul %117, %78  : i64
    %197 = llvm.add %110, %196  : i64
    %198 = llvm.add %197, %181  : i64
    %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %202 = llvm.mul %118, %78  : i64
    %203 = llvm.add %110, %202  : i64
    %204 = llvm.add %203, %181  : i64
    %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %208 = llvm.mul %119, %78  : i64
    %209 = llvm.add %110, %208  : i64
    %210 = llvm.add %209, %181  : i64
    %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %214 = llvm.mul %120, %78  : i64
    %215 = llvm.add %110, %214  : i64
    %216 = llvm.add %215, %181  : i64
    %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %220 = llvm.mul %121, %78  : i64
    %221 = llvm.add %110, %220  : i64
    %222 = llvm.add %221, %181  : i64
    %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %226 = llvm.mul %122, %78  : i64
    %227 = llvm.add %110, %226  : i64
    %228 = llvm.add %227, %181  : i64
    %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %232 = llvm.mul %181, %71  : i64
    %233 = llvm.add %111, %232  : i64
    %234 = llvm.add %233, %123  : i64
    %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %238 = llvm.add %181, %74  : i64
    %239 = llvm.mul %238, %71  : i64
    %240 = llvm.add %111, %239  : i64
    %241 = llvm.add %240, %123  : i64
    %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %245 = llvm.add %181, %67  : i64
    %246 = llvm.mul %245, %71  : i64
    %247 = llvm.add %111, %246  : i64
    %248 = llvm.add %247, %123  : i64
    %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %252 = llvm.add %181, %66  : i64
    %253 = llvm.mul %252, %71  : i64
    %254 = llvm.add %111, %253  : i64
    %255 = llvm.add %254, %123  : i64
    %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %259 = llvm.add %181, %65  : i64
    %260 = llvm.mul %259, %71  : i64
    %261 = llvm.add %111, %260  : i64
    %262 = llvm.add %261, %123  : i64
    %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %266 = llvm.add %181, %64  : i64
    %267 = llvm.mul %266, %71  : i64
    %268 = llvm.add %111, %267  : i64
    %269 = llvm.add %268, %123  : i64
    %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %273 = llvm.add %181, %63  : i64
    %274 = llvm.mul %273, %71  : i64
    %275 = llvm.add %111, %274  : i64
    %276 = llvm.add %275, %123  : i64
    %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %280 = llvm.add %181, %62  : i64
    %281 = llvm.mul %280, %71  : i64
    %282 = llvm.add %111, %281  : i64
    %283 = llvm.add %282, %123  : i64
    %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
    %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
    %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
    %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
    %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
    %305 = llvm.mlir.undef : vector<8xf32>
    %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
    %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
    %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
    %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
    %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
    %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
    %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
    %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
    %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
    %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
    %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
    %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
    %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
    %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
    %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
    %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
    %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
    %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
    %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
    %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
    %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
    %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
    %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
    %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
    %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
    %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
    %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
    %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
    %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
    %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
    %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
    %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
    %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
    %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
    %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
    %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
    %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
    %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
    %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
    %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
    %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
    %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
    %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
    %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
    %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
    %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
    %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
    %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
    %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
    %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
    %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
    %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
    %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
    %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
    %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
    %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
    %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
    %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
    %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
    %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
    %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
    %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
    %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
    %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
    %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
    %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
    %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
    %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
    %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
    %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
    %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
    %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
    %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
    %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
    %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
    %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
    %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
    %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
    %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
    %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
    %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
    %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
    %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
    %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
    %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
    %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
    %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
    %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
    %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
    %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
    %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
    %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
    %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
    %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
    %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
    %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
    %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
    %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
    %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
    %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
    %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
    %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
    %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
    %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
    %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
    %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
    %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
    %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
    %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
    %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
    %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
    %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
    %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
    %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
    %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
    %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
    %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
    %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
    %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
    %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
    %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
    %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
    %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
    %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
    %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
    %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
    %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
    %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
    %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
    %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
    %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
    %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
    %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
    %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
    %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
    %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
    %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
    %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
    %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
    %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
    %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
    %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
    %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
    %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
    %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
    %577 = llvm.add %181, %79  : i64
    llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
  ^bb7:  // pred: ^bb5
    %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
    llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
    %586 = llvm.add %123, %79  : i64
    llvm.br ^bb3(%586 : i64)
  ^bb8:  // pred: ^bb3
    %587 = llvm.add %114, %79  : i64
    llvm.br ^bb1(%587 : i64)
  ^bb9:  // pred: ^bb1
    llvm.return %61 : i32
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
  hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    hal.return %c32, %c16, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(63 : i64) : i64
      %1 = llvm.mlir.constant(62 : i64) : i64
      %2 = llvm.mlir.constant(61 : i64) : i64
      %3 = llvm.mlir.constant(60 : i64) : i64
      %4 = llvm.mlir.constant(59 : i64) : i64
      %5 = llvm.mlir.constant(58 : i64) : i64
      %6 = llvm.mlir.constant(57 : i64) : i64
      %7 = llvm.mlir.constant(56 : i64) : i64
      %8 = llvm.mlir.constant(55 : i64) : i64
      %9 = llvm.mlir.constant(54 : i64) : i64
      %10 = llvm.mlir.constant(53 : i64) : i64
      %11 = llvm.mlir.constant(52 : i64) : i64
      %12 = llvm.mlir.constant(51 : i64) : i64
      %13 = llvm.mlir.constant(50 : i64) : i64
      %14 = llvm.mlir.constant(49 : i64) : i64
      %15 = llvm.mlir.constant(48 : i64) : i64
      %16 = llvm.mlir.constant(47 : i64) : i64
      %17 = llvm.mlir.constant(46 : i64) : i64
      %18 = llvm.mlir.constant(45 : i64) : i64
      %19 = llvm.mlir.constant(44 : i64) : i64
      %20 = llvm.mlir.constant(43 : i64) : i64
      %21 = llvm.mlir.constant(42 : i64) : i64
      %22 = llvm.mlir.constant(41 : i64) : i64
      %23 = llvm.mlir.constant(40 : i64) : i64
      %24 = llvm.mlir.constant(39 : i64) : i64
      %25 = llvm.mlir.constant(38 : i64) : i64
      %26 = llvm.mlir.constant(37 : i64) : i64
      %27 = llvm.mlir.constant(36 : i64) : i64
      %28 = llvm.mlir.constant(35 : i64) : i64
      %29 = llvm.mlir.constant(34 : i64) : i64
      %30 = llvm.mlir.constant(33 : i64) : i64
      %31 = llvm.mlir.constant(32 : i64) : i64
      %32 = llvm.mlir.constant(31 : i64) : i64
      %33 = llvm.mlir.constant(30 : i64) : i64
      %34 = llvm.mlir.constant(29 : i64) : i64
      %35 = llvm.mlir.constant(28 : i64) : i64
      %36 = llvm.mlir.constant(27 : i64) : i64
      %37 = llvm.mlir.constant(26 : i64) : i64
      %38 = llvm.mlir.constant(25 : i64) : i64
      %39 = llvm.mlir.constant(24 : i64) : i64
      %40 = llvm.mlir.constant(23 : i64) : i64
      %41 = llvm.mlir.constant(22 : i64) : i64
      %42 = llvm.mlir.constant(21 : i64) : i64
      %43 = llvm.mlir.constant(20 : i64) : i64
      %44 = llvm.mlir.constant(19 : i64) : i64
      %45 = llvm.mlir.constant(18 : i64) : i64
      %46 = llvm.mlir.constant(17 : i64) : i64
      %47 = llvm.mlir.constant(16 : i64) : i64
      %48 = llvm.mlir.constant(15 : i64) : i64
      %49 = llvm.mlir.constant(14 : i64) : i64
      %50 = llvm.mlir.constant(13 : i64) : i64
      %51 = llvm.mlir.constant(12 : i64) : i64
      %52 = llvm.mlir.constant(11 : i64) : i64
      %53 = llvm.mlir.constant(10 : i64) : i64
      %54 = llvm.mlir.constant(9 : i64) : i64
      %55 = llvm.mlir.constant(8 : i64) : i64
      %56 = llvm.mlir.constant(7 : i64) : i64
      %57 = llvm.mlir.constant(6 : i64) : i64
      %58 = llvm.mlir.constant(5 : i64) : i64
      %59 = llvm.mlir.constant(4 : i64) : i64
      %60 = llvm.mlir.constant(3 : i64) : i64
      %61 = llvm.mlir.constant(0 : i32) : i32
      %62 = llvm.mlir.constant(7 : index) : i64
      %63 = llvm.mlir.constant(6 : index) : i64
      %64 = llvm.mlir.constant(5 : index) : i64
      %65 = llvm.mlir.constant(4 : index) : i64
      %66 = llvm.mlir.constant(3 : index) : i64
      %67 = llvm.mlir.constant(2 : index) : i64
      %68 = llvm.mlir.constant(32768 : index) : i64
      %69 = llvm.mlir.constant(8192 : index) : i64
      %70 = llvm.mlir.constant(2 : i64) : i64
      %71 = llvm.mlir.constant(1024 : index) : i64
      %72 = llvm.mlir.constant(1 : i64) : i64
      %73 = llvm.mlir.constant(63 : index) : i64
      %74 = llvm.mlir.constant(1 : index) : i64
      %75 = llvm.mlir.constant(0 : i64) : i64
      %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
      %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
      %78 = llvm.mlir.constant(256 : index) : i64
      %79 = llvm.mlir.constant(8 : index) : i64
      %80 = llvm.mlir.constant(32 : index) : i64
      %81 = llvm.mlir.constant(0 : index) : i64
      %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
      %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
      %87 = llvm.and %86, %73  : i64
      %88 = llvm.icmp "eq" %87, %81 : i64
      "llvm.intr.assume"(%88) : (i1) -> ()
      %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
      %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
      %95 = llvm.and %94, %73  : i64
      %96 = llvm.icmp "eq" %95, %81 : i64
      "llvm.intr.assume"(%96) : (i1) -> ()
      %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
      %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
      %103 = llvm.and %102, %73  : i64
      %104 = llvm.icmp "eq" %103, %81 : i64
      "llvm.intr.assume"(%104) : (i1) -> ()
      %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
      %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %107 = llvm.zext %106 : i32 to i64
      %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %109 = llvm.zext %108 : i32 to i64
      %110 = llvm.mul %109, %69  : i64
      %111 = llvm.mul %107, %80  : i64
      %112 = llvm.mul %109, %68  : i64
      %113 = llvm.add %112, %111  : i64
      llvm.br ^bb1(%81 : i64)
    ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
      %115 = llvm.icmp "slt" %114, %80 : i64
      llvm.cond_br %115, ^bb2, ^bb9
    ^bb2:  // pred: ^bb1
      %116 = llvm.add %114, %74  : i64
      %117 = llvm.add %114, %67  : i64
      %118 = llvm.add %114, %66  : i64
      %119 = llvm.add %114, %65  : i64
      %120 = llvm.add %114, %64  : i64
      %121 = llvm.add %114, %63  : i64
      %122 = llvm.add %114, %62  : i64
      llvm.br ^bb3(%81 : i64)
    ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
      %124 = llvm.icmp "slt" %123, %80 : i64
      llvm.cond_br %124, ^bb4, ^bb8
    ^bb4:  // pred: ^bb3
      %125 = llvm.mul %114, %71  : i64
      %126 = llvm.add %113, %125  : i64
      %127 = llvm.add %126, %123  : i64
      %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %132 = llvm.mul %116, %71  : i64
      %133 = llvm.add %113, %132  : i64
      %134 = llvm.add %133, %123  : i64
      %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
      %139 = llvm.mul %117, %71  : i64
      %140 = llvm.add %113, %139  : i64
      %141 = llvm.add %140, %123  : i64
      %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
      %146 = llvm.mul %118, %71  : i64
      %147 = llvm.add %113, %146  : i64
      %148 = llvm.add %147, %123  : i64
      %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
      %153 = llvm.mul %119, %71  : i64
      %154 = llvm.add %113, %153  : i64
      %155 = llvm.add %154, %123  : i64
      %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
      %160 = llvm.mul %120, %71  : i64
      %161 = llvm.add %113, %160  : i64
      %162 = llvm.add %161, %123  : i64
      %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
      %167 = llvm.mul %121, %71  : i64
      %168 = llvm.add %113, %167  : i64
      %169 = llvm.add %168, %123  : i64
      %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
      %174 = llvm.mul %122, %71  : i64
      %175 = llvm.add %113, %174  : i64
      %176 = llvm.add %175, %123  : i64
      %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
      %183 = llvm.icmp "slt" %181, %78 : i64
      llvm.cond_br %183, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %184 = llvm.mul %114, %78  : i64
      %185 = llvm.add %110, %184  : i64
      %186 = llvm.add %185, %181  : i64
      %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %190 = llvm.mul %116, %78  : i64
      %191 = llvm.add %110, %190  : i64
      %192 = llvm.add %191, %181  : i64
      %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %196 = llvm.mul %117, %78  : i64
      %197 = llvm.add %110, %196  : i64
      %198 = llvm.add %197, %181  : i64
      %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %202 = llvm.mul %118, %78  : i64
      %203 = llvm.add %110, %202  : i64
      %204 = llvm.add %203, %181  : i64
      %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %208 = llvm.mul %119, %78  : i64
      %209 = llvm.add %110, %208  : i64
      %210 = llvm.add %209, %181  : i64
      %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %214 = llvm.mul %120, %78  : i64
      %215 = llvm.add %110, %214  : i64
      %216 = llvm.add %215, %181  : i64
      %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %220 = llvm.mul %121, %78  : i64
      %221 = llvm.add %110, %220  : i64
      %222 = llvm.add %221, %181  : i64
      %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %226 = llvm.mul %122, %78  : i64
      %227 = llvm.add %110, %226  : i64
      %228 = llvm.add %227, %181  : i64
      %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %232 = llvm.mul %181, %71  : i64
      %233 = llvm.add %111, %232  : i64
      %234 = llvm.add %233, %123  : i64
      %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %238 = llvm.add %181, %74  : i64
      %239 = llvm.mul %238, %71  : i64
      %240 = llvm.add %111, %239  : i64
      %241 = llvm.add %240, %123  : i64
      %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %245 = llvm.add %181, %67  : i64
      %246 = llvm.mul %245, %71  : i64
      %247 = llvm.add %111, %246  : i64
      %248 = llvm.add %247, %123  : i64
      %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %252 = llvm.add %181, %66  : i64
      %253 = llvm.mul %252, %71  : i64
      %254 = llvm.add %111, %253  : i64
      %255 = llvm.add %254, %123  : i64
      %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %259 = llvm.add %181, %65  : i64
      %260 = llvm.mul %259, %71  : i64
      %261 = llvm.add %111, %260  : i64
      %262 = llvm.add %261, %123  : i64
      %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %266 = llvm.add %181, %64  : i64
      %267 = llvm.mul %266, %71  : i64
      %268 = llvm.add %111, %267  : i64
      %269 = llvm.add %268, %123  : i64
      %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %273 = llvm.add %181, %63  : i64
      %274 = llvm.mul %273, %71  : i64
      %275 = llvm.add %111, %274  : i64
      %276 = llvm.add %275, %123  : i64
      %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %280 = llvm.add %181, %62  : i64
      %281 = llvm.mul %280, %71  : i64
      %282 = llvm.add %111, %281  : i64
      %283 = llvm.add %282, %123  : i64
      %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
      %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
      %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
      %305 = llvm.mlir.undef : vector<8xf32>
      %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
      %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
      %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
      %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
      %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
      %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
      %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
      %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
      %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
      %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
      %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
      %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
      %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
      %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
      %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
      %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
      %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
      %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
      %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
      %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
      %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
      %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
      %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
      %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
      %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
      %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
      %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
      %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
      %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
      %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
      %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
      %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
      %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
      %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
      %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
      %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
      %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
      %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
      %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
      %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
      %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
      %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
      %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
      %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
      %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
      %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
      %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
      %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
      %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
      %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
      %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
      %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
      %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
      %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
      %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
      %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
      %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
      %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
      %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
      %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
      %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
      %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
      %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
      %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
      %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
      %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
      %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
      %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
      %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
      %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
      %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
      %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
      %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
      %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
      %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
      %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
      %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
      %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
      %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
      %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
      %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
      %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
      %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
      %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
      %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
      %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
      %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
      %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
      %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
      %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
      %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
      %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
      %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
      %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
      %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
      %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
      %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
      %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
      %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
      %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
      %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
      %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
      %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
      %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
      %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
      %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
      %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
      %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
      %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
      %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
      %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
      %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
      %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
      %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
      %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
      %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
      %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
      %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
      %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
      %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
      %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
      %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
      %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
      %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
      %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
      %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
      %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
      %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
      %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
      %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
      %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
      %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
      %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
      %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
      %577 = llvm.add %181, %79  : i64
      llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb7:  // pred: ^bb5
      %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %586 = llvm.add %123, %79  : i64
      llvm.br ^bb3(%586 : i64)
    ^bb8:  // pred: ^bb3
      %587 = llvm.add %114, %79  : i64
      llvm.br ^bb1(%587 : i64)
    ^bb9:  // pred: ^bb1
      llvm.return %61 : i32
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateExecutablesPass (iree-hal-translate-executables) //----- //
hal.executable private @matmul_static_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
    hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
      %c32 = arith.constant 32 : index
      %c16 = arith.constant 16 : index
      %c1 = arith.constant 1 : index
      hal.return %c32, %c16, %c1 : index, index, index
    }
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
        %0 = llvm.mlir.constant(63 : i64) : i64
        %1 = llvm.mlir.constant(62 : i64) : i64
        %2 = llvm.mlir.constant(61 : i64) : i64
        %3 = llvm.mlir.constant(60 : i64) : i64
        %4 = llvm.mlir.constant(59 : i64) : i64
        %5 = llvm.mlir.constant(58 : i64) : i64
        %6 = llvm.mlir.constant(57 : i64) : i64
        %7 = llvm.mlir.constant(56 : i64) : i64
        %8 = llvm.mlir.constant(55 : i64) : i64
        %9 = llvm.mlir.constant(54 : i64) : i64
        %10 = llvm.mlir.constant(53 : i64) : i64
        %11 = llvm.mlir.constant(52 : i64) : i64
        %12 = llvm.mlir.constant(51 : i64) : i64
        %13 = llvm.mlir.constant(50 : i64) : i64
        %14 = llvm.mlir.constant(49 : i64) : i64
        %15 = llvm.mlir.constant(48 : i64) : i64
        %16 = llvm.mlir.constant(47 : i64) : i64
        %17 = llvm.mlir.constant(46 : i64) : i64
        %18 = llvm.mlir.constant(45 : i64) : i64
        %19 = llvm.mlir.constant(44 : i64) : i64
        %20 = llvm.mlir.constant(43 : i64) : i64
        %21 = llvm.mlir.constant(42 : i64) : i64
        %22 = llvm.mlir.constant(41 : i64) : i64
        %23 = llvm.mlir.constant(40 : i64) : i64
        %24 = llvm.mlir.constant(39 : i64) : i64
        %25 = llvm.mlir.constant(38 : i64) : i64
        %26 = llvm.mlir.constant(37 : i64) : i64
        %27 = llvm.mlir.constant(36 : i64) : i64
        %28 = llvm.mlir.constant(35 : i64) : i64
        %29 = llvm.mlir.constant(34 : i64) : i64
        %30 = llvm.mlir.constant(33 : i64) : i64
        %31 = llvm.mlir.constant(32 : i64) : i64
        %32 = llvm.mlir.constant(31 : i64) : i64
        %33 = llvm.mlir.constant(30 : i64) : i64
        %34 = llvm.mlir.constant(29 : i64) : i64
        %35 = llvm.mlir.constant(28 : i64) : i64
        %36 = llvm.mlir.constant(27 : i64) : i64
        %37 = llvm.mlir.constant(26 : i64) : i64
        %38 = llvm.mlir.constant(25 : i64) : i64
        %39 = llvm.mlir.constant(24 : i64) : i64
        %40 = llvm.mlir.constant(23 : i64) : i64
        %41 = llvm.mlir.constant(22 : i64) : i64
        %42 = llvm.mlir.constant(21 : i64) : i64
        %43 = llvm.mlir.constant(20 : i64) : i64
        %44 = llvm.mlir.constant(19 : i64) : i64
        %45 = llvm.mlir.constant(18 : i64) : i64
        %46 = llvm.mlir.constant(17 : i64) : i64
        %47 = llvm.mlir.constant(16 : i64) : i64
        %48 = llvm.mlir.constant(15 : i64) : i64
        %49 = llvm.mlir.constant(14 : i64) : i64
        %50 = llvm.mlir.constant(13 : i64) : i64
        %51 = llvm.mlir.constant(12 : i64) : i64
        %52 = llvm.mlir.constant(11 : i64) : i64
        %53 = llvm.mlir.constant(10 : i64) : i64
        %54 = llvm.mlir.constant(9 : i64) : i64
        %55 = llvm.mlir.constant(8 : i64) : i64
        %56 = llvm.mlir.constant(7 : i64) : i64
        %57 = llvm.mlir.constant(6 : i64) : i64
        %58 = llvm.mlir.constant(5 : i64) : i64
        %59 = llvm.mlir.constant(4 : i64) : i64
        %60 = llvm.mlir.constant(3 : i64) : i64
        %61 = llvm.mlir.constant(0 : i32) : i32
        %62 = llvm.mlir.constant(7 : index) : i64
        %63 = llvm.mlir.constant(6 : index) : i64
        %64 = llvm.mlir.constant(5 : index) : i64
        %65 = llvm.mlir.constant(4 : index) : i64
        %66 = llvm.mlir.constant(3 : index) : i64
        %67 = llvm.mlir.constant(2 : index) : i64
        %68 = llvm.mlir.constant(32768 : index) : i64
        %69 = llvm.mlir.constant(8192 : index) : i64
        %70 = llvm.mlir.constant(2 : i64) : i64
        %71 = llvm.mlir.constant(1024 : index) : i64
        %72 = llvm.mlir.constant(1 : i64) : i64
        %73 = llvm.mlir.constant(63 : index) : i64
        %74 = llvm.mlir.constant(1 : index) : i64
        %75 = llvm.mlir.constant(0 : i64) : i64
        %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
        %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
        %78 = llvm.mlir.constant(256 : index) : i64
        %79 = llvm.mlir.constant(8 : index) : i64
        %80 = llvm.mlir.constant(32 : index) : i64
        %81 = llvm.mlir.constant(0 : index) : i64
        %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
        %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
        %87 = llvm.and %86, %73  : i64
        %88 = llvm.icmp "eq" %87, %81 : i64
        "llvm.intr.assume"(%88) : (i1) -> ()
        %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
        %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
        %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
        %95 = llvm.and %94, %73  : i64
        %96 = llvm.icmp "eq" %95, %81 : i64
        "llvm.intr.assume"(%96) : (i1) -> ()
        %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
        %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
        %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
        %103 = llvm.and %102, %73  : i64
        %104 = llvm.icmp "eq" %103, %81 : i64
        "llvm.intr.assume"(%104) : (i1) -> ()
        %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
        %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
        %107 = llvm.zext %106 : i32 to i64
        %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
        %109 = llvm.zext %108 : i32 to i64
        %110 = llvm.mul %109, %69  : i64
        %111 = llvm.mul %107, %80  : i64
        %112 = llvm.mul %109, %68  : i64
        %113 = llvm.add %112, %111  : i64
        llvm.br ^bb1(%81 : i64)
      ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
        %115 = llvm.icmp "slt" %114, %80 : i64
        llvm.cond_br %115, ^bb2, ^bb9
      ^bb2:  // pred: ^bb1
        %116 = llvm.add %114, %74  : i64
        %117 = llvm.add %114, %67  : i64
        %118 = llvm.add %114, %66  : i64
        %119 = llvm.add %114, %65  : i64
        %120 = llvm.add %114, %64  : i64
        %121 = llvm.add %114, %63  : i64
        %122 = llvm.add %114, %62  : i64
        llvm.br ^bb3(%81 : i64)
      ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
        %124 = llvm.icmp "slt" %123, %80 : i64
        llvm.cond_br %124, ^bb4, ^bb8
      ^bb4:  // pred: ^bb3
        %125 = llvm.mul %114, %71  : i64
        %126 = llvm.add %113, %125  : i64
        %127 = llvm.add %126, %123  : i64
        %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
        %132 = llvm.mul %116, %71  : i64
        %133 = llvm.add %113, %132  : i64
        %134 = llvm.add %133, %123  : i64
        %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
        %139 = llvm.mul %117, %71  : i64
        %140 = llvm.add %113, %139  : i64
        %141 = llvm.add %140, %123  : i64
        %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
        %146 = llvm.mul %118, %71  : i64
        %147 = llvm.add %113, %146  : i64
        %148 = llvm.add %147, %123  : i64
        %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
        %153 = llvm.mul %119, %71  : i64
        %154 = llvm.add %113, %153  : i64
        %155 = llvm.add %154, %123  : i64
        %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
        %160 = llvm.mul %120, %71  : i64
        %161 = llvm.add %113, %160  : i64
        %162 = llvm.add %161, %123  : i64
        %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
        %167 = llvm.mul %121, %71  : i64
        %168 = llvm.add %113, %167  : i64
        %169 = llvm.add %168, %123  : i64
        %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
        %174 = llvm.mul %122, %71  : i64
        %175 = llvm.add %113, %174  : i64
        %176 = llvm.add %175, %123  : i64
        %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
        llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
      ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
        %183 = llvm.icmp "slt" %181, %78 : i64
        llvm.cond_br %183, ^bb6, ^bb7
      ^bb6:  // pred: ^bb5
        %184 = llvm.mul %114, %78  : i64
        %185 = llvm.add %110, %184  : i64
        %186 = llvm.add %185, %181  : i64
        %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %190 = llvm.mul %116, %78  : i64
        %191 = llvm.add %110, %190  : i64
        %192 = llvm.add %191, %181  : i64
        %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %196 = llvm.mul %117, %78  : i64
        %197 = llvm.add %110, %196  : i64
        %198 = llvm.add %197, %181  : i64
        %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %202 = llvm.mul %118, %78  : i64
        %203 = llvm.add %110, %202  : i64
        %204 = llvm.add %203, %181  : i64
        %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %208 = llvm.mul %119, %78  : i64
        %209 = llvm.add %110, %208  : i64
        %210 = llvm.add %209, %181  : i64
        %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %214 = llvm.mul %120, %78  : i64
        %215 = llvm.add %110, %214  : i64
        %216 = llvm.add %215, %181  : i64
        %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %220 = llvm.mul %121, %78  : i64
        %221 = llvm.add %110, %220  : i64
        %222 = llvm.add %221, %181  : i64
        %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %226 = llvm.mul %122, %78  : i64
        %227 = llvm.add %110, %226  : i64
        %228 = llvm.add %227, %181  : i64
        %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %232 = llvm.mul %181, %71  : i64
        %233 = llvm.add %111, %232  : i64
        %234 = llvm.add %233, %123  : i64
        %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %238 = llvm.add %181, %74  : i64
        %239 = llvm.mul %238, %71  : i64
        %240 = llvm.add %111, %239  : i64
        %241 = llvm.add %240, %123  : i64
        %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %245 = llvm.add %181, %67  : i64
        %246 = llvm.mul %245, %71  : i64
        %247 = llvm.add %111, %246  : i64
        %248 = llvm.add %247, %123  : i64
        %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %252 = llvm.add %181, %66  : i64
        %253 = llvm.mul %252, %71  : i64
        %254 = llvm.add %111, %253  : i64
        %255 = llvm.add %254, %123  : i64
        %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %259 = llvm.add %181, %65  : i64
        %260 = llvm.mul %259, %71  : i64
        %261 = llvm.add %111, %260  : i64
        %262 = llvm.add %261, %123  : i64
        %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %266 = llvm.add %181, %64  : i64
        %267 = llvm.mul %266, %71  : i64
        %268 = llvm.add %111, %267  : i64
        %269 = llvm.add %268, %123  : i64
        %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %273 = llvm.add %181, %63  : i64
        %274 = llvm.mul %273, %71  : i64
        %275 = llvm.add %111, %274  : i64
        %276 = llvm.add %275, %123  : i64
        %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %280 = llvm.add %181, %62  : i64
        %281 = llvm.mul %280, %71  : i64
        %282 = llvm.add %111, %281  : i64
        %283 = llvm.add %282, %123  : i64
        %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
        %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
        %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
        %305 = llvm.mlir.undef : vector<8xf32>
        %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
        %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
        %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
        %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
        %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
        %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
        %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
        %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
        %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
        %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
        %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
        %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
        %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
        %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
        %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
        %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
        %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
        %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
        %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
        %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
        %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
        %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
        %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
        %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
        %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
        %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
        %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
        %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
        %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
        %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
        %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
        %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
        %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
        %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
        %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
        %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
        %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
        %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
        %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
        %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
        %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
        %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
        %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
        %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
        %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
        %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
        %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
        %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
        %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
        %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
        %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
        %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
        %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
        %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
        %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
        %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
        %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
        %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
        %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
        %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
        %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
        %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
        %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
        %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
        %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
        %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
        %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
        %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
        %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
        %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
        %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
        %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
        %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
        %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
        %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
        %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
        %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
        %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
        %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
        %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
        %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
        %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
        %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
        %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
        %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
        %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
        %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
        %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
        %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
        %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
        %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
        %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
        %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
        %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
        %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
        %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
        %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
        %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
        %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
        %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
        %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
        %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
        %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
        %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
        %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
        %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
        %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
        %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
        %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
        %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
        %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
        %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
        %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
        %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
        %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
        %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
        %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
        %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
        %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
        %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
        %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
        %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
        %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
        %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
        %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
        %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
        %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
        %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
        %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
        %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
        %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
        %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
        %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
        %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
        %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
        %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
        %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
        %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
        %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
        %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
        %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
        %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
        %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
        %577 = llvm.add %181, %79  : i64
        llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
      ^bb7:  // pred: ^bb5
        %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %586 = llvm.add %123, %79  : i64
        llvm.br ^bb3(%586 : i64)
      ^bb8:  // pred: ^bb3
        %587 = llvm.add %114, %79  : i64
        llvm.br ^bb1(%587 : i64)
      ^bb9:  // pred: ^bb1
        llvm.return %61 : i32
      }
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_3 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    %device_4 = hal.ex.shared_device : !hal.device
    %allocator_5 = hal.device.allocator<%device_4 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_3 : !hal.buffer> message("tensor") allocator(%allocator_5 : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_6 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_6 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    hal.device.switch<%0 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%0 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      %c0_12 = arith.constant 0 : index
      %c1_13 = arith.constant 1 : index
      %c2 = arith.constant 2 : index
      %c0_14 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_14] bindings([
        %c0_12 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1_13 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_3 : !hal.buffer)[%c0, %c2097152]
      ])
      %c32 = arith.constant 32 : index
      %c16 = arith.constant 16 : index
      %c1_15 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1_15])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %1 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_6 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_6 : !hal.device> affinity(%c-1_i64) wait(%1) signal(%fence) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c512_7 = arith.constant 512 : index
    %c1024_8 = arith.constant 1024 : index
    %c0_9 = arith.constant 0 : index
    %c553648160_i32_10 = arith.constant 553648160 : i32
    %c1_i32_11 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0_9, %c2097152] shape([%c512_7, %c1024_8]) type(%c553648160_i32_10) encoding(%c1_i32_11) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_3 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    %device_4 = hal.ex.shared_device : !hal.device
    %allocator_5 = hal.device.allocator<%device_4 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_3 : !hal.buffer> message("tensor") allocator(%allocator_5 : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_6 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_6 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    hal.device.switch<%0 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%0 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      %c0_12 = arith.constant 0 : index
      %c1_13 = arith.constant 1 : index
      %c2 = arith.constant 2 : index
      %c0_14 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_14] bindings([
        %c0_12 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1_13 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_3 : !hal.buffer)[%c0, %c2097152]
      ])
      %c32 = arith.constant 32 : index
      %c16 = arith.constant 16 : index
      %c1_15 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1_15])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %1 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_6 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_6 : !hal.device> affinity(%c-1_i64) wait(%1) signal(%fence) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c512_7 = arith.constant 512 : index
    %c1024_8 = arith.constant 1024 : index
    %c0_9 = arith.constant 0 : index
    %c553648160_i32_10 = arith.constant 553648160 : i32
    %c1_i32_11 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0_9, %c2097152] shape([%c512_7, %c1024_8]) type(%c553648160_i32_10) encoding(%c1_i32_11) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_3 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    %device_4 = hal.ex.shared_device : !hal.device
    %allocator_5 = hal.device.allocator<%device_4 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_3 : !hal.buffer> message("tensor") allocator(%allocator_5 : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_6 = hal.ex.shared_device : !hal.device
    %cmd = hal.command_buffer.create device(%device_6 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device_6 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device_6 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_3 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_6 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_6 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
    %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After LLVMCPULinkExecutables (iree-llvmcpu-link-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
hal.executable private @matmul_static_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
    hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
      %c32 = arith.constant 32 : index
      %c16 = arith.constant 16 : index
      %c1 = arith.constant 1 : index
      hal.return %c32, %c16, %c1 : index, index, index
    }
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
        %0 = llvm.mlir.constant(63 : i64) : i64
        %1 = llvm.mlir.constant(62 : i64) : i64
        %2 = llvm.mlir.constant(61 : i64) : i64
        %3 = llvm.mlir.constant(60 : i64) : i64
        %4 = llvm.mlir.constant(59 : i64) : i64
        %5 = llvm.mlir.constant(58 : i64) : i64
        %6 = llvm.mlir.constant(57 : i64) : i64
        %7 = llvm.mlir.constant(56 : i64) : i64
        %8 = llvm.mlir.constant(55 : i64) : i64
        %9 = llvm.mlir.constant(54 : i64) : i64
        %10 = llvm.mlir.constant(53 : i64) : i64
        %11 = llvm.mlir.constant(52 : i64) : i64
        %12 = llvm.mlir.constant(51 : i64) : i64
        %13 = llvm.mlir.constant(50 : i64) : i64
        %14 = llvm.mlir.constant(49 : i64) : i64
        %15 = llvm.mlir.constant(48 : i64) : i64
        %16 = llvm.mlir.constant(47 : i64) : i64
        %17 = llvm.mlir.constant(46 : i64) : i64
        %18 = llvm.mlir.constant(45 : i64) : i64
        %19 = llvm.mlir.constant(44 : i64) : i64
        %20 = llvm.mlir.constant(43 : i64) : i64
        %21 = llvm.mlir.constant(42 : i64) : i64
        %22 = llvm.mlir.constant(41 : i64) : i64
        %23 = llvm.mlir.constant(40 : i64) : i64
        %24 = llvm.mlir.constant(39 : i64) : i64
        %25 = llvm.mlir.constant(38 : i64) : i64
        %26 = llvm.mlir.constant(37 : i64) : i64
        %27 = llvm.mlir.constant(36 : i64) : i64
        %28 = llvm.mlir.constant(35 : i64) : i64
        %29 = llvm.mlir.constant(34 : i64) : i64
        %30 = llvm.mlir.constant(33 : i64) : i64
        %31 = llvm.mlir.constant(32 : i64) : i64
        %32 = llvm.mlir.constant(31 : i64) : i64
        %33 = llvm.mlir.constant(30 : i64) : i64
        %34 = llvm.mlir.constant(29 : i64) : i64
        %35 = llvm.mlir.constant(28 : i64) : i64
        %36 = llvm.mlir.constant(27 : i64) : i64
        %37 = llvm.mlir.constant(26 : i64) : i64
        %38 = llvm.mlir.constant(25 : i64) : i64
        %39 = llvm.mlir.constant(24 : i64) : i64
        %40 = llvm.mlir.constant(23 : i64) : i64
        %41 = llvm.mlir.constant(22 : i64) : i64
        %42 = llvm.mlir.constant(21 : i64) : i64
        %43 = llvm.mlir.constant(20 : i64) : i64
        %44 = llvm.mlir.constant(19 : i64) : i64
        %45 = llvm.mlir.constant(18 : i64) : i64
        %46 = llvm.mlir.constant(17 : i64) : i64
        %47 = llvm.mlir.constant(16 : i64) : i64
        %48 = llvm.mlir.constant(15 : i64) : i64
        %49 = llvm.mlir.constant(14 : i64) : i64
        %50 = llvm.mlir.constant(13 : i64) : i64
        %51 = llvm.mlir.constant(12 : i64) : i64
        %52 = llvm.mlir.constant(11 : i64) : i64
        %53 = llvm.mlir.constant(10 : i64) : i64
        %54 = llvm.mlir.constant(9 : i64) : i64
        %55 = llvm.mlir.constant(8 : i64) : i64
        %56 = llvm.mlir.constant(7 : i64) : i64
        %57 = llvm.mlir.constant(6 : i64) : i64
        %58 = llvm.mlir.constant(5 : i64) : i64
        %59 = llvm.mlir.constant(4 : i64) : i64
        %60 = llvm.mlir.constant(3 : i64) : i64
        %61 = llvm.mlir.constant(0 : i32) : i32
        %62 = llvm.mlir.constant(7 : index) : i64
        %63 = llvm.mlir.constant(6 : index) : i64
        %64 = llvm.mlir.constant(5 : index) : i64
        %65 = llvm.mlir.constant(4 : index) : i64
        %66 = llvm.mlir.constant(3 : index) : i64
        %67 = llvm.mlir.constant(2 : index) : i64
        %68 = llvm.mlir.constant(32768 : index) : i64
        %69 = llvm.mlir.constant(8192 : index) : i64
        %70 = llvm.mlir.constant(2 : i64) : i64
        %71 = llvm.mlir.constant(1024 : index) : i64
        %72 = llvm.mlir.constant(1 : i64) : i64
        %73 = llvm.mlir.constant(63 : index) : i64
        %74 = llvm.mlir.constant(1 : index) : i64
        %75 = llvm.mlir.constant(0 : i64) : i64
        %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
        %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
        %78 = llvm.mlir.constant(256 : index) : i64
        %79 = llvm.mlir.constant(8 : index) : i64
        %80 = llvm.mlir.constant(32 : index) : i64
        %81 = llvm.mlir.constant(0 : index) : i64
        %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
        %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
        %87 = llvm.and %86, %73  : i64
        %88 = llvm.icmp "eq" %87, %81 : i64
        "llvm.intr.assume"(%88) : (i1) -> ()
        %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
        %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
        %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
        %95 = llvm.and %94, %73  : i64
        %96 = llvm.icmp "eq" %95, %81 : i64
        "llvm.intr.assume"(%96) : (i1) -> ()
        %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
        %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
        %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
        %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
        %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
        %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
        %103 = llvm.and %102, %73  : i64
        %104 = llvm.icmp "eq" %103, %81 : i64
        "llvm.intr.assume"(%104) : (i1) -> ()
        %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
        %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
        %107 = llvm.zext %106 : i32 to i64
        %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
        %109 = llvm.zext %108 : i32 to i64
        %110 = llvm.mul %109, %69  : i64
        %111 = llvm.mul %107, %80  : i64
        %112 = llvm.mul %109, %68  : i64
        %113 = llvm.add %112, %111  : i64
        llvm.br ^bb1(%81 : i64)
      ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
        %115 = llvm.icmp "slt" %114, %80 : i64
        llvm.cond_br %115, ^bb2, ^bb9
      ^bb2:  // pred: ^bb1
        %116 = llvm.add %114, %74  : i64
        %117 = llvm.add %114, %67  : i64
        %118 = llvm.add %114, %66  : i64
        %119 = llvm.add %114, %65  : i64
        %120 = llvm.add %114, %64  : i64
        %121 = llvm.add %114, %63  : i64
        %122 = llvm.add %114, %62  : i64
        llvm.br ^bb3(%81 : i64)
      ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
        %124 = llvm.icmp "slt" %123, %80 : i64
        llvm.cond_br %124, ^bb4, ^bb8
      ^bb4:  // pred: ^bb3
        %125 = llvm.mul %114, %71  : i64
        %126 = llvm.add %113, %125  : i64
        %127 = llvm.add %126, %123  : i64
        %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
        %132 = llvm.mul %116, %71  : i64
        %133 = llvm.add %113, %132  : i64
        %134 = llvm.add %133, %123  : i64
        %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
        %139 = llvm.mul %117, %71  : i64
        %140 = llvm.add %113, %139  : i64
        %141 = llvm.add %140, %123  : i64
        %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
        %146 = llvm.mul %118, %71  : i64
        %147 = llvm.add %113, %146  : i64
        %148 = llvm.add %147, %123  : i64
        %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
        %153 = llvm.mul %119, %71  : i64
        %154 = llvm.add %113, %153  : i64
        %155 = llvm.add %154, %123  : i64
        %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
        %160 = llvm.mul %120, %71  : i64
        %161 = llvm.add %113, %160  : i64
        %162 = llvm.add %161, %123  : i64
        %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
        %167 = llvm.mul %121, %71  : i64
        %168 = llvm.add %113, %167  : i64
        %169 = llvm.add %168, %123  : i64
        %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
        %174 = llvm.mul %122, %71  : i64
        %175 = llvm.add %113, %174  : i64
        %176 = llvm.add %175, %123  : i64
        %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
        llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
      ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
        %183 = llvm.icmp "slt" %181, %78 : i64
        llvm.cond_br %183, ^bb6, ^bb7
      ^bb6:  // pred: ^bb5
        %184 = llvm.mul %114, %78  : i64
        %185 = llvm.add %110, %184  : i64
        %186 = llvm.add %185, %181  : i64
        %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %190 = llvm.mul %116, %78  : i64
        %191 = llvm.add %110, %190  : i64
        %192 = llvm.add %191, %181  : i64
        %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %196 = llvm.mul %117, %78  : i64
        %197 = llvm.add %110, %196  : i64
        %198 = llvm.add %197, %181  : i64
        %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %202 = llvm.mul %118, %78  : i64
        %203 = llvm.add %110, %202  : i64
        %204 = llvm.add %203, %181  : i64
        %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %208 = llvm.mul %119, %78  : i64
        %209 = llvm.add %110, %208  : i64
        %210 = llvm.add %209, %181  : i64
        %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %214 = llvm.mul %120, %78  : i64
        %215 = llvm.add %110, %214  : i64
        %216 = llvm.add %215, %181  : i64
        %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %220 = llvm.mul %121, %78  : i64
        %221 = llvm.add %110, %220  : i64
        %222 = llvm.add %221, %181  : i64
        %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %226 = llvm.mul %122, %78  : i64
        %227 = llvm.add %110, %226  : i64
        %228 = llvm.add %227, %181  : i64
        %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %232 = llvm.mul %181, %71  : i64
        %233 = llvm.add %111, %232  : i64
        %234 = llvm.add %233, %123  : i64
        %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %238 = llvm.add %181, %74  : i64
        %239 = llvm.mul %238, %71  : i64
        %240 = llvm.add %111, %239  : i64
        %241 = llvm.add %240, %123  : i64
        %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %245 = llvm.add %181, %67  : i64
        %246 = llvm.mul %245, %71  : i64
        %247 = llvm.add %111, %246  : i64
        %248 = llvm.add %247, %123  : i64
        %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %252 = llvm.add %181, %66  : i64
        %253 = llvm.mul %252, %71  : i64
        %254 = llvm.add %111, %253  : i64
        %255 = llvm.add %254, %123  : i64
        %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %259 = llvm.add %181, %65  : i64
        %260 = llvm.mul %259, %71  : i64
        %261 = llvm.add %111, %260  : i64
        %262 = llvm.add %261, %123  : i64
        %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %266 = llvm.add %181, %64  : i64
        %267 = llvm.mul %266, %71  : i64
        %268 = llvm.add %111, %267  : i64
        %269 = llvm.add %268, %123  : i64
        %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %273 = llvm.add %181, %63  : i64
        %274 = llvm.mul %273, %71  : i64
        %275 = llvm.add %111, %274  : i64
        %276 = llvm.add %275, %123  : i64
        %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %280 = llvm.add %181, %62  : i64
        %281 = llvm.mul %280, %71  : i64
        %282 = llvm.add %111, %281  : i64
        %283 = llvm.add %282, %123  : i64
        %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
        %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
        %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
        %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
        %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
        %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
        %305 = llvm.mlir.undef : vector<8xf32>
        %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
        %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
        %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
        %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
        %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
        %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
        %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
        %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
        %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
        %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
        %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
        %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
        %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
        %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
        %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
        %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
        %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
        %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
        %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
        %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
        %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
        %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
        %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
        %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
        %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
        %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
        %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
        %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
        %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
        %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
        %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
        %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
        %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
        %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
        %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
        %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
        %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
        %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
        %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
        %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
        %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
        %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
        %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
        %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
        %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
        %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
        %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
        %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
        %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
        %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
        %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
        %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
        %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
        %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
        %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
        %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
        %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
        %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
        %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
        %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
        %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
        %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
        %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
        %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
        %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
        %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
        %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
        %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
        %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
        %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
        %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
        %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
        %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
        %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
        %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
        %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
        %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
        %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
        %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
        %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
        %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
        %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
        %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
        %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
        %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
        %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
        %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
        %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
        %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
        %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
        %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
        %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
        %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
        %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
        %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
        %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
        %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
        %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
        %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
        %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
        %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
        %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
        %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
        %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
        %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
        %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
        %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
        %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
        %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
        %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
        %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
        %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
        %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
        %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
        %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
        %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
        %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
        %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
        %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
        %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
        %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
        %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
        %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
        %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
        %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
        %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
        %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
        %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
        %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
        %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
        %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
        %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
        %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
        %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
        %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
        %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
        %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
        %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
        %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
        %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
        %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
        %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
        %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
        %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
        %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
        %577 = llvm.add %181, %79  : i64
        llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
      ^bb7:  // pred: ^bb5
        %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
        llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
        %586 = llvm.add %123, %79  : i64
        llvm.br ^bb3(%586 : i64)
      ^bb8:  // pred: ^bb3
        %587 = llvm.add %114, %79  : i64
        llvm.br ^bb1(%587 : i64)
      ^bb9:  // pred: ^bb1
        llvm.return %61 : i32
      }
    }
  }
}

// -----// IR Dump After LLVMCPUAssignConstantOrdinals (iree-llvmcpu-assign-constant-ordinals) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
  hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    hal.return %c32, %c16, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(63 : i64) : i64
      %1 = llvm.mlir.constant(62 : i64) : i64
      %2 = llvm.mlir.constant(61 : i64) : i64
      %3 = llvm.mlir.constant(60 : i64) : i64
      %4 = llvm.mlir.constant(59 : i64) : i64
      %5 = llvm.mlir.constant(58 : i64) : i64
      %6 = llvm.mlir.constant(57 : i64) : i64
      %7 = llvm.mlir.constant(56 : i64) : i64
      %8 = llvm.mlir.constant(55 : i64) : i64
      %9 = llvm.mlir.constant(54 : i64) : i64
      %10 = llvm.mlir.constant(53 : i64) : i64
      %11 = llvm.mlir.constant(52 : i64) : i64
      %12 = llvm.mlir.constant(51 : i64) : i64
      %13 = llvm.mlir.constant(50 : i64) : i64
      %14 = llvm.mlir.constant(49 : i64) : i64
      %15 = llvm.mlir.constant(48 : i64) : i64
      %16 = llvm.mlir.constant(47 : i64) : i64
      %17 = llvm.mlir.constant(46 : i64) : i64
      %18 = llvm.mlir.constant(45 : i64) : i64
      %19 = llvm.mlir.constant(44 : i64) : i64
      %20 = llvm.mlir.constant(43 : i64) : i64
      %21 = llvm.mlir.constant(42 : i64) : i64
      %22 = llvm.mlir.constant(41 : i64) : i64
      %23 = llvm.mlir.constant(40 : i64) : i64
      %24 = llvm.mlir.constant(39 : i64) : i64
      %25 = llvm.mlir.constant(38 : i64) : i64
      %26 = llvm.mlir.constant(37 : i64) : i64
      %27 = llvm.mlir.constant(36 : i64) : i64
      %28 = llvm.mlir.constant(35 : i64) : i64
      %29 = llvm.mlir.constant(34 : i64) : i64
      %30 = llvm.mlir.constant(33 : i64) : i64
      %31 = llvm.mlir.constant(32 : i64) : i64
      %32 = llvm.mlir.constant(31 : i64) : i64
      %33 = llvm.mlir.constant(30 : i64) : i64
      %34 = llvm.mlir.constant(29 : i64) : i64
      %35 = llvm.mlir.constant(28 : i64) : i64
      %36 = llvm.mlir.constant(27 : i64) : i64
      %37 = llvm.mlir.constant(26 : i64) : i64
      %38 = llvm.mlir.constant(25 : i64) : i64
      %39 = llvm.mlir.constant(24 : i64) : i64
      %40 = llvm.mlir.constant(23 : i64) : i64
      %41 = llvm.mlir.constant(22 : i64) : i64
      %42 = llvm.mlir.constant(21 : i64) : i64
      %43 = llvm.mlir.constant(20 : i64) : i64
      %44 = llvm.mlir.constant(19 : i64) : i64
      %45 = llvm.mlir.constant(18 : i64) : i64
      %46 = llvm.mlir.constant(17 : i64) : i64
      %47 = llvm.mlir.constant(16 : i64) : i64
      %48 = llvm.mlir.constant(15 : i64) : i64
      %49 = llvm.mlir.constant(14 : i64) : i64
      %50 = llvm.mlir.constant(13 : i64) : i64
      %51 = llvm.mlir.constant(12 : i64) : i64
      %52 = llvm.mlir.constant(11 : i64) : i64
      %53 = llvm.mlir.constant(10 : i64) : i64
      %54 = llvm.mlir.constant(9 : i64) : i64
      %55 = llvm.mlir.constant(8 : i64) : i64
      %56 = llvm.mlir.constant(7 : i64) : i64
      %57 = llvm.mlir.constant(6 : i64) : i64
      %58 = llvm.mlir.constant(5 : i64) : i64
      %59 = llvm.mlir.constant(4 : i64) : i64
      %60 = llvm.mlir.constant(3 : i64) : i64
      %61 = llvm.mlir.constant(0 : i32) : i32
      %62 = llvm.mlir.constant(7 : index) : i64
      %63 = llvm.mlir.constant(6 : index) : i64
      %64 = llvm.mlir.constant(5 : index) : i64
      %65 = llvm.mlir.constant(4 : index) : i64
      %66 = llvm.mlir.constant(3 : index) : i64
      %67 = llvm.mlir.constant(2 : index) : i64
      %68 = llvm.mlir.constant(32768 : index) : i64
      %69 = llvm.mlir.constant(8192 : index) : i64
      %70 = llvm.mlir.constant(2 : i64) : i64
      %71 = llvm.mlir.constant(1024 : index) : i64
      %72 = llvm.mlir.constant(1 : i64) : i64
      %73 = llvm.mlir.constant(63 : index) : i64
      %74 = llvm.mlir.constant(1 : index) : i64
      %75 = llvm.mlir.constant(0 : i64) : i64
      %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
      %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
      %78 = llvm.mlir.constant(256 : index) : i64
      %79 = llvm.mlir.constant(8 : index) : i64
      %80 = llvm.mlir.constant(32 : index) : i64
      %81 = llvm.mlir.constant(0 : index) : i64
      %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
      %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
      %87 = llvm.and %86, %73  : i64
      %88 = llvm.icmp "eq" %87, %81 : i64
      "llvm.intr.assume"(%88) : (i1) -> ()
      %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
      %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
      %95 = llvm.and %94, %73  : i64
      %96 = llvm.icmp "eq" %95, %81 : i64
      "llvm.intr.assume"(%96) : (i1) -> ()
      %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
      %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
      %103 = llvm.and %102, %73  : i64
      %104 = llvm.icmp "eq" %103, %81 : i64
      "llvm.intr.assume"(%104) : (i1) -> ()
      %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
      %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %107 = llvm.zext %106 : i32 to i64
      %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %109 = llvm.zext %108 : i32 to i64
      %110 = llvm.mul %109, %69  : i64
      %111 = llvm.mul %107, %80  : i64
      %112 = llvm.mul %109, %68  : i64
      %113 = llvm.add %112, %111  : i64
      llvm.br ^bb1(%81 : i64)
    ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
      %115 = llvm.icmp "slt" %114, %80 : i64
      llvm.cond_br %115, ^bb2, ^bb9
    ^bb2:  // pred: ^bb1
      %116 = llvm.add %114, %74  : i64
      %117 = llvm.add %114, %67  : i64
      %118 = llvm.add %114, %66  : i64
      %119 = llvm.add %114, %65  : i64
      %120 = llvm.add %114, %64  : i64
      %121 = llvm.add %114, %63  : i64
      %122 = llvm.add %114, %62  : i64
      llvm.br ^bb3(%81 : i64)
    ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
      %124 = llvm.icmp "slt" %123, %80 : i64
      llvm.cond_br %124, ^bb4, ^bb8
    ^bb4:  // pred: ^bb3
      %125 = llvm.mul %114, %71  : i64
      %126 = llvm.add %113, %125  : i64
      %127 = llvm.add %126, %123  : i64
      %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %132 = llvm.mul %116, %71  : i64
      %133 = llvm.add %113, %132  : i64
      %134 = llvm.add %133, %123  : i64
      %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
      %139 = llvm.mul %117, %71  : i64
      %140 = llvm.add %113, %139  : i64
      %141 = llvm.add %140, %123  : i64
      %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
      %146 = llvm.mul %118, %71  : i64
      %147 = llvm.add %113, %146  : i64
      %148 = llvm.add %147, %123  : i64
      %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
      %153 = llvm.mul %119, %71  : i64
      %154 = llvm.add %113, %153  : i64
      %155 = llvm.add %154, %123  : i64
      %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
      %160 = llvm.mul %120, %71  : i64
      %161 = llvm.add %113, %160  : i64
      %162 = llvm.add %161, %123  : i64
      %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
      %167 = llvm.mul %121, %71  : i64
      %168 = llvm.add %113, %167  : i64
      %169 = llvm.add %168, %123  : i64
      %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
      %174 = llvm.mul %122, %71  : i64
      %175 = llvm.add %113, %174  : i64
      %176 = llvm.add %175, %123  : i64
      %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
      %183 = llvm.icmp "slt" %181, %78 : i64
      llvm.cond_br %183, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %184 = llvm.mul %114, %78  : i64
      %185 = llvm.add %110, %184  : i64
      %186 = llvm.add %185, %181  : i64
      %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %190 = llvm.mul %116, %78  : i64
      %191 = llvm.add %110, %190  : i64
      %192 = llvm.add %191, %181  : i64
      %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %196 = llvm.mul %117, %78  : i64
      %197 = llvm.add %110, %196  : i64
      %198 = llvm.add %197, %181  : i64
      %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %202 = llvm.mul %118, %78  : i64
      %203 = llvm.add %110, %202  : i64
      %204 = llvm.add %203, %181  : i64
      %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %208 = llvm.mul %119, %78  : i64
      %209 = llvm.add %110, %208  : i64
      %210 = llvm.add %209, %181  : i64
      %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %214 = llvm.mul %120, %78  : i64
      %215 = llvm.add %110, %214  : i64
      %216 = llvm.add %215, %181  : i64
      %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %220 = llvm.mul %121, %78  : i64
      %221 = llvm.add %110, %220  : i64
      %222 = llvm.add %221, %181  : i64
      %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %226 = llvm.mul %122, %78  : i64
      %227 = llvm.add %110, %226  : i64
      %228 = llvm.add %227, %181  : i64
      %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %232 = llvm.mul %181, %71  : i64
      %233 = llvm.add %111, %232  : i64
      %234 = llvm.add %233, %123  : i64
      %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %238 = llvm.add %181, %74  : i64
      %239 = llvm.mul %238, %71  : i64
      %240 = llvm.add %111, %239  : i64
      %241 = llvm.add %240, %123  : i64
      %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %245 = llvm.add %181, %67  : i64
      %246 = llvm.mul %245, %71  : i64
      %247 = llvm.add %111, %246  : i64
      %248 = llvm.add %247, %123  : i64
      %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %252 = llvm.add %181, %66  : i64
      %253 = llvm.mul %252, %71  : i64
      %254 = llvm.add %111, %253  : i64
      %255 = llvm.add %254, %123  : i64
      %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %259 = llvm.add %181, %65  : i64
      %260 = llvm.mul %259, %71  : i64
      %261 = llvm.add %111, %260  : i64
      %262 = llvm.add %261, %123  : i64
      %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %266 = llvm.add %181, %64  : i64
      %267 = llvm.mul %266, %71  : i64
      %268 = llvm.add %111, %267  : i64
      %269 = llvm.add %268, %123  : i64
      %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %273 = llvm.add %181, %63  : i64
      %274 = llvm.mul %273, %71  : i64
      %275 = llvm.add %111, %274  : i64
      %276 = llvm.add %275, %123  : i64
      %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %280 = llvm.add %181, %62  : i64
      %281 = llvm.mul %280, %71  : i64
      %282 = llvm.add %111, %281  : i64
      %283 = llvm.add %282, %123  : i64
      %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
      %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
      %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
      %305 = llvm.mlir.undef : vector<8xf32>
      %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
      %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
      %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
      %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
      %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
      %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
      %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
      %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
      %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
      %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
      %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
      %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
      %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
      %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
      %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
      %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
      %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
      %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
      %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
      %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
      %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
      %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
      %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
      %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
      %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
      %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
      %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
      %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
      %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
      %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
      %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
      %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
      %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
      %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
      %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
      %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
      %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
      %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
      %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
      %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
      %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
      %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
      %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
      %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
      %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
      %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
      %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
      %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
      %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
      %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
      %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
      %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
      %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
      %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
      %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
      %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
      %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
      %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
      %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
      %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
      %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
      %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
      %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
      %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
      %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
      %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
      %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
      %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
      %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
      %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
      %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
      %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
      %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
      %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
      %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
      %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
      %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
      %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
      %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
      %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
      %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
      %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
      %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
      %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
      %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
      %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
      %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
      %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
      %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
      %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
      %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
      %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
      %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
      %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
      %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
      %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
      %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
      %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
      %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
      %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
      %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
      %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
      %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
      %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
      %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
      %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
      %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
      %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
      %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
      %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
      %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
      %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
      %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
      %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
      %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
      %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
      %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
      %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
      %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
      %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
      %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
      %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
      %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
      %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
      %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
      %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
      %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
      %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
      %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
      %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
      %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
      %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
      %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
      %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
      %577 = llvm.add %181, %79  : i64
      llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb7:  // pred: ^bb5
      %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %586 = llvm.add %123, %79  : i64
      llvm.br ^bb3(%586 : i64)
    ^bb8:  // pred: ^bb3
      %587 = llvm.add %114, %79  : i64
      llvm.br ^bb1(%587 : i64)
    ^bb9:  // pred: ^bb1
      llvm.return %61 : i32
    }
  }
}

// -----// IR Dump After LLVMCPUAssignImportOrdinals (iree-llvmcpu-assign-import-ordinals) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}> {
  hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    hal.return %c32, %c16, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(63 : i64) : i64
      %1 = llvm.mlir.constant(62 : i64) : i64
      %2 = llvm.mlir.constant(61 : i64) : i64
      %3 = llvm.mlir.constant(60 : i64) : i64
      %4 = llvm.mlir.constant(59 : i64) : i64
      %5 = llvm.mlir.constant(58 : i64) : i64
      %6 = llvm.mlir.constant(57 : i64) : i64
      %7 = llvm.mlir.constant(56 : i64) : i64
      %8 = llvm.mlir.constant(55 : i64) : i64
      %9 = llvm.mlir.constant(54 : i64) : i64
      %10 = llvm.mlir.constant(53 : i64) : i64
      %11 = llvm.mlir.constant(52 : i64) : i64
      %12 = llvm.mlir.constant(51 : i64) : i64
      %13 = llvm.mlir.constant(50 : i64) : i64
      %14 = llvm.mlir.constant(49 : i64) : i64
      %15 = llvm.mlir.constant(48 : i64) : i64
      %16 = llvm.mlir.constant(47 : i64) : i64
      %17 = llvm.mlir.constant(46 : i64) : i64
      %18 = llvm.mlir.constant(45 : i64) : i64
      %19 = llvm.mlir.constant(44 : i64) : i64
      %20 = llvm.mlir.constant(43 : i64) : i64
      %21 = llvm.mlir.constant(42 : i64) : i64
      %22 = llvm.mlir.constant(41 : i64) : i64
      %23 = llvm.mlir.constant(40 : i64) : i64
      %24 = llvm.mlir.constant(39 : i64) : i64
      %25 = llvm.mlir.constant(38 : i64) : i64
      %26 = llvm.mlir.constant(37 : i64) : i64
      %27 = llvm.mlir.constant(36 : i64) : i64
      %28 = llvm.mlir.constant(35 : i64) : i64
      %29 = llvm.mlir.constant(34 : i64) : i64
      %30 = llvm.mlir.constant(33 : i64) : i64
      %31 = llvm.mlir.constant(32 : i64) : i64
      %32 = llvm.mlir.constant(31 : i64) : i64
      %33 = llvm.mlir.constant(30 : i64) : i64
      %34 = llvm.mlir.constant(29 : i64) : i64
      %35 = llvm.mlir.constant(28 : i64) : i64
      %36 = llvm.mlir.constant(27 : i64) : i64
      %37 = llvm.mlir.constant(26 : i64) : i64
      %38 = llvm.mlir.constant(25 : i64) : i64
      %39 = llvm.mlir.constant(24 : i64) : i64
      %40 = llvm.mlir.constant(23 : i64) : i64
      %41 = llvm.mlir.constant(22 : i64) : i64
      %42 = llvm.mlir.constant(21 : i64) : i64
      %43 = llvm.mlir.constant(20 : i64) : i64
      %44 = llvm.mlir.constant(19 : i64) : i64
      %45 = llvm.mlir.constant(18 : i64) : i64
      %46 = llvm.mlir.constant(17 : i64) : i64
      %47 = llvm.mlir.constant(16 : i64) : i64
      %48 = llvm.mlir.constant(15 : i64) : i64
      %49 = llvm.mlir.constant(14 : i64) : i64
      %50 = llvm.mlir.constant(13 : i64) : i64
      %51 = llvm.mlir.constant(12 : i64) : i64
      %52 = llvm.mlir.constant(11 : i64) : i64
      %53 = llvm.mlir.constant(10 : i64) : i64
      %54 = llvm.mlir.constant(9 : i64) : i64
      %55 = llvm.mlir.constant(8 : i64) : i64
      %56 = llvm.mlir.constant(7 : i64) : i64
      %57 = llvm.mlir.constant(6 : i64) : i64
      %58 = llvm.mlir.constant(5 : i64) : i64
      %59 = llvm.mlir.constant(4 : i64) : i64
      %60 = llvm.mlir.constant(3 : i64) : i64
      %61 = llvm.mlir.constant(0 : i32) : i32
      %62 = llvm.mlir.constant(7 : index) : i64
      %63 = llvm.mlir.constant(6 : index) : i64
      %64 = llvm.mlir.constant(5 : index) : i64
      %65 = llvm.mlir.constant(4 : index) : i64
      %66 = llvm.mlir.constant(3 : index) : i64
      %67 = llvm.mlir.constant(2 : index) : i64
      %68 = llvm.mlir.constant(32768 : index) : i64
      %69 = llvm.mlir.constant(8192 : index) : i64
      %70 = llvm.mlir.constant(2 : i64) : i64
      %71 = llvm.mlir.constant(1024 : index) : i64
      %72 = llvm.mlir.constant(1 : i64) : i64
      %73 = llvm.mlir.constant(63 : index) : i64
      %74 = llvm.mlir.constant(1 : index) : i64
      %75 = llvm.mlir.constant(0 : i64) : i64
      %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
      %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
      %78 = llvm.mlir.constant(256 : index) : i64
      %79 = llvm.mlir.constant(8 : index) : i64
      %80 = llvm.mlir.constant(32 : index) : i64
      %81 = llvm.mlir.constant(0 : index) : i64
      %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
      %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
      %87 = llvm.and %86, %73  : i64
      %88 = llvm.icmp "eq" %87, %81 : i64
      "llvm.intr.assume"(%88) : (i1) -> ()
      %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
      %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
      %95 = llvm.and %94, %73  : i64
      %96 = llvm.icmp "eq" %95, %81 : i64
      "llvm.intr.assume"(%96) : (i1) -> ()
      %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
      %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
      %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
      %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
      %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
      %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
      %103 = llvm.and %102, %73  : i64
      %104 = llvm.icmp "eq" %103, %81 : i64
      "llvm.intr.assume"(%104) : (i1) -> ()
      %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
      %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %107 = llvm.zext %106 : i32 to i64
      %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
      %109 = llvm.zext %108 : i32 to i64
      %110 = llvm.mul %109, %69  : i64
      %111 = llvm.mul %107, %80  : i64
      %112 = llvm.mul %109, %68  : i64
      %113 = llvm.add %112, %111  : i64
      llvm.br ^bb1(%81 : i64)
    ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
      %115 = llvm.icmp "slt" %114, %80 : i64
      llvm.cond_br %115, ^bb2, ^bb9
    ^bb2:  // pred: ^bb1
      %116 = llvm.add %114, %74  : i64
      %117 = llvm.add %114, %67  : i64
      %118 = llvm.add %114, %66  : i64
      %119 = llvm.add %114, %65  : i64
      %120 = llvm.add %114, %64  : i64
      %121 = llvm.add %114, %63  : i64
      %122 = llvm.add %114, %62  : i64
      llvm.br ^bb3(%81 : i64)
    ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
      %124 = llvm.icmp "slt" %123, %80 : i64
      llvm.cond_br %124, ^bb4, ^bb8
    ^bb4:  // pred: ^bb3
      %125 = llvm.mul %114, %71  : i64
      %126 = llvm.add %113, %125  : i64
      %127 = llvm.add %126, %123  : i64
      %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %132 = llvm.mul %116, %71  : i64
      %133 = llvm.add %113, %132  : i64
      %134 = llvm.add %133, %123  : i64
      %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
      %139 = llvm.mul %117, %71  : i64
      %140 = llvm.add %113, %139  : i64
      %141 = llvm.add %140, %123  : i64
      %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
      %146 = llvm.mul %118, %71  : i64
      %147 = llvm.add %113, %146  : i64
      %148 = llvm.add %147, %123  : i64
      %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
      %153 = llvm.mul %119, %71  : i64
      %154 = llvm.add %113, %153  : i64
      %155 = llvm.add %154, %123  : i64
      %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
      %160 = llvm.mul %120, %71  : i64
      %161 = llvm.add %113, %160  : i64
      %162 = llvm.add %161, %123  : i64
      %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
      %167 = llvm.mul %121, %71  : i64
      %168 = llvm.add %113, %167  : i64
      %169 = llvm.add %168, %123  : i64
      %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
      %174 = llvm.mul %122, %71  : i64
      %175 = llvm.add %113, %174  : i64
      %176 = llvm.add %175, %123  : i64
      %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
      %183 = llvm.icmp "slt" %181, %78 : i64
      llvm.cond_br %183, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %184 = llvm.mul %114, %78  : i64
      %185 = llvm.add %110, %184  : i64
      %186 = llvm.add %185, %181  : i64
      %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %190 = llvm.mul %116, %78  : i64
      %191 = llvm.add %110, %190  : i64
      %192 = llvm.add %191, %181  : i64
      %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %196 = llvm.mul %117, %78  : i64
      %197 = llvm.add %110, %196  : i64
      %198 = llvm.add %197, %181  : i64
      %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %202 = llvm.mul %118, %78  : i64
      %203 = llvm.add %110, %202  : i64
      %204 = llvm.add %203, %181  : i64
      %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %208 = llvm.mul %119, %78  : i64
      %209 = llvm.add %110, %208  : i64
      %210 = llvm.add %209, %181  : i64
      %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %214 = llvm.mul %120, %78  : i64
      %215 = llvm.add %110, %214  : i64
      %216 = llvm.add %215, %181  : i64
      %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %220 = llvm.mul %121, %78  : i64
      %221 = llvm.add %110, %220  : i64
      %222 = llvm.add %221, %181  : i64
      %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %226 = llvm.mul %122, %78  : i64
      %227 = llvm.add %110, %226  : i64
      %228 = llvm.add %227, %181  : i64
      %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %232 = llvm.mul %181, %71  : i64
      %233 = llvm.add %111, %232  : i64
      %234 = llvm.add %233, %123  : i64
      %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %238 = llvm.add %181, %74  : i64
      %239 = llvm.mul %238, %71  : i64
      %240 = llvm.add %111, %239  : i64
      %241 = llvm.add %240, %123  : i64
      %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %245 = llvm.add %181, %67  : i64
      %246 = llvm.mul %245, %71  : i64
      %247 = llvm.add %111, %246  : i64
      %248 = llvm.add %247, %123  : i64
      %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %252 = llvm.add %181, %66  : i64
      %253 = llvm.mul %252, %71  : i64
      %254 = llvm.add %111, %253  : i64
      %255 = llvm.add %254, %123  : i64
      %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %259 = llvm.add %181, %65  : i64
      %260 = llvm.mul %259, %71  : i64
      %261 = llvm.add %111, %260  : i64
      %262 = llvm.add %261, %123  : i64
      %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %266 = llvm.add %181, %64  : i64
      %267 = llvm.mul %266, %71  : i64
      %268 = llvm.add %111, %267  : i64
      %269 = llvm.add %268, %123  : i64
      %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %273 = llvm.add %181, %63  : i64
      %274 = llvm.mul %273, %71  : i64
      %275 = llvm.add %111, %274  : i64
      %276 = llvm.add %275, %123  : i64
      %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %280 = llvm.add %181, %62  : i64
      %281 = llvm.mul %280, %71  : i64
      %282 = llvm.add %111, %281  : i64
      %283 = llvm.add %282, %123  : i64
      %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
      %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
      %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
      %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
      %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
      %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
      %305 = llvm.mlir.undef : vector<8xf32>
      %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
      %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
      %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
      %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
      %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
      %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
      %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
      %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
      %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
      %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
      %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
      %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
      %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
      %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
      %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
      %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
      %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
      %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
      %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
      %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
      %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
      %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
      %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
      %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
      %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
      %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
      %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
      %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
      %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
      %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
      %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
      %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
      %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
      %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
      %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
      %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
      %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
      %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
      %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
      %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
      %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
      %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
      %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
      %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
      %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
      %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
      %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
      %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
      %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
      %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
      %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
      %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
      %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
      %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
      %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
      %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
      %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
      %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
      %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
      %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
      %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
      %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
      %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
      %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
      %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
      %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
      %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
      %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
      %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
      %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
      %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
      %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
      %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
      %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
      %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
      %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
      %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
      %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
      %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
      %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
      %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
      %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
      %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
      %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
      %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
      %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
      %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
      %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
      %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
      %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
      %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
      %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
      %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
      %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
      %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
      %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
      %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
      %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
      %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
      %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
      %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
      %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
      %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
      %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
      %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
      %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
      %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
      %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
      %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
      %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
      %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
      %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
      %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
      %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
      %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
      %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
      %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
      %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
      %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
      %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
      %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
      %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
      %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
      %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
      %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
      %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
      %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
      %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
      %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
      %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
      %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
      %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
      %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
      %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
      %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
      %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
      %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
      %577 = llvm.add %181, %79  : i64
      llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
    ^bb7:  // pred: ^bb5
      %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
      llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
      %586 = llvm.add %123, %79  : i64
      llvm.br ^bb3(%586 : i64)
    ^bb8:  // pred: ^bb3
      %587 = llvm.add %114, %79  : i64
      llvm.br ^bb1(%587 : i64)
    ^bb9:  // pred: ^bb1
      llvm.return %61 : i32
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkExecutablesPass (iree-hal-link-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@matmul_static_dispatch_0::@embedded_elf_x86_64::@matmul_static_dispatch_0_matmul_512x1024x256) workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      %1 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%1 : !hal.device) executable(@matmul_static_dispatch_0) : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.switch<%device : !hal.device> -> !hal.executable
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
      hal.return %exe : !hal.executable
    },
    #hal.match.always {
      %1 = util.null : !hal.executable
      hal.return %1 : !hal.executable
    }
    util.global.store %0, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
        %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
        %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
      ])
      %1 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb5(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %true = arith.constant true
  cf.cond_br %true, ^bb3, ^bb4
^bb3:  // pred: ^bb2
  %0 = util.null : !hal.executable
  cf.br ^bb5(%0 : !hal.executable)
^bb4:  // pred: ^bb2
  util.unreachable "device not supported in the compiled configuration"
^bb5(%1: !hal.executable):  // 2 preds: ^bb1, ^bb3
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  cf.br ^bb3
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
^bb3:  // pred: ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %1 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%1) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb5(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %true = arith.constant true
    cf.cond_br %true, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %0 = util.null : !hal.executable
    cf.br ^bb5(%0 : !hal.executable)
  ^bb4:  // pred: ^bb2
    util.unreachable "device not supported in the compiled configuration"
  ^bb5(%1: !hal.executable):  // 2 preds: ^bb1, ^bb3
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  ^bb3:  // pred: ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %1 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%1) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.global.store %ok, @_device_query_0_ok : i1
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.global.store %ok, @_device_query_0_ok : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c256 = arith.constant 256 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1 = arith.constant 1 : index
  %c1024 = arith.constant 1024 : index
  %c512 = arith.constant 512 : index
  %c2097152 = arith.constant 2097152 : index
  %c1048576 = arith.constant 1048576 : index
  %c524288 = arith.constant 524288 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %c2 = arith.constant 2 : index
  %c32 = arith.constant 32 : index
  %c16 = arith.constant 16 : index
  %c-1_i32 = arith.constant -1 : i32
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c256 = arith.constant 256 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1 = arith.constant 1 : index
  %c1024 = arith.constant 1024 : index
  %c512 = arith.constant 512 : index
  %c2097152 = arith.constant 2097152 : index
  %c1048576 = arith.constant 1048576 : index
  %c524288 = arith.constant 524288 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %c2 = arith.constant 2 : index
  %c32 = arith.constant 32 : index
  %c16 = arith.constant 16 : index
  %c-1_i32 = arith.constant -1 : i32
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDoubleTilingPadExpert>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @matmul_static_dispatch_0_matmul_512x1024x256 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index, %arg3: index):
        %c32 = arith.constant 32 : index
        %c16 = arith.constant 16 : index
        %c1 = arith.constant 1 : index
        hal.return %c32, %c16, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.func @matmul_static_dispatch_0_matmul_512x1024x256(%arg0: !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr<i32>, ptr<func<i32 (ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<i8>, ptr<i8>, ptr<i8>)>>, ptr<ptr<func<i32 (ptr<i8>, ptr<i8>, ptr<i8>)>>>, ptr<ptr<i8>>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>> {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>> {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(63 : i64) : i64
          %1 = llvm.mlir.constant(62 : i64) : i64
          %2 = llvm.mlir.constant(61 : i64) : i64
          %3 = llvm.mlir.constant(60 : i64) : i64
          %4 = llvm.mlir.constant(59 : i64) : i64
          %5 = llvm.mlir.constant(58 : i64) : i64
          %6 = llvm.mlir.constant(57 : i64) : i64
          %7 = llvm.mlir.constant(56 : i64) : i64
          %8 = llvm.mlir.constant(55 : i64) : i64
          %9 = llvm.mlir.constant(54 : i64) : i64
          %10 = llvm.mlir.constant(53 : i64) : i64
          %11 = llvm.mlir.constant(52 : i64) : i64
          %12 = llvm.mlir.constant(51 : i64) : i64
          %13 = llvm.mlir.constant(50 : i64) : i64
          %14 = llvm.mlir.constant(49 : i64) : i64
          %15 = llvm.mlir.constant(48 : i64) : i64
          %16 = llvm.mlir.constant(47 : i64) : i64
          %17 = llvm.mlir.constant(46 : i64) : i64
          %18 = llvm.mlir.constant(45 : i64) : i64
          %19 = llvm.mlir.constant(44 : i64) : i64
          %20 = llvm.mlir.constant(43 : i64) : i64
          %21 = llvm.mlir.constant(42 : i64) : i64
          %22 = llvm.mlir.constant(41 : i64) : i64
          %23 = llvm.mlir.constant(40 : i64) : i64
          %24 = llvm.mlir.constant(39 : i64) : i64
          %25 = llvm.mlir.constant(38 : i64) : i64
          %26 = llvm.mlir.constant(37 : i64) : i64
          %27 = llvm.mlir.constant(36 : i64) : i64
          %28 = llvm.mlir.constant(35 : i64) : i64
          %29 = llvm.mlir.constant(34 : i64) : i64
          %30 = llvm.mlir.constant(33 : i64) : i64
          %31 = llvm.mlir.constant(32 : i64) : i64
          %32 = llvm.mlir.constant(31 : i64) : i64
          %33 = llvm.mlir.constant(30 : i64) : i64
          %34 = llvm.mlir.constant(29 : i64) : i64
          %35 = llvm.mlir.constant(28 : i64) : i64
          %36 = llvm.mlir.constant(27 : i64) : i64
          %37 = llvm.mlir.constant(26 : i64) : i64
          %38 = llvm.mlir.constant(25 : i64) : i64
          %39 = llvm.mlir.constant(24 : i64) : i64
          %40 = llvm.mlir.constant(23 : i64) : i64
          %41 = llvm.mlir.constant(22 : i64) : i64
          %42 = llvm.mlir.constant(21 : i64) : i64
          %43 = llvm.mlir.constant(20 : i64) : i64
          %44 = llvm.mlir.constant(19 : i64) : i64
          %45 = llvm.mlir.constant(18 : i64) : i64
          %46 = llvm.mlir.constant(17 : i64) : i64
          %47 = llvm.mlir.constant(16 : i64) : i64
          %48 = llvm.mlir.constant(15 : i64) : i64
          %49 = llvm.mlir.constant(14 : i64) : i64
          %50 = llvm.mlir.constant(13 : i64) : i64
          %51 = llvm.mlir.constant(12 : i64) : i64
          %52 = llvm.mlir.constant(11 : i64) : i64
          %53 = llvm.mlir.constant(10 : i64) : i64
          %54 = llvm.mlir.constant(9 : i64) : i64
          %55 = llvm.mlir.constant(8 : i64) : i64
          %56 = llvm.mlir.constant(7 : i64) : i64
          %57 = llvm.mlir.constant(6 : i64) : i64
          %58 = llvm.mlir.constant(5 : i64) : i64
          %59 = llvm.mlir.constant(4 : i64) : i64
          %60 = llvm.mlir.constant(3 : i64) : i64
          %61 = llvm.mlir.constant(0 : i32) : i32
          %62 = llvm.mlir.constant(7 : index) : i64
          %63 = llvm.mlir.constant(6 : index) : i64
          %64 = llvm.mlir.constant(5 : index) : i64
          %65 = llvm.mlir.constant(4 : index) : i64
          %66 = llvm.mlir.constant(3 : index) : i64
          %67 = llvm.mlir.constant(2 : index) : i64
          %68 = llvm.mlir.constant(32768 : index) : i64
          %69 = llvm.mlir.constant(8192 : index) : i64
          %70 = llvm.mlir.constant(2 : i64) : i64
          %71 = llvm.mlir.constant(1024 : index) : i64
          %72 = llvm.mlir.constant(1 : i64) : i64
          %73 = llvm.mlir.constant(63 : index) : i64
          %74 = llvm.mlir.constant(1 : index) : i64
          %75 = llvm.mlir.constant(0 : i64) : i64
          %76 = llvm.mlir.constant(dense<0.000000e+00> : vector<64xf32>) : vector<64xf32>
          %77 = llvm.mlir.constant(dense<0.000000e+00> : vector<8x8xf32>) : !llvm.array<8 x vector<8xf32>>
          %78 = llvm.mlir.constant(256 : index) : i64
          %79 = llvm.mlir.constant(8 : index) : i64
          %80 = llvm.mlir.constant(32 : index) : i64
          %81 = llvm.mlir.constant(0 : index) : i64
          %82 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %83 = llvm.extractvalue %82[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %84 = llvm.load %83 : !llvm.ptr<ptr<i8>>
          %85 = llvm.bitcast %84 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %86 = llvm.ptrtoint %85 : !llvm.ptr<f32> to i64
          %87 = llvm.and %86, %73  : i64
          %88 = llvm.icmp "eq" %87, %81 : i64
          "llvm.intr.assume"(%88) : (i1) -> ()
          %89 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %90 = llvm.extractvalue %89[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %91 = llvm.getelementptr %90[1] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %92 = llvm.load %91 : !llvm.ptr<ptr<i8>>
          %93 = llvm.bitcast %92 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %94 = llvm.ptrtoint %93 : !llvm.ptr<f32> to i64
          %95 = llvm.and %94, %73  : i64
          %96 = llvm.icmp "eq" %95, %81 : i64
          "llvm.intr.assume"(%96) : (i1) -> ()
          %97 = llvm.load %arg1 : !llvm.ptr<struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)>>
          %98 = llvm.extractvalue %97[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr<i32>, ptr<ptr<i8>>, ptr<i64>)> 
          %99 = llvm.getelementptr %98[2] : (!llvm.ptr<ptr<i8>>) -> !llvm.ptr<ptr<i8>>
          %100 = llvm.load %99 : !llvm.ptr<ptr<i8>>
          %101 = llvm.bitcast %100 : !llvm.ptr<i8> to !llvm.ptr<f32>
          %102 = llvm.ptrtoint %101 : !llvm.ptr<f32> to i64
          %103 = llvm.and %102, %73  : i64
          %104 = llvm.icmp "eq" %103, %81 : i64
          "llvm.intr.assume"(%104) : (i1) -> ()
          %105 = llvm.load %arg2 : !llvm.ptr<struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)>>
          %106 = llvm.extractvalue %105[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %107 = llvm.zext %106 : i32 to i64
          %108 = llvm.extractvalue %105[1] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr<ptr<i8>>, i32)> 
          %109 = llvm.zext %108 : i32 to i64
          %110 = llvm.mul %109, %69  : i64
          %111 = llvm.mul %107, %80  : i64
          %112 = llvm.mul %109, %68  : i64
          %113 = llvm.add %112, %111  : i64
          llvm.br ^bb1(%81 : i64)
        ^bb1(%114: i64):  // 2 preds: ^bb0, ^bb8
          %115 = llvm.icmp "slt" %114, %80 : i64
          llvm.cond_br %115, ^bb2, ^bb9
        ^bb2:  // pred: ^bb1
          %116 = llvm.add %114, %74  : i64
          %117 = llvm.add %114, %67  : i64
          %118 = llvm.add %114, %66  : i64
          %119 = llvm.add %114, %65  : i64
          %120 = llvm.add %114, %64  : i64
          %121 = llvm.add %114, %63  : i64
          %122 = llvm.add %114, %62  : i64
          llvm.br ^bb3(%81 : i64)
        ^bb3(%123: i64):  // 2 preds: ^bb2, ^bb7
          %124 = llvm.icmp "slt" %123, %80 : i64
          llvm.cond_br %124, ^bb4, ^bb8
        ^bb4:  // pred: ^bb3
          %125 = llvm.mul %114, %71  : i64
          %126 = llvm.add %113, %125  : i64
          %127 = llvm.add %126, %123  : i64
          %128 = llvm.getelementptr %101[%127] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %129 = llvm.bitcast %128 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %130 = llvm.load %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %131 = llvm.insertvalue %130, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %132 = llvm.mul %116, %71  : i64
          %133 = llvm.add %113, %132  : i64
          %134 = llvm.add %133, %123  : i64
          %135 = llvm.getelementptr %101[%134] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %136 = llvm.bitcast %135 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %137 = llvm.load %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %138 = llvm.insertvalue %137, %131[1] : !llvm.array<8 x vector<8xf32>> 
          %139 = llvm.mul %117, %71  : i64
          %140 = llvm.add %113, %139  : i64
          %141 = llvm.add %140, %123  : i64
          %142 = llvm.getelementptr %101[%141] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %143 = llvm.bitcast %142 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %144 = llvm.load %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %145 = llvm.insertvalue %144, %138[2] : !llvm.array<8 x vector<8xf32>> 
          %146 = llvm.mul %118, %71  : i64
          %147 = llvm.add %113, %146  : i64
          %148 = llvm.add %147, %123  : i64
          %149 = llvm.getelementptr %101[%148] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %150 = llvm.bitcast %149 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %151 = llvm.load %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %152 = llvm.insertvalue %151, %145[3] : !llvm.array<8 x vector<8xf32>> 
          %153 = llvm.mul %119, %71  : i64
          %154 = llvm.add %113, %153  : i64
          %155 = llvm.add %154, %123  : i64
          %156 = llvm.getelementptr %101[%155] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %157 = llvm.bitcast %156 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %158 = llvm.load %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %159 = llvm.insertvalue %158, %152[4] : !llvm.array<8 x vector<8xf32>> 
          %160 = llvm.mul %120, %71  : i64
          %161 = llvm.add %113, %160  : i64
          %162 = llvm.add %161, %123  : i64
          %163 = llvm.getelementptr %101[%162] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %164 = llvm.bitcast %163 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %165 = llvm.load %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %166 = llvm.insertvalue %165, %159[5] : !llvm.array<8 x vector<8xf32>> 
          %167 = llvm.mul %121, %71  : i64
          %168 = llvm.add %113, %167  : i64
          %169 = llvm.add %168, %123  : i64
          %170 = llvm.getelementptr %101[%169] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %171 = llvm.bitcast %170 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %172 = llvm.load %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %173 = llvm.insertvalue %172, %166[6] : !llvm.array<8 x vector<8xf32>> 
          %174 = llvm.mul %122, %71  : i64
          %175 = llvm.add %113, %174  : i64
          %176 = llvm.add %175, %123  : i64
          %177 = llvm.getelementptr %101[%176] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %178 = llvm.bitcast %177 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %179 = llvm.load %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %180 = llvm.insertvalue %179, %173[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.br ^bb5(%81, %180 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb5(%181: i64, %182: !llvm.array<8 x vector<8xf32>>):  // 2 preds: ^bb4, ^bb6
          %183 = llvm.icmp "slt" %181, %78 : i64
          llvm.cond_br %183, ^bb6, ^bb7
        ^bb6:  // pred: ^bb5
          %184 = llvm.mul %114, %78  : i64
          %185 = llvm.add %110, %184  : i64
          %186 = llvm.add %185, %181  : i64
          %187 = llvm.getelementptr %85[%186] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %188 = llvm.bitcast %187 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %189 = llvm.load %188 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %190 = llvm.mul %116, %78  : i64
          %191 = llvm.add %110, %190  : i64
          %192 = llvm.add %191, %181  : i64
          %193 = llvm.getelementptr %85[%192] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %194 = llvm.bitcast %193 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %195 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %196 = llvm.mul %117, %78  : i64
          %197 = llvm.add %110, %196  : i64
          %198 = llvm.add %197, %181  : i64
          %199 = llvm.getelementptr %85[%198] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %200 = llvm.bitcast %199 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %201 = llvm.load %200 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %202 = llvm.mul %118, %78  : i64
          %203 = llvm.add %110, %202  : i64
          %204 = llvm.add %203, %181  : i64
          %205 = llvm.getelementptr %85[%204] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %206 = llvm.bitcast %205 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %207 = llvm.load %206 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %208 = llvm.mul %119, %78  : i64
          %209 = llvm.add %110, %208  : i64
          %210 = llvm.add %209, %181  : i64
          %211 = llvm.getelementptr %85[%210] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %212 = llvm.bitcast %211 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %213 = llvm.load %212 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %214 = llvm.mul %120, %78  : i64
          %215 = llvm.add %110, %214  : i64
          %216 = llvm.add %215, %181  : i64
          %217 = llvm.getelementptr %85[%216] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %218 = llvm.bitcast %217 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %219 = llvm.load %218 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %220 = llvm.mul %121, %78  : i64
          %221 = llvm.add %110, %220  : i64
          %222 = llvm.add %221, %181  : i64
          %223 = llvm.getelementptr %85[%222] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %224 = llvm.bitcast %223 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %225 = llvm.load %224 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %226 = llvm.mul %122, %78  : i64
          %227 = llvm.add %110, %226  : i64
          %228 = llvm.add %227, %181  : i64
          %229 = llvm.getelementptr %85[%228] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %230 = llvm.bitcast %229 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %231 = llvm.load %230 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %232 = llvm.mul %181, %71  : i64
          %233 = llvm.add %111, %232  : i64
          %234 = llvm.add %233, %123  : i64
          %235 = llvm.getelementptr %93[%234] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %236 = llvm.bitcast %235 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %237 = llvm.load %236 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %238 = llvm.add %181, %74  : i64
          %239 = llvm.mul %238, %71  : i64
          %240 = llvm.add %111, %239  : i64
          %241 = llvm.add %240, %123  : i64
          %242 = llvm.getelementptr %93[%241] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %243 = llvm.bitcast %242 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %244 = llvm.load %243 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %245 = llvm.add %181, %67  : i64
          %246 = llvm.mul %245, %71  : i64
          %247 = llvm.add %111, %246  : i64
          %248 = llvm.add %247, %123  : i64
          %249 = llvm.getelementptr %93[%248] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %250 = llvm.bitcast %249 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %251 = llvm.load %250 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %252 = llvm.add %181, %66  : i64
          %253 = llvm.mul %252, %71  : i64
          %254 = llvm.add %111, %253  : i64
          %255 = llvm.add %254, %123  : i64
          %256 = llvm.getelementptr %93[%255] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %257 = llvm.bitcast %256 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %258 = llvm.load %257 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %259 = llvm.add %181, %65  : i64
          %260 = llvm.mul %259, %71  : i64
          %261 = llvm.add %111, %260  : i64
          %262 = llvm.add %261, %123  : i64
          %263 = llvm.getelementptr %93[%262] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %264 = llvm.bitcast %263 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %265 = llvm.load %264 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %266 = llvm.add %181, %64  : i64
          %267 = llvm.mul %266, %71  : i64
          %268 = llvm.add %111, %267  : i64
          %269 = llvm.add %268, %123  : i64
          %270 = llvm.getelementptr %93[%269] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %271 = llvm.bitcast %270 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %272 = llvm.load %271 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %273 = llvm.add %181, %63  : i64
          %274 = llvm.mul %273, %71  : i64
          %275 = llvm.add %111, %274  : i64
          %276 = llvm.add %275, %123  : i64
          %277 = llvm.getelementptr %93[%276] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %278 = llvm.bitcast %277 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %279 = llvm.load %278 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %280 = llvm.add %181, %62  : i64
          %281 = llvm.mul %280, %71  : i64
          %282 = llvm.add %111, %281  : i64
          %283 = llvm.add %282, %123  : i64
          %284 = llvm.getelementptr %93[%283] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
          %285 = llvm.bitcast %284 : !llvm.ptr<f32> to !llvm.ptr<vector<8xf32>>
          %286 = llvm.load %285 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %287 = llvm.shufflevector %189, %189 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %288 = llvm.shufflevector %287, %76 [0, 1, 2, 3, 4, 5, 6, 7, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %289 = llvm.shufflevector %195, %195 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %290 = llvm.shufflevector %289, %288 [64, 65, 66, 67, 68, 69, 70, 71, 0, 1, 2, 3, 4, 5, 6, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %291 = llvm.shufflevector %201, %201 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %292 = llvm.shufflevector %291, %290 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 0, 1, 2, 3, 4, 5, 6, 7, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %293 = llvm.shufflevector %207, %207 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %294 = llvm.shufflevector %293, %292 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 0, 1, 2, 3, 4, 5, 6, 7, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %295 = llvm.shufflevector %213, %213 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %296 = llvm.shufflevector %295, %294 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 0, 1, 2, 3, 4, 5, 6, 7, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %297 = llvm.shufflevector %219, %219 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %298 = llvm.shufflevector %297, %296 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 0, 1, 2, 3, 4, 5, 6, 7, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %299 = llvm.shufflevector %225, %225 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %300 = llvm.shufflevector %299, %298 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 0, 1, 2, 3, 4, 5, 6, 7, 120, 121, 122, 123, 124, 125, 126, 127] : vector<64xf32> 
          %301 = llvm.shufflevector %231, %231 [0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %302 = llvm.shufflevector %301, %300 [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 0, 1, 2, 3, 4, 5, 6, 7] : vector<64xf32> 
          %303 = llvm.shufflevector %302, %302 [0, 8, 16, 24, 32, 40, 48, 56, 1, 9, 17, 25, 33, 41, 49, 57, 2, 10, 18, 26, 34, 42, 50, 58, 3, 11, 19, 27, 35, 43, 51, 59, 4, 12, 20, 28, 36, 44, 52, 60, 5, 13, 21, 29, 37, 45, 53, 61, 6, 14, 22, 30, 38, 46, 54, 62, 7, 15, 23, 31, 39, 47, 55, 63] : vector<64xf32> 
          %304 = llvm.extractelement %303[%75 : i64] : vector<64xf32>
          %305 = llvm.mlir.undef : vector<8xf32>
          %306 = llvm.insertelement %304, %305[%61 : i32] : vector<8xf32>
          %307 = llvm.shufflevector %306, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %308 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          %309 = llvm.intr.fmuladd(%307, %237, %308)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %310 = llvm.extractelement %303[%72 : i64] : vector<64xf32>
          %311 = llvm.insertelement %310, %305[%61 : i32] : vector<8xf32>
          %312 = llvm.shufflevector %311, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %313 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          %314 = llvm.intr.fmuladd(%312, %237, %313)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %315 = llvm.extractelement %303[%70 : i64] : vector<64xf32>
          %316 = llvm.insertelement %315, %305[%61 : i32] : vector<8xf32>
          %317 = llvm.shufflevector %316, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %318 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          %319 = llvm.intr.fmuladd(%317, %237, %318)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %320 = llvm.extractelement %303[%60 : i64] : vector<64xf32>
          %321 = llvm.insertelement %320, %305[%61 : i32] : vector<8xf32>
          %322 = llvm.shufflevector %321, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %323 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          %324 = llvm.intr.fmuladd(%322, %237, %323)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %325 = llvm.extractelement %303[%59 : i64] : vector<64xf32>
          %326 = llvm.insertelement %325, %305[%61 : i32] : vector<8xf32>
          %327 = llvm.shufflevector %326, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %328 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          %329 = llvm.intr.fmuladd(%327, %237, %328)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %330 = llvm.extractelement %303[%58 : i64] : vector<64xf32>
          %331 = llvm.insertelement %330, %305[%61 : i32] : vector<8xf32>
          %332 = llvm.shufflevector %331, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %333 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          %334 = llvm.intr.fmuladd(%332, %237, %333)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %335 = llvm.extractelement %303[%57 : i64] : vector<64xf32>
          %336 = llvm.insertelement %335, %305[%61 : i32] : vector<8xf32>
          %337 = llvm.shufflevector %336, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %338 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          %339 = llvm.intr.fmuladd(%337, %237, %338)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %340 = llvm.extractelement %303[%56 : i64] : vector<64xf32>
          %341 = llvm.insertelement %340, %305[%61 : i32] : vector<8xf32>
          %342 = llvm.shufflevector %341, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %343 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          %344 = llvm.intr.fmuladd(%342, %237, %343)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %345 = llvm.extractelement %303[%55 : i64] : vector<64xf32>
          %346 = llvm.insertelement %345, %305[%61 : i32] : vector<8xf32>
          %347 = llvm.shufflevector %346, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %348 = llvm.intr.fmuladd(%347, %244, %309)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %349 = llvm.extractelement %303[%54 : i64] : vector<64xf32>
          %350 = llvm.insertelement %349, %305[%61 : i32] : vector<8xf32>
          %351 = llvm.shufflevector %350, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %352 = llvm.intr.fmuladd(%351, %244, %314)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %353 = llvm.extractelement %303[%53 : i64] : vector<64xf32>
          %354 = llvm.insertelement %353, %305[%61 : i32] : vector<8xf32>
          %355 = llvm.shufflevector %354, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %356 = llvm.intr.fmuladd(%355, %244, %319)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %357 = llvm.extractelement %303[%52 : i64] : vector<64xf32>
          %358 = llvm.insertelement %357, %305[%61 : i32] : vector<8xf32>
          %359 = llvm.shufflevector %358, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %360 = llvm.intr.fmuladd(%359, %244, %324)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %361 = llvm.extractelement %303[%51 : i64] : vector<64xf32>
          %362 = llvm.insertelement %361, %305[%61 : i32] : vector<8xf32>
          %363 = llvm.shufflevector %362, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %364 = llvm.intr.fmuladd(%363, %244, %329)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %365 = llvm.extractelement %303[%50 : i64] : vector<64xf32>
          %366 = llvm.insertelement %365, %305[%61 : i32] : vector<8xf32>
          %367 = llvm.shufflevector %366, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %368 = llvm.intr.fmuladd(%367, %244, %334)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %369 = llvm.extractelement %303[%49 : i64] : vector<64xf32>
          %370 = llvm.insertelement %369, %305[%61 : i32] : vector<8xf32>
          %371 = llvm.shufflevector %370, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %372 = llvm.intr.fmuladd(%371, %244, %339)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %373 = llvm.extractelement %303[%48 : i64] : vector<64xf32>
          %374 = llvm.insertelement %373, %305[%61 : i32] : vector<8xf32>
          %375 = llvm.shufflevector %374, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %376 = llvm.intr.fmuladd(%375, %244, %344)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %377 = llvm.extractelement %303[%47 : i64] : vector<64xf32>
          %378 = llvm.insertelement %377, %305[%61 : i32] : vector<8xf32>
          %379 = llvm.shufflevector %378, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %380 = llvm.intr.fmuladd(%379, %251, %348)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %381 = llvm.extractelement %303[%46 : i64] : vector<64xf32>
          %382 = llvm.insertelement %381, %305[%61 : i32] : vector<8xf32>
          %383 = llvm.shufflevector %382, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %384 = llvm.intr.fmuladd(%383, %251, %352)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %385 = llvm.extractelement %303[%45 : i64] : vector<64xf32>
          %386 = llvm.insertelement %385, %305[%61 : i32] : vector<8xf32>
          %387 = llvm.shufflevector %386, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %388 = llvm.intr.fmuladd(%387, %251, %356)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %389 = llvm.extractelement %303[%44 : i64] : vector<64xf32>
          %390 = llvm.insertelement %389, %305[%61 : i32] : vector<8xf32>
          %391 = llvm.shufflevector %390, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %392 = llvm.intr.fmuladd(%391, %251, %360)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %393 = llvm.extractelement %303[%43 : i64] : vector<64xf32>
          %394 = llvm.insertelement %393, %305[%61 : i32] : vector<8xf32>
          %395 = llvm.shufflevector %394, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %396 = llvm.intr.fmuladd(%395, %251, %364)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %397 = llvm.extractelement %303[%42 : i64] : vector<64xf32>
          %398 = llvm.insertelement %397, %305[%61 : i32] : vector<8xf32>
          %399 = llvm.shufflevector %398, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %400 = llvm.intr.fmuladd(%399, %251, %368)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %401 = llvm.extractelement %303[%41 : i64] : vector<64xf32>
          %402 = llvm.insertelement %401, %305[%61 : i32] : vector<8xf32>
          %403 = llvm.shufflevector %402, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %404 = llvm.intr.fmuladd(%403, %251, %372)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %405 = llvm.extractelement %303[%40 : i64] : vector<64xf32>
          %406 = llvm.insertelement %405, %305[%61 : i32] : vector<8xf32>
          %407 = llvm.shufflevector %406, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %408 = llvm.intr.fmuladd(%407, %251, %376)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %409 = llvm.extractelement %303[%39 : i64] : vector<64xf32>
          %410 = llvm.insertelement %409, %305[%61 : i32] : vector<8xf32>
          %411 = llvm.shufflevector %410, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %412 = llvm.intr.fmuladd(%411, %258, %380)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %413 = llvm.extractelement %303[%38 : i64] : vector<64xf32>
          %414 = llvm.insertelement %413, %305[%61 : i32] : vector<8xf32>
          %415 = llvm.shufflevector %414, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %416 = llvm.intr.fmuladd(%415, %258, %384)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %417 = llvm.extractelement %303[%37 : i64] : vector<64xf32>
          %418 = llvm.insertelement %417, %305[%61 : i32] : vector<8xf32>
          %419 = llvm.shufflevector %418, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %420 = llvm.intr.fmuladd(%419, %258, %388)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %421 = llvm.extractelement %303[%36 : i64] : vector<64xf32>
          %422 = llvm.insertelement %421, %305[%61 : i32] : vector<8xf32>
          %423 = llvm.shufflevector %422, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %424 = llvm.intr.fmuladd(%423, %258, %392)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %425 = llvm.extractelement %303[%35 : i64] : vector<64xf32>
          %426 = llvm.insertelement %425, %305[%61 : i32] : vector<8xf32>
          %427 = llvm.shufflevector %426, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %428 = llvm.intr.fmuladd(%427, %258, %396)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %429 = llvm.extractelement %303[%34 : i64] : vector<64xf32>
          %430 = llvm.insertelement %429, %305[%61 : i32] : vector<8xf32>
          %431 = llvm.shufflevector %430, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %432 = llvm.intr.fmuladd(%431, %258, %400)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %433 = llvm.extractelement %303[%33 : i64] : vector<64xf32>
          %434 = llvm.insertelement %433, %305[%61 : i32] : vector<8xf32>
          %435 = llvm.shufflevector %434, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %436 = llvm.intr.fmuladd(%435, %258, %404)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %437 = llvm.extractelement %303[%32 : i64] : vector<64xf32>
          %438 = llvm.insertelement %437, %305[%61 : i32] : vector<8xf32>
          %439 = llvm.shufflevector %438, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %440 = llvm.intr.fmuladd(%439, %258, %408)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %441 = llvm.extractelement %303[%31 : i64] : vector<64xf32>
          %442 = llvm.insertelement %441, %305[%61 : i32] : vector<8xf32>
          %443 = llvm.shufflevector %442, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %444 = llvm.intr.fmuladd(%443, %265, %412)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %445 = llvm.extractelement %303[%30 : i64] : vector<64xf32>
          %446 = llvm.insertelement %445, %305[%61 : i32] : vector<8xf32>
          %447 = llvm.shufflevector %446, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %448 = llvm.intr.fmuladd(%447, %265, %416)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %449 = llvm.extractelement %303[%29 : i64] : vector<64xf32>
          %450 = llvm.insertelement %449, %305[%61 : i32] : vector<8xf32>
          %451 = llvm.shufflevector %450, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %452 = llvm.intr.fmuladd(%451, %265, %420)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %453 = llvm.extractelement %303[%28 : i64] : vector<64xf32>
          %454 = llvm.insertelement %453, %305[%61 : i32] : vector<8xf32>
          %455 = llvm.shufflevector %454, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %456 = llvm.intr.fmuladd(%455, %265, %424)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %457 = llvm.extractelement %303[%27 : i64] : vector<64xf32>
          %458 = llvm.insertelement %457, %305[%61 : i32] : vector<8xf32>
          %459 = llvm.shufflevector %458, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %460 = llvm.intr.fmuladd(%459, %265, %428)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %461 = llvm.extractelement %303[%26 : i64] : vector<64xf32>
          %462 = llvm.insertelement %461, %305[%61 : i32] : vector<8xf32>
          %463 = llvm.shufflevector %462, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %464 = llvm.intr.fmuladd(%463, %265, %432)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %465 = llvm.extractelement %303[%25 : i64] : vector<64xf32>
          %466 = llvm.insertelement %465, %305[%61 : i32] : vector<8xf32>
          %467 = llvm.shufflevector %466, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %468 = llvm.intr.fmuladd(%467, %265, %436)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %469 = llvm.extractelement %303[%24 : i64] : vector<64xf32>
          %470 = llvm.insertelement %469, %305[%61 : i32] : vector<8xf32>
          %471 = llvm.shufflevector %470, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %472 = llvm.intr.fmuladd(%471, %265, %440)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %473 = llvm.extractelement %303[%23 : i64] : vector<64xf32>
          %474 = llvm.insertelement %473, %305[%61 : i32] : vector<8xf32>
          %475 = llvm.shufflevector %474, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %476 = llvm.intr.fmuladd(%475, %272, %444)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %477 = llvm.extractelement %303[%22 : i64] : vector<64xf32>
          %478 = llvm.insertelement %477, %305[%61 : i32] : vector<8xf32>
          %479 = llvm.shufflevector %478, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %480 = llvm.intr.fmuladd(%479, %272, %448)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %481 = llvm.extractelement %303[%21 : i64] : vector<64xf32>
          %482 = llvm.insertelement %481, %305[%61 : i32] : vector<8xf32>
          %483 = llvm.shufflevector %482, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %484 = llvm.intr.fmuladd(%483, %272, %452)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %485 = llvm.extractelement %303[%20 : i64] : vector<64xf32>
          %486 = llvm.insertelement %485, %305[%61 : i32] : vector<8xf32>
          %487 = llvm.shufflevector %486, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %488 = llvm.intr.fmuladd(%487, %272, %456)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %489 = llvm.extractelement %303[%19 : i64] : vector<64xf32>
          %490 = llvm.insertelement %489, %305[%61 : i32] : vector<8xf32>
          %491 = llvm.shufflevector %490, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %492 = llvm.intr.fmuladd(%491, %272, %460)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %493 = llvm.extractelement %303[%18 : i64] : vector<64xf32>
          %494 = llvm.insertelement %493, %305[%61 : i32] : vector<8xf32>
          %495 = llvm.shufflevector %494, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %496 = llvm.intr.fmuladd(%495, %272, %464)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %497 = llvm.extractelement %303[%17 : i64] : vector<64xf32>
          %498 = llvm.insertelement %497, %305[%61 : i32] : vector<8xf32>
          %499 = llvm.shufflevector %498, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %500 = llvm.intr.fmuladd(%499, %272, %468)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %501 = llvm.extractelement %303[%16 : i64] : vector<64xf32>
          %502 = llvm.insertelement %501, %305[%61 : i32] : vector<8xf32>
          %503 = llvm.shufflevector %502, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %504 = llvm.intr.fmuladd(%503, %272, %472)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %505 = llvm.extractelement %303[%15 : i64] : vector<64xf32>
          %506 = llvm.insertelement %505, %305[%61 : i32] : vector<8xf32>
          %507 = llvm.shufflevector %506, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %508 = llvm.intr.fmuladd(%507, %279, %476)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %509 = llvm.extractelement %303[%14 : i64] : vector<64xf32>
          %510 = llvm.insertelement %509, %305[%61 : i32] : vector<8xf32>
          %511 = llvm.shufflevector %510, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %512 = llvm.intr.fmuladd(%511, %279, %480)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %513 = llvm.extractelement %303[%13 : i64] : vector<64xf32>
          %514 = llvm.insertelement %513, %305[%61 : i32] : vector<8xf32>
          %515 = llvm.shufflevector %514, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %516 = llvm.intr.fmuladd(%515, %279, %484)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %517 = llvm.extractelement %303[%12 : i64] : vector<64xf32>
          %518 = llvm.insertelement %517, %305[%61 : i32] : vector<8xf32>
          %519 = llvm.shufflevector %518, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %520 = llvm.intr.fmuladd(%519, %279, %488)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %521 = llvm.extractelement %303[%11 : i64] : vector<64xf32>
          %522 = llvm.insertelement %521, %305[%61 : i32] : vector<8xf32>
          %523 = llvm.shufflevector %522, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %524 = llvm.intr.fmuladd(%523, %279, %492)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %525 = llvm.extractelement %303[%10 : i64] : vector<64xf32>
          %526 = llvm.insertelement %525, %305[%61 : i32] : vector<8xf32>
          %527 = llvm.shufflevector %526, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %528 = llvm.intr.fmuladd(%527, %279, %496)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %529 = llvm.extractelement %303[%9 : i64] : vector<64xf32>
          %530 = llvm.insertelement %529, %305[%61 : i32] : vector<8xf32>
          %531 = llvm.shufflevector %530, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %532 = llvm.intr.fmuladd(%531, %279, %500)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %533 = llvm.extractelement %303[%8 : i64] : vector<64xf32>
          %534 = llvm.insertelement %533, %305[%61 : i32] : vector<8xf32>
          %535 = llvm.shufflevector %534, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %536 = llvm.intr.fmuladd(%535, %279, %504)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %537 = llvm.extractelement %303[%7 : i64] : vector<64xf32>
          %538 = llvm.insertelement %537, %305[%61 : i32] : vector<8xf32>
          %539 = llvm.shufflevector %538, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %540 = llvm.intr.fmuladd(%539, %286, %508)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %541 = llvm.insertvalue %540, %77[0] : !llvm.array<8 x vector<8xf32>> 
          %542 = llvm.extractelement %303[%6 : i64] : vector<64xf32>
          %543 = llvm.insertelement %542, %305[%61 : i32] : vector<8xf32>
          %544 = llvm.shufflevector %543, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %545 = llvm.intr.fmuladd(%544, %286, %512)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %546 = llvm.insertvalue %545, %541[1] : !llvm.array<8 x vector<8xf32>> 
          %547 = llvm.extractelement %303[%5 : i64] : vector<64xf32>
          %548 = llvm.insertelement %547, %305[%61 : i32] : vector<8xf32>
          %549 = llvm.shufflevector %548, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %550 = llvm.intr.fmuladd(%549, %286, %516)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %551 = llvm.insertvalue %550, %546[2] : !llvm.array<8 x vector<8xf32>> 
          %552 = llvm.extractelement %303[%4 : i64] : vector<64xf32>
          %553 = llvm.insertelement %552, %305[%61 : i32] : vector<8xf32>
          %554 = llvm.shufflevector %553, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %555 = llvm.intr.fmuladd(%554, %286, %520)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %556 = llvm.insertvalue %555, %551[3] : !llvm.array<8 x vector<8xf32>> 
          %557 = llvm.extractelement %303[%3 : i64] : vector<64xf32>
          %558 = llvm.insertelement %557, %305[%61 : i32] : vector<8xf32>
          %559 = llvm.shufflevector %558, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %560 = llvm.intr.fmuladd(%559, %286, %524)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %561 = llvm.insertvalue %560, %556[4] : !llvm.array<8 x vector<8xf32>> 
          %562 = llvm.extractelement %303[%2 : i64] : vector<64xf32>
          %563 = llvm.insertelement %562, %305[%61 : i32] : vector<8xf32>
          %564 = llvm.shufflevector %563, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %565 = llvm.intr.fmuladd(%564, %286, %528)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %566 = llvm.insertvalue %565, %561[5] : !llvm.array<8 x vector<8xf32>> 
          %567 = llvm.extractelement %303[%1 : i64] : vector<64xf32>
          %568 = llvm.insertelement %567, %305[%61 : i32] : vector<8xf32>
          %569 = llvm.shufflevector %568, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %570 = llvm.intr.fmuladd(%569, %286, %532)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %571 = llvm.insertvalue %570, %566[6] : !llvm.array<8 x vector<8xf32>> 
          %572 = llvm.extractelement %303[%0 : i64] : vector<64xf32>
          %573 = llvm.insertelement %572, %305[%61 : i32] : vector<8xf32>
          %574 = llvm.shufflevector %573, %305 [0, 0, 0, 0, 0, 0, 0, 0] : vector<8xf32> 
          %575 = llvm.intr.fmuladd(%574, %286, %536)  : (vector<8xf32>, vector<8xf32>, vector<8xf32>) -> vector<8xf32>
          %576 = llvm.insertvalue %575, %571[7] : !llvm.array<8 x vector<8xf32>> 
          %577 = llvm.add %181, %79  : i64
          llvm.br ^bb5(%577, %576 : i64, !llvm.array<8 x vector<8xf32>>)
        ^bb7:  // pred: ^bb5
          %578 = llvm.extractvalue %182[0] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %578, %129 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %579 = llvm.extractvalue %182[1] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %579, %136 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %580 = llvm.extractvalue %182[2] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %580, %143 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %581 = llvm.extractvalue %182[3] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %581, %150 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %582 = llvm.extractvalue %182[4] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %582, %157 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %583 = llvm.extractvalue %182[5] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %583, %164 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %584 = llvm.extractvalue %182[6] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %584, %171 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %585 = llvm.extractvalue %182[7] : !llvm.array<8 x vector<8xf32>> 
          llvm.store %585, %178 {alignment = 4 : i64} : !llvm.ptr<vector<8xf32>>
          %586 = llvm.add %123, %79  : i64
          llvm.br ^bb3(%586 : i64)
        ^bb8:  // pred: ^bb3
          %587 = llvm.add %114, %79  : i64
          llvm.br ^bb1(%587 : i64)
        ^bb9:  // pred: ^bb1
          llvm.return %61 : i32
        }
      }
    }
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @matmul_static_dispatch_0 {
  hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeExecutablesPass (iree-hal-serialize-executables) //----- //
hal.executable private @matmul_static_dispatch_0 {
  hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  %c256 = arith.constant 256 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1 = arith.constant 1 : index
  %c1024 = arith.constant 1024 : index
  %c512 = arith.constant 512 : index
  %c2097152 = arith.constant 2097152 : index
  %c1048576 = arith.constant 1048576 : index
  %c524288 = arith.constant 524288 : index
  %c0 = arith.constant 0 : index
  %c-1_i64 = arith.constant -1 : i64
  %c2 = arith.constant 2 : index
  %c32 = arith.constant 32 : index
  %c16 = arith.constant 16 : index
  %c-1_i32 = arith.constant -1 : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068120000000000000000000040003800070040000D000B00060000000400000040000000000000004000000000000000400000000000000088010000000000008801000000000000080000000000000001000000040000000000000000000000000000000000000000000000000000009203000000000000920300000000000000100000000000000100000005000000A003000000000000A013000000000000A013000000000000810C000000000000810C000000000000001000000000000001000000060000003010000000000000303000000000000030300000000000005001000000000000500100000000000000100000000000000200000006000000C010000000000000C030000000000000C030000000000000C000000000000000C000000000000000080000000000000052E57464040000003010000000000000303000000000000030300000000000005001000000000000D00F000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120006001020000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F717565727900000000000038300000000000000800000000000000400300000000000048300000000000000800000000000000A013000000000000503000000000000008000000000000006403000000000000583000000000000008000000000000009103000000000000683000000000000008000000000000009103000000000000703000000000000008000000000000003030000000000000903000000000000008000000000000004830000000000000983000000000000008000000000000006003000000000000A03000000000000008000000000000005030000000000000A83000000000000008000000000000005830000000000000B030000000000000080000000000000060300000000000006D61746D756C5F7374617469635F64697370617463685F300000000000000000000000006D61746D756C5F7374617469635F64697370617463685F305F6D61746D756C5F35313278313032347832353600000000000000000000000000000000554889E54157415641554154534881ECF8000000488B4620488B08488B7008488B40108B3A8B52044989F849C1E00548C1E20F4901D04C8985D8FEFFFF48C1E7074801FE4881C6007000004889B5E8FEFFFF488D340A4881C6001C000031C99048898DE0FEFFFF4889CA48C1E20A4889D14881C90004000048898DA0FEFFFF4889D14881C90008000048898DA8FEFFFF4889D14881C9000C000048898DB0FEFFFF4889D14881C90010000048898DB8FEFFFF4889D14881C90014000048898DC0FEFFFF4889D14881C90018000048898DC8FEFFFF4889D148899598FEFFFF4881CA001C0000488995D0FEFFFF4C8B85E8FEFFFF31D266662E0F1F840000000000488B8DD8FEFFFF488D3C0A488B8D98FEFFFF4801F90F280488440F287488104C8B8DA0FEFFFF4E8D0C0F420F280C880F294DB0460F284488104C8B95A8FEFFFF4E8D1417420F281490460F284C90104C8B9DB0FEFFFF4E8D1C1F420F280C980F294DC0460F28549810488B9DB8FEFFFF488D1C1F0F281C98440F285C98104C8BB5C0FEFFFF4901FE420F280CB00F294D90460F2864B0104C8BBDC8FEFFFF4901FF420F282CB8460F286CB8104803BDD0FEFFFF0F280CB8440F287CB81049C7C4F8FFFFFF4D89C5660F1F8400000000000F298D70FFFFFF0F295D80420F288CA620E4FFFF0F298DF0FEFFFF0FC6C900410F28A50090FFFF0F28F10F59F40F58F00F28C5410F28AD1090FFFF0F59CD410F58CE420F28BCA620E8FFFF0F29BD60FFFFFF0FC6FF000F28DF0F59DC0F585DB00F299D20FFFFFF0F59FD410F58F8460F2884A620ECFFFF440F298530FFFFFF450FC6C000410F28D80F59DC0F58DA0F295DA0440F59C5450F58C1460F288CA620F0FFFF440F298D40FFFFFF450FC6C900410F28D10F59D40F5855C0440F59CD450F58CA460F2894A620F4FFFF440F299550FFFFFF450FC6D200410F28DA0F59DC0F585D800F299D00FFFFFF440F59D5450F58D3420F289CA620F8FFFF0F295D800FC6DB00440F28DB440F59DC440F585D900F59DD410F58DC460F28A4A620FCFFFF440F2965B0450F28F7450F28FC450FC6FC00450F28E7440F59E4440F58E0440F59FD450F58FD460F286CA620440F296DC0450FC6ED00410F59E50F58A570FFFFFF0F296590440F59ED450F58EE440F28B5F0FEFFFF450FC6F655410F28A510A0FFFF410F28EE0F59EC0F58E9410F288D00A0FFFF440F59F1440F58F60F288560FFFFFF0FC6C0550F28F00F59F40F58F70F29B570FFFFFF0F59C10F588520FFFFFF0F28F00F288530FFFFFF0FC6C0550F28F80F59FC410F58F80F29BD20FFFFFF0F59C10F5845A00F28F80F288540FFFFFF0FC6C055440F28C0440F59C4450F58C1440F2945A00F59C10F58C2440F28C00F289550FFFFFF0FC6D2550F28C20F59C4410F58C20F298510FFFFFF0F59D10F589500FFFFFF440F285580450FC6D255450F28CA440F59CC440F58CB440F59D1450F58D3440F285DB0450FC6DB55410F28DB0F59DC410F58DF440F59D9450F58DC440F2865C0450FC6E455410F59E4410F58E5440F59E1440F5865900F2885F0FEFFFF440F28F8440FC6F8AA410F288D00B0FFFF450F28EF440F59E9450F58EE440F296D90450F28AD10B0FFFF450F59FD440F58FD0F28AD60FFFFFF0FC6EDAA440F28F5440F59F1440F58F6440F29B500FFFFFF410F59ED0F58AD70FFFFFF0F28B530FFFFFF0FC6F6AA440F28F6440F59F1440F58F7440F29B570FFFFFF410F59F50F58B520FFFFFF0F28BD40FFFFFF0FC6FFAA440F28F7440F59F1450F58F0440F29B520FFFFFF410F59FD0F587DA0440F288550FFFFFF450FC6C0AA450F28F0440F59F1440F58F2440F2975A0450F59C5440F588510FFFFFF0F2855800FC6D2AA440F28F2440F59F1450F58F2440F29B510FFFFFF410F59D5410F58D1440F284DB0450FC6C9AA450F28F1440F59F1450F58F3450F59CD440F58CB440F2855C0450FC6D2AA410F59CA410F58CC450F59D5440F58D40FC6C0FF450F28AD10C0FFFF440F28E0450F59E5450F58E7450F289D00C0FFFF410F59C30F5845900F28A560FFFFFF0FC6E4FF0F28DC410F59DD0F58DD410F59E30F58A500FFFFFF440F28FC0F28AD30FFFFFF0FC6EDFF0F28E5410F59E50F58E6410F59EB0F58AD70FFFFFF0F29AD30FFFFFF0F28B540FFFFFF0FC6F6FF0F28EE410F59ED0F58EF410F59F30F58B520FFFFFF0F29B540FFFFFF0F28BD50FFFFFF0FC6FFFF0F28F7410F59F5410F58F0410F59FB0F587DA00F29BD50FFFFFF440F284580450FC6C0FF410F28F8410F59FD0F58FA450F59C3440F588510FFFFFF440F294580440F2845B0450FC6C0FF410F28D0410F59D5410F58D1450F59C3450F58C6440F2945B0440F2845C0450FC6C0FF450F59E8450F58EA450F59C3440F58C1440F2945C0420F288CA630E4FFFF0F298D60FFFFFF0FC6C900450F28B500D0FFFF440F28C1450F59C6440F58C0410F288510D0FFFF0F59C8410F58CC460F288CA630E8FFFF440F298DF0FEFFFF450FC6C900450F28D1450F59D6450F58D7440F2955A0440F59C8440F58CB420F289CA630ECFFFF0F295D900FC6DB00440F28D3450F59D6440F589530FFFFFF0F59D80F58DC420F28A4A630F0FFFF0F29A530FFFFFF0FC6E400440F28E4450F59E6440F58A540FFFFFF0F59E00F58E5420F28ACA630F4FFFF0F29AD40FFFFFF0FC6ED00440F28FD450F59FE440F58BD50FFFFFF0F59E80F58EE420F28B4A630F8FFFF0F29B520FFFFFF0FC6F600440F28DE450F59DE440F585D80440F299D00FFFFFF0F59F00F58F7460F289CA630FCFFFF440F299D50FFFFFF450FC6DB00410F28FB410F59FE0F587DB00F29BD70FFFFFF440F59D8440F58DA420F2854A6300F2955800FC6D200440F59F2440F5875C0440F2975C00F59D0410F58D5440F28AD60FFFFFF450FC6ED55410F28BD10E0FFFF450F28F5440F59F7440F58F1440F2975B0410F288500E0FFFF440F59E8450F58E8440F2885F0FEFFFF450FC6C055410F28C80F59CF410F58C90F298D10FFFFFF440F59C0440F5845A0440F284D90450FC6C955410F28C90F59CF0F58CB0F294DA0440F59C8450F58CA440F289530FFFFFF450FC6D255410F28DA0F59DF0F58DC440F59D0450F58D4440F28A540FFFFFF450FC6E455410F28E40F59E70F58E5440F59E0450F58E7440F28BD20FFFFFF450FC6FF55410F28EF0F59EF0F58EE440F59F8440F58BD00FFFFFF0F28B550FFFFFF0FC6F6550F28CE0F59CF410F58CB0F298D00FFFFFF0F59F00F58B570FFFFFF440F287580450FC6F655410F59FE0F58FA440F59F0440F5875C0440F289D60FFFFFF450FC6DBAA410F288500F0FFFF410F28CB0F59C8410F58CD0F294DC0410F288D10F0FFFF440F59D9440F585DB00F2895F0FEFFFF0FC6D2AA440F28EA440F59E8450F58E8440F296DB00F59D10F589510FFFFFF440F286D90450FC6EDAA450F28C5440F59C0450F58C1440F298570FFFFFF440F59E9440F586DA0440F29AD80FEFFFF440F28AD30FFFFFF450FC6EDAA450F28C5440F59C0450F58C2440F298510FFFFFF440F59E9440F58EB0F289D40FFFFFF0FC6DBAA440F28C3440F59C0450F58C4440F298560FEFFFF0F59D90F58DC440F28A520FFFFFF410F28E4410FC6E4AA440F28C4440F59C0450F58C7450F28F80F59E10F58E50F28AD50FFFFFF0FC6EDAA440F28C5440F59C0440F58C6440F298570FEFFFF0F59E90F58AD00FFFFFF0F2875800FC6F6AA0F59C6410F58C60F2945A00F59F10F58F7440F288560FFFFFF450FC6C0FF410F284510450F28F0440F59F0450F58F3410F287D00440F59C7440F5845C0440F298560FFFFFF440F288DF0FEFFFF450FC6C9FF450F28C1440F59C0440F58C2440F59CF440F584DB0440F294DB00F2855900FC6D2FF440F28CA440F59C8440F588D80FEFFFF0F59D70F589570FFFFFF0F288D30FFFFFF0FC6C9FF440F28D1440F59D0450F58D50F59CF0F588D10FFFFFF0F294DC00F288D40FFFFFF0FC6C9FF440F28D9440F59D8440F58DB0F59CF0F28D90F589D60FEFFFF410F28CC410FC6CCFF440F28E1440F59E0440F58E40F59CF410F58CF0F294D900F288D50FFFFFF0FC6C9FF440F28E9440F59E8440F58ED0F59CF0F28E90F58AD70FEFFFF0F284D800FC6C9FF0F59C1440F28F80F288560FFFFFF440F58FE0F59CF0F584DA04983C4084981C5008000004981FCF80000000F820BF6FFFF0F290488440F297488100F2845B0420F290488460F29448810420F291490460F294C90100F2845C0420F290498460F295498100F291C98440F295C98100F284590420F2904B0460F2964B010420F292CB8460F296CB8100F290CB8440F297CB810488D4A084983C0204883FA184889CA0F82C5F4FFFF488B95E0FEFFFF488D4A084881C6002000004883FA180F8209F4FFFF31C04881C4F80000005B415C415D415E415F5DC3CCCCCCCCCC31C083FF03488D0D54100000480F44C1C30000000000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000080100000000000009000000000000001800000000000000F9FFFF6F000000000B000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F8010000000000000000000000000000000000000000000049524545000000000000000000000000000000000000000000000000000000002300000000020800C0300000000000000000000000000000010000001200060010200000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E74657874002E646174612E72656C2E726F002E64796E616D6963002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F000000030000000200000000000000100200000000000010020000000000002300000000000000000000000000000001000000000000000000000000000000170000000400000002000000000000003802000000000000380200000000000008010000000000000100000000000000080000000000000018000000000000002100000001000000020000000000000040030000000000004003000000000000520000000000000000000000000000000800000000000000000000000000000029000000010000000600000000000000A013000000000000A003000000000000810C0000000000000000000000000000100000000000000000000000000000002F0000000100000003000000000000003030000000000000301000000000000090000000000000000000000000000000100000000000000000000000000000003C000000060000000300000000000000C030000000000000C010000000000000C000000000000000030000000000000008000000000000001000000000000000450000000100000030000000000000000000000000000000801100000000000005000000000000000000000000000000010000000000000001000000000000004E0000000200000000000000000000000000000000000000881100000000000048000000000000000C0000000200000008000000000000001800000000000000560000000300000000000000000000000000000000000000D011000000000000680000000000000000000000000000000100000000000000000000000000000060000000030000000000000000000000000000000000000038120000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c-1_i32 = arith.constant -1 : i32
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c2 = arith.constant 2 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c524288 = arith.constant 524288 : index
    %c1048576 = arith.constant 1048576 : index
    %c2097152 = arith.constant 2097152 : index
    %c512 = arith.constant 512 : index
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c256 = arith.constant 256 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
  %c-1_i32 = arith.constant -1 : i32
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c2 = arith.constant 2 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c524288 = arith.constant 524288 : index
  %c1048576 = arith.constant 1048576 : index
  %c2097152 = arith.constant 2097152 : index
  %c512 = arith.constant 512 : index
  %c1024 = arith.constant 1024 : index
  %c1 = arith.constant 1 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c256 = arith.constant 256 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %0 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_matmul_static_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@matmul_static_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable_matmul_static_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @matmul_static_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<5544xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func @matmul_static(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c256 = arith.constant 256 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1 = arith.constant 1 : index
    %c1024 = arith.constant 1024 : index
    %c512 = arith.constant 512 : index
    %c2097152 = arith.constant 2097152 : index
    %c1048576 = arith.constant 1048576 : index
    %c524288 = arith.constant 524288 : index
    %c0 = arith.constant 0 : index
    %c-1_i64 = arith.constant -1 : i64
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    %c-1_i32 = arith.constant -1 : i32
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_matmul_static_dispatch_0 = util.global.load @_executable_matmul_static_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("tensor") shape([%c512, %c256]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c524288) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("tensor") shape([%c256, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c1048576) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    hal.buffer_view.assert<%arg2 : !hal.buffer_view> message("tensor") shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer_1 = hal.buffer_view.buffer<%arg2 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_1 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c2097152) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c524288], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %c1048576], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %c2097152]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_matmul_static_dispatch_0 : !hal.executable)[0] workgroups([%c32, %c16, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %0 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %c2097152] shape([%c512, %c1024]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.initializer {
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_0 = vm.rodata.inline "_utf8_embedded_elf_x86_64_9FD8733DA4A6F228" {alignment = 1 : i64} : !vm.buffer = "embedded-elf-x86_64"
      %0:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_0) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %c1 = vm.const.i32 1
      %2 = vm.and.i32 %1, %c1 : i32
      %zero = vm.const.i32.zero
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %c1_1 = vm.const.i32 1
      %zero_2 = vm.const.i32.zero
      %zero_3 = vm.const.i32.zero
      %c7 = vm.const.i32 7
      %c1_4 = vm.const.i32 1
      %c1_5 = vm.const.i32 1
      %c7_6 = vm.const.i32 7
      %c1_7 = vm.const.i32 1
      %c2 = vm.const.i32 2
      %c7_8 = vm.const.i32 7
      %zero_9 = vm.const.i32.zero
      %ref_10 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_3, %c7, %c1_4), (%c1_5, %c7_6, %c1_7), (%c2, %c7_8, %zero_9)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %zero_11 = vm.const.i32.zero
      %ref_12 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_11, [%ref_10]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_12, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %buffer_13 = vm.rodata.inline "_utf8_embedded_elf_x86_64_9FD8733DA4A6F228" {alignment = 1 : i64} : !vm.buffer = "embedded-elf-x86_64"
      %null = vm.const.ref.zero : !vm.buffer
      %ref_14 = vm.call.variadic @hal.executable.create(%ref, %buffer_13, %matmul_static_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_14 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null_15 = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null_15 : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2 = vm.const.i64 2
      %c32 = vm.const.i64 32
      %c16 = vm.const.i64 16
      %c-1_1 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %buffer = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_4 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_5 = vm.const.i32 16
      %c3075 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_4, %ref_3, %c524288, %c16_5, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %buffer_6 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      vm.call.variadic @hal.buffer_view.assert(%arg1, %buffer_6, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %buffer_8 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_9 = vm.const.i32 16
      %c3075_10 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref_7, %buffer_8, %ref_3, %c1048576, %c16_9, %c3075_10) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %buffer_11 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      vm.call.variadic @hal.buffer_view.assert(%arg2, %buffer_11, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_12 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %buffer_13 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_14 = vm.const.i32 16
      %c3075_15 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref_12, %buffer_13, %ref_3, %c2097152, %c16_14, %c3075_15) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %c17 = vm.const.i32 17
      %c3 = vm.const.i32 3
      %zero_16 = vm.const.i32.zero
      %ref_17 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero_16) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %zero_18 = vm.const.i32.zero
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_17, %_pipeline_layout_0, %zero, [(%zero, %zero_18, %ref, %zero, %c524288), (%c1_0, %zero_18, %ref_7, %zero, %c1048576), (%c2, %zero_18, %ref_12, %zero, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %zero_19 = vm.const.i32.zero
      %c32_20 = vm.const.i32 32
      %c16_21 = vm.const.i32 16
      %c1_22 = vm.const.i32 1
      vm.call @hal.command_buffer.dispatch(%ref_17, %_executable_matmul_static_dispatch_0, %zero_19, %c32_20, %c16_21, %c1_22) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_23 = vm.const.i32.zero
      vm.call @hal.command_buffer.execution_barrier(%ref_17, %c28, %c13, %zero_23) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_17) : (!vm.ref<!hal.command_buffer>) -> ()
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero_24 = vm.const.i32.zero
      %ref_25 = vm.call @hal.fence.create(%ref_2, %zero_24) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1, %null, %ref_25, [%ref_17]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_25]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %0, "failed to wait on timepoint"
      %ref_26 = vm.call.variadic @hal.buffer_view.create(%ref_12, %zero, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_26 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      %c2_27 = vm.const.i32 2
      vm.fail %c2_27, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %c1_0 = vm.const.i32 1
    %zero_1 = vm.const.i32.zero
    %zero_2 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_3 = vm.const.i32 1
    %c1_4 = vm.const.i32 1
    %c7_5 = vm.const.i32 7
    %c1_6 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_7 = vm.const.i32 7
    %zero_8 = vm.const.i32.zero
    %ref_9 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_1, [(%zero_2, %c7, %c1_3), (%c1_4, %c7_5, %c1_6), (%c2, %c7_7, %zero_8)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %zero_10 = vm.const.i32.zero
    %ref_11 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_10, [%ref_9]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_11, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_12 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0, %matmul_static_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_12 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_13 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_13 : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
  vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
  vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_1 {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_2 {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_3 {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_4 {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_5 {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2 = vm.const.i64 2
    %c32 = vm.const.i64 32
    %c16 = vm.const.i64 16
    %c-1_1 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC_1 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_1 : !vm.buffer
    %c16_4 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC_1, %ref_3, %c524288, %c16_4, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %_utf8_tensor_3C6209B4FD120BDC_2 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_2 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC_2, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_5 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_3 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_3 : !vm.buffer
    %c16_6 = vm.const.i32 16
    %c3075_7 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_5, %_utf8_tensor_3C6209B4FD120BDC_3, %ref_3, %c1048576, %c16_6, %c3075_7) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %_utf8_tensor_3C6209B4FD120BDC_4 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_4 : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC_4, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_8 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_5 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_5 : !vm.buffer
    %c16_9 = vm.const.i32 16
    %c3075_10 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_8, %_utf8_tensor_3C6209B4FD120BDC_5, %ref_3, %c2097152, %c16_9, %c3075_10) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_11 = vm.const.i32.zero
    %ref_12 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero_11) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %zero_13 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_12, %_pipeline_layout_0, %zero, [(%zero, %zero_13, %ref, %zero, %c524288), (%c1_0, %zero_13, %ref_5, %zero, %c1048576), (%c2, %zero_13, %ref_8, %zero, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_14 = vm.const.i32.zero
    %c32_15 = vm.const.i32 32
    %c16_16 = vm.const.i32 16
    %c1_17 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_12, %_executable_matmul_static_dispatch_0, %zero_14, %c32_15, %c16_16, %c1_17) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_18 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_12, %c28, %c13, %zero_18) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_12) : (!vm.ref<!hal.command_buffer>) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_19 = vm.const.i32.zero
    %ref_20 = vm.call @hal.fence.create(%ref_2, %zero_19) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1, %null, %ref_20, [%ref_12]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_20]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_21 = vm.call.variadic @hal.buffer_view.create(%ref_8, %zero, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_21 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    %c2_22 = vm.const.i32 2
    vm.fail %c2_22, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %c1_0 = vm.const.i32 1
    %zero_1 = vm.const.i32.zero
    %zero_2 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_3 = vm.const.i32 1
    %c1_4 = vm.const.i32 1
    %c7_5 = vm.const.i32 7
    %c1_6 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_7 = vm.const.i32 7
    %zero_8 = vm.const.i32.zero
    %ref_9 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_1, [(%zero_2, %c7, %c1_3), (%c1_4, %c7_5, %c1_6), (%c2, %c7_7, %zero_8)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %zero_10 = vm.const.i32.zero
    %ref_11 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_10, [%ref_9]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_11, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_12 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_13 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_12, %matmul_static_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_13 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_14 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_14 : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
  vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
  vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2 = vm.const.i64 2
    %c32 = vm.const.i64 32
    %c16 = vm.const.i64 16
    %c-1_1 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC_4 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_5 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC_4, %ref_3, %c524288, %c16_5, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC_6, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_8 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_9 = vm.const.i32 16
    %c3075_10 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC_8, %ref_3, %c1048576, %c16_9, %c3075_10) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %_utf8_tensor_3C6209B4FD120BDC_11 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC_11, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_12 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_13 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_14 = vm.const.i32 16
    %c3075_15 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_12, %_utf8_tensor_3C6209B4FD120BDC_13, %ref_3, %c2097152, %c16_14, %c3075_15) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_16 = vm.const.i32.zero
    %ref_17 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero_16) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %zero_18 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_17, %_pipeline_layout_0, %zero, [(%zero, %zero_18, %ref, %zero, %c524288), (%c1_0, %zero_18, %ref_7, %zero, %c1048576), (%c2, %zero_18, %ref_12, %zero, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_19 = vm.const.i32.zero
    %c32_20 = vm.const.i32 32
    %c16_21 = vm.const.i32 16
    %c1_22 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_17, %_executable_matmul_static_dispatch_0, %zero_19, %c32_20, %c16_21, %c1_22) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_23 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_17, %c28, %c13, %zero_23) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_17) : (!vm.ref<!hal.command_buffer>) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_24 = vm.const.i32.zero
    %ref_25 = vm.call @hal.fence.create(%ref_2, %zero_24) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1, %null, %ref_25, [%ref_17]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_25]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %0, "failed to wait on timepoint"
    %ref_26 = vm.call.variadic @hal.buffer_view.create(%ref_12, %zero, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_26 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    %c2_27 = vm.const.i32 2
    vm.fail %c2_27, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_3 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_3, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC_6 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC_6, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %_utf8_tensor_3C6209B4FD120BDC_7 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC_7, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_8 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_9 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_8, %_utf8_tensor_3C6209B4FD120BDC_9, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %_utf8_tensor_3C6209B4FD120BDC_10 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC_10, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_11 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_12 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_11, %_utf8_tensor_3C6209B4FD120BDC_12, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_13 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_13, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_8, %zero_1, %c1048576), (%c2_2, %zero, %ref_11, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_13, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_13, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_13) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_14 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_14, [%ref_13]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_14]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3(%0 : i32), ^bb2
    ^bb2:  // pred: ^bb1
      %ref_15 = vm.call.variadic @hal.buffer_view.create(%ref_11, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_15 : !vm.ref<!hal.buffer_view>
    ^bb3(%1: i32):  // pred: ^bb1
      vm.fail %1, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3(%0 : i32), ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3(%1: i32):  // pred: ^bb1
      vm.fail %1, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
  vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
  vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
  vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.cond_br %3, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
  %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c2 = vm.const.i32 2
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c32 = vm.const.i32 32
  %zero = vm.const.i32.zero
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c256 = vm.const.i64 256
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %c1_0 = vm.const.i64 1
  %c1024 = vm.const.i64 1024
  %c512 = vm.const.i64 512
  %c2097152 = vm.const.i64 2097152
  %c1048576 = vm.const.i64 1048576
  %c524288 = vm.const.i64 524288
  %zero_1 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %c2_2 = vm.const.i64 2
  %c-1_3 = vm.const.i32 -1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.cond_br %_device_query_0, ^bb1, ^bb4
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %0, ^bb3, ^bb2
^bb2:  // pred: ^bb1
  %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_10 : !vm.ref<!hal.buffer_view>
^bb3:  // pred: ^bb1
  vm.fail %0, "failed to wait on timepoint"
^bb4:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.ex.submit_and_wait(%device : !vm.ref<!hal.device>, %command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.allocate.initialized(%allocator : !vm.ref<!hal.allocator>, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.allocator.map.byte_buffer(%allocator : !vm.ref<!hal.allocator>, %try : i32, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...) attributes {sym_visibility = "private"}
    vm.import @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32 attributes {sym_visibility = "private"}
    vm.import @hal.fence.signal(%fence : !vm.ref<!hal.fence>) attributes {sym_visibility = "private"}
    vm.import @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32) attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068120000000000000000000040003800070040000D000B00060000000400000040000000000000004000000000000000400000000000000088010000000000008801000000000000080000000000000001000000040000000000000000000000000000000000000000000000000000009203000000000000920300000000000000100000000000000100000005000000A003000000000000A013000000000000A013000000000000810C000000000000810C000000000000001000000000000001000000060000003010000000000000303000000000000030300000000000005001000000000000500100000000000000100000000000000200000006000000C010000000000000C030000000000000C030000000000000C000000000000000C000000000000000080000000000000052E57464040000003010000000000000303000000000000030300000000000005001000000000000D00F000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120006001020000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F717565727900000000000038300000000000000800000000000000400300000000000048300000000000000800000000000000A013000000000000503000000000000008000000000000006403000000000000583000000000000008000000000000009103000000000000683000000000000008000000000000009103000000000000703000000000000008000000000000003030000000000000903000000000000008000000000000004830000000000000983000000000000008000000000000006003000000000000A03000000000000008000000000000005030000000000000A83000000000000008000000000000005830000000000000B030000000000000080000000000000060300000000000006D61746D756C5F7374617469635F64697370617463685F300000000000000000000000006D61746D756C5F7374617469635F64697370617463685F305F6D61746D756C5F35313278313032347832353600000000000000000000000000000000554889E54157415641554154534881ECF8000000488B4620488B08488B7008488B40108B3A8B52044989F849C1E00548C1E20F4901D04C8985D8FEFFFF48C1E7074801FE4881C6007000004889B5E8FEFFFF488D340A4881C6001C000031C99048898DE0FEFFFF4889CA48C1E20A4889D14881C90004000048898DA0FEFFFF4889D14881C90008000048898DA8FEFFFF4889D14881C9000C000048898DB0FEFFFF4889D14881C90010000048898DB8FEFFFF4889D14881C90014000048898DC0FEFFFF4889D14881C90018000048898DC8FEFFFF4889D148899598FEFFFF4881CA001C0000488995D0FEFFFF4C8B85E8FEFFFF31D266662E0F1F840000000000488B8DD8FEFFFF488D3C0A488B8D98FEFFFF4801F90F280488440F287488104C8B8DA0FEFFFF4E8D0C0F420F280C880F294DB0460F284488104C8B95A8FEFFFF4E8D1417420F281490460F284C90104C8B9DB0FEFFFF4E8D1C1F420F280C980F294DC0460F28549810488B9DB8FEFFFF488D1C1F0F281C98440F285C98104C8BB5C0FEFFFF4901FE420F280CB00F294D90460F2864B0104C8BBDC8FEFFFF4901FF420F282CB8460F286CB8104803BDD0FEFFFF0F280CB8440F287CB81049C7C4F8FFFFFF4D89C5660F1F8400000000000F298D70FFFFFF0F295D80420F288CA620E4FFFF0F298DF0FEFFFF0FC6C900410F28A50090FFFF0F28F10F59F40F58F00F28C5410F28AD1090FFFF0F59CD410F58CE420F28BCA620E8FFFF0F29BD60FFFFFF0FC6FF000F28DF0F59DC0F585DB00F299D20FFFFFF0F59FD410F58F8460F2884A620ECFFFF440F298530FFFFFF450FC6C000410F28D80F59DC0F58DA0F295DA0440F59C5450F58C1460F288CA620F0FFFF440F298D40FFFFFF450FC6C900410F28D10F59D40F5855C0440F59CD450F58CA460F2894A620F4FFFF440F299550FFFFFF450FC6D200410F28DA0F59DC0F585D800F299D00FFFFFF440F59D5450F58D3420F289CA620F8FFFF0F295D800FC6DB00440F28DB440F59DC440F585D900F59DD410F58DC460F28A4A620FCFFFF440F2965B0450F28F7450F28FC450FC6FC00450F28E7440F59E4440F58E0440F59FD450F58FD460F286CA620440F296DC0450FC6ED00410F59E50F58A570FFFFFF0F296590440F59ED450F58EE440F28B5F0FEFFFF450FC6F655410F28A510A0FFFF410F28EE0F59EC0F58E9410F288D00A0FFFF440F59F1440F58F60F288560FFFFFF0FC6C0550F28F00F59F40F58F70F29B570FFFFFF0F59C10F588520FFFFFF0F28F00F288530FFFFFF0FC6C0550F28F80F59FC410F58F80F29BD20FFFFFF0F59C10F5845A00F28F80F288540FFFFFF0FC6C055440F28C0440F59C4450F58C1440F2945A00F59C10F58C2440F28C00F289550FFFFFF0FC6D2550F28C20F59C4410F58C20F298510FFFFFF0F59D10F589500FFFFFF440F285580450FC6D255450F28CA440F59CC440F58CB440F59D1450F58D3440F285DB0450FC6DB55410F28DB0F59DC410F58DF440F59D9450F58DC440F2865C0450FC6E455410F59E4410F58E5440F59E1440F5865900F2885F0FEFFFF440F28F8440FC6F8AA410F288D00B0FFFF450F28EF440F59E9450F58EE440F296D90450F28AD10B0FFFF450F59FD440F58FD0F28AD60FFFFFF0FC6EDAA440F28F5440F59F1440F58F6440F29B500FFFFFF410F59ED0F58AD70FFFFFF0F28B530FFFFFF0FC6F6AA440F28F6440F59F1440F58F7440F29B570FFFFFF410F59F50F58B520FFFFFF0F28BD40FFFFFF0FC6FFAA440F28F7440F59F1450F58F0440F29B520FFFFFF410F59FD0F587DA0440F288550FFFFFF450FC6C0AA450F28F0440F59F1440F58F2440F2975A0450F59C5440F588510FFFFFF0F2855800FC6D2AA440F28F2440F59F1450F58F2440F29B510FFFFFF410F59D5410F58D1440F284DB0450FC6C9AA450F28F1440F59F1450F58F3450F59CD440F58CB440F2855C0450FC6D2AA410F59CA410F58CC450F59D5440F58D40FC6C0FF450F28AD10C0FFFF440F28E0450F59E5450F58E7450F289D00C0FFFF410F59C30F5845900F28A560FFFFFF0FC6E4FF0F28DC410F59DD0F58DD410F59E30F58A500FFFFFF440F28FC0F28AD30FFFFFF0FC6EDFF0F28E5410F59E50F58E6410F59EB0F58AD70FFFFFF0F29AD30FFFFFF0F28B540FFFFFF0FC6F6FF0F28EE410F59ED0F58EF410F59F30F58B520FFFFFF0F29B540FFFFFF0F28BD50FFFFFF0FC6FFFF0F28F7410F59F5410F58F0410F59FB0F587DA00F29BD50FFFFFF440F284580450FC6C0FF410F28F8410F59FD0F58FA450F59C3440F588510FFFFFF440F294580440F2845B0450FC6C0FF410F28D0410F59D5410F58D1450F59C3450F58C6440F2945B0440F2845C0450FC6C0FF450F59E8450F58EA450F59C3440F58C1440F2945C0420F288CA630E4FFFF0F298D60FFFFFF0FC6C900450F28B500D0FFFF440F28C1450F59C6440F58C0410F288510D0FFFF0F59C8410F58CC460F288CA630E8FFFF440F298DF0FEFFFF450FC6C900450F28D1450F59D6450F58D7440F2955A0440F59C8440F58CB420F289CA630ECFFFF0F295D900FC6DB00440F28D3450F59D6440F589530FFFFFF0F59D80F58DC420F28A4A630F0FFFF0F29A530FFFFFF0FC6E400440F28E4450F59E6440F58A540FFFFFF0F59E00F58E5420F28ACA630F4FFFF0F29AD40FFFFFF0FC6ED00440F28FD450F59FE440F58BD50FFFFFF0F59E80F58EE420F28B4A630F8FFFF0F29B520FFFFFF0FC6F600440F28DE450F59DE440F585D80440F299D00FFFFFF0F59F00F58F7460F289CA630FCFFFF440F299D50FFFFFF450FC6DB00410F28FB410F59FE0F587DB00F29BD70FFFFFF440F59D8440F58DA420F2854A6300F2955800FC6D200440F59F2440F5875C0440F2975C00F59D0410F58D5440F28AD60FFFFFF450FC6ED55410F28BD10E0FFFF450F28F5440F59F7440F58F1440F2975B0410F288500E0FFFF440F59E8450F58E8440F2885F0FEFFFF450FC6C055410F28C80F59CF410F58C90F298D10FFFFFF440F59C0440F5845A0440F284D90450FC6C955410F28C90F59CF0F58CB0F294DA0440F59C8450F58CA440F289530FFFFFF450FC6D255410F28DA0F59DF0F58DC440F59D0450F58D4440F28A540FFFFFF450FC6E455410F28E40F59E70F58E5440F59E0450F58E7440F28BD20FFFFFF450FC6FF55410F28EF0F59EF0F58EE440F59F8440F58BD00FFFFFF0F28B550FFFFFF0FC6F6550F28CE0F59CF410F58CB0F298D00FFFFFF0F59F00F58B570FFFFFF440F287580450FC6F655410F59FE0F58FA440F59F0440F5875C0440F289D60FFFFFF450FC6DBAA410F288500F0FFFF410F28CB0F59C8410F58CD0F294DC0410F288D10F0FFFF440F59D9440F585DB00F2895F0FEFFFF0FC6D2AA440F28EA440F59E8450F58E8440F296DB00F59D10F589510FFFFFF440F286D90450FC6EDAA450F28C5440F59C0450F58C1440F298570FFFFFF440F59E9440F586DA0440F29AD80FEFFFF440F28AD30FFFFFF450FC6EDAA450F28C5440F59C0450F58C2440F298510FFFFFF440F59E9440F58EB0F289D40FFFFFF0FC6DBAA440F28C3440F59C0450F58C4440F298560FEFFFF0F59D90F58DC440F28A520FFFFFF410F28E4410FC6E4AA440F28C4440F59C0450F58C7450F28F80F59E10F58E50F28AD50FFFFFF0FC6EDAA440F28C5440F59C0440F58C6440F298570FEFFFF0F59E90F58AD00FFFFFF0F2875800FC6F6AA0F59C6410F58C60F2945A00F59F10F58F7440F288560FFFFFF450FC6C0FF410F284510450F28F0440F59F0450F58F3410F287D00440F59C7440F5845C0440F298560FFFFFF440F288DF0FEFFFF450FC6C9FF450F28C1440F59C0440F58C2440F59CF440F584DB0440F294DB00F2855900FC6D2FF440F28CA440F59C8440F588D80FEFFFF0F59D70F589570FFFFFF0F288D30FFFFFF0FC6C9FF440F28D1440F59D0450F58D50F59CF0F588D10FFFFFF0F294DC00F288D40FFFFFF0FC6C9FF440F28D9440F59D8440F58DB0F59CF0F28D90F589D60FEFFFF410F28CC410FC6CCFF440F28E1440F59E0440F58E40F59CF410F58CF0F294D900F288D50FFFFFF0FC6C9FF440F28E9440F59E8440F58ED0F59CF0F28E90F58AD70FEFFFF0F284D800FC6C9FF0F59C1440F28F80F288560FFFFFF440F58FE0F59CF0F584DA04983C4084981C5008000004981FCF80000000F820BF6FFFF0F290488440F297488100F2845B0420F290488460F29448810420F291490460F294C90100F2845C0420F290498460F295498100F291C98440F295C98100F284590420F2904B0460F2964B010420F292CB8460F296CB8100F290CB8440F297CB810488D4A084983C0204883FA184889CA0F82C5F4FFFF488B95E0FEFFFF488D4A084881C6002000004883FA180F8209F4FFFF31C04881C4F80000005B415C415D415E415F5DC3CCCCCCCCCC31C083FF03488D0D54100000480F44C1C30000000000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000080100000000000009000000000000001800000000000000F9FFFF6F000000000B000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F8010000000000000000000000000000000000000000000049524545000000000000000000000000000000000000000000000000000000002300000000020800C0300000000000000000000000000000010000001200060010200000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E74657874002E646174612E72656C2E726F002E64796E616D6963002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F000000030000000200000000000000100200000000000010020000000000002300000000000000000000000000000001000000000000000000000000000000170000000400000002000000000000003802000000000000380200000000000008010000000000000100000000000000080000000000000018000000000000002100000001000000020000000000000040030000000000004003000000000000520000000000000000000000000000000800000000000000000000000000000029000000010000000600000000000000A013000000000000A003000000000000810C0000000000000000000000000000100000000000000000000000000000002F0000000100000003000000000000003030000000000000301000000000000090000000000000000000000000000000100000000000000000000000000000003C000000060000000300000000000000C030000000000000C010000000000000C000000000000000030000000000000008000000000000001000000000000000450000000100000030000000000000000000000000000000801100000000000005000000000000000000000000000000010000000000000001000000000000004E0000000200000000000000000000000000000000000000881100000000000048000000000000000C0000000200000008000000000000001800000000000000560000000300000000000000000000000000000000000000D011000000000000680000000000000000000000000000000100000000000000000000000000000060000000030000000000000000000000000000000000000038120000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068120000000000000000000040003800070040000D000B00060000000400000040000000000000004000000000000000400000000000000088010000000000008801000000000000080000000000000001000000040000000000000000000000000000000000000000000000000000009203000000000000920300000000000000100000000000000100000005000000A003000000000000A013000000000000A013000000000000810C000000000000810C000000000000001000000000000001000000060000003010000000000000303000000000000030300000000000005001000000000000500100000000000000100000000000000200000006000000C010000000000000C030000000000000C030000000000000C000000000000000C000000000000000080000000000000052E57464040000003010000000000000303000000000000030300000000000005001000000000000D00F000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120006001020000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F717565727900000000000038300000000000000800000000000000400300000000000048300000000000000800000000000000A013000000000000503000000000000008000000000000006403000000000000583000000000000008000000000000009103000000000000683000000000000008000000000000009103000000000000703000000000000008000000000000003030000000000000903000000000000008000000000000004830000000000000983000000000000008000000000000006003000000000000A03000000000000008000000000000005030000000000000A83000000000000008000000000000005830000000000000B030000000000000080000000000000060300000000000006D61746D756C5F7374617469635F64697370617463685F300000000000000000000000006D61746D756C5F7374617469635F64697370617463685F305F6D61746D756C5F35313278313032347832353600000000000000000000000000000000554889E54157415641554154534881ECF8000000488B4620488B08488B7008488B40108B3A8B52044989F849C1E00548C1E20F4901D04C8985D8FEFFFF48C1E7074801FE4881C6007000004889B5E8FEFFFF488D340A4881C6001C000031C99048898DE0FEFFFF4889CA48C1E20A4889D14881C90004000048898DA0FEFFFF4889D14881C90008000048898DA8FEFFFF4889D14881C9000C000048898DB0FEFFFF4889D14881C90010000048898DB8FEFFFF4889D14881C90014000048898DC0FEFFFF4889D14881C90018000048898DC8FEFFFF4889D148899598FEFFFF4881CA001C0000488995D0FEFFFF4C8B85E8FEFFFF31D266662E0F1F840000000000488B8DD8FEFFFF488D3C0A488B8D98FEFFFF4801F90F280488440F287488104C8B8DA0FEFFFF4E8D0C0F420F280C880F294DB0460F284488104C8B95A8FEFFFF4E8D1417420F281490460F284C90104C8B9DB0FEFFFF4E8D1C1F420F280C980F294DC0460F28549810488B9DB8FEFFFF488D1C1F0F281C98440F285C98104C8BB5C0FEFFFF4901FE420F280CB00F294D90460F2864B0104C8BBDC8FEFFFF4901FF420F282CB8460F286CB8104803BDD0FEFFFF0F280CB8440F287CB81049C7C4F8FFFFFF4D89C5660F1F8400000000000F298D70FFFFFF0F295D80420F288CA620E4FFFF0F298DF0FEFFFF0FC6C900410F28A50090FFFF0F28F10F59F40F58F00F28C5410F28AD1090FFFF0F59CD410F58CE420F28BCA620E8FFFF0F29BD60FFFFFF0FC6FF000F28DF0F59DC0F585DB00F299D20FFFFFF0F59FD410F58F8460F2884A620ECFFFF440F298530FFFFFF450FC6C000410F28D80F59DC0F58DA0F295DA0440F59C5450F58C1460F288CA620F0FFFF440F298D40FFFFFF450FC6C900410F28D10F59D40F5855C0440F59CD450F58CA460F2894A620F4FFFF440F299550FFFFFF450FC6D200410F28DA0F59DC0F585D800F299D00FFFFFF440F59D5450F58D3420F289CA620F8FFFF0F295D800FC6DB00440F28DB440F59DC440F585D900F59DD410F58DC460F28A4A620FCFFFF440F2965B0450F28F7450F28FC450FC6FC00450F28E7440F59E4440F58E0440F59FD450F58FD460F286CA620440F296DC0450FC6ED00410F59E50F58A570FFFFFF0F296590440F59ED450F58EE440F28B5F0FEFFFF450FC6F655410F28A510A0FFFF410F28EE0F59EC0F58E9410F288D00A0FFFF440F59F1440F58F60F288560FFFFFF0FC6C0550F28F00F59F40F58F70F29B570FFFFFF0F59C10F588520FFFFFF0F28F00F288530FFFFFF0FC6C0550F28F80F59FC410F58F80F29BD20FFFFFF0F59C10F5845A00F28F80F288540FFFFFF0FC6C055440F28C0440F59C4450F58C1440F2945A00F59C10F58C2440F28C00F289550FFFFFF0FC6D2550F28C20F59C4410F58C20F298510FFFFFF0F59D10F589500FFFFFF440F285580450FC6D255450F28CA440F59CC440F58CB440F59D1450F58D3440F285DB0450FC6DB55410F28DB0F59DC410F58DF440F59D9450F58DC440F2865C0450FC6E455410F59E4410F58E5440F59E1440F5865900F2885F0FEFFFF440F28F8440FC6F8AA410F288D00B0FFFF450F28EF440F59E9450F58EE440F296D90450F28AD10B0FFFF450F59FD440F58FD0F28AD60FFFFFF0FC6EDAA440F28F5440F59F1440F58F6440F29B500FFFFFF410F59ED0F58AD70FFFFFF0F28B530FFFFFF0FC6F6AA440F28F6440F59F1440F58F7440F29B570FFFFFF410F59F50F58B520FFFFFF0F28BD40FFFFFF0FC6FFAA440F28F7440F59F1450F58F0440F29B520FFFFFF410F59FD0F587DA0440F288550FFFFFF450FC6C0AA450F28F0440F59F1440F58F2440F2975A0450F59C5440F588510FFFFFF0F2855800FC6D2AA440F28F2440F59F1450F58F2440F29B510FFFFFF410F59D5410F58D1440F284DB0450FC6C9AA450F28F1440F59F1450F58F3450F59CD440F58CB440F2855C0450FC6D2AA410F59CA410F58CC450F59D5440F58D40FC6C0FF450F28AD10C0FFFF440F28E0450F59E5450F58E7450F289D00C0FFFF410F59C30F5845900F28A560FFFFFF0FC6E4FF0F28DC410F59DD0F58DD410F59E30F58A500FFFFFF440F28FC0F28AD30FFFFFF0FC6EDFF0F28E5410F59E50F58E6410F59EB0F58AD70FFFFFF0F29AD30FFFFFF0F28B540FFFFFF0FC6F6FF0F28EE410F59ED0F58EF410F59F30F58B520FFFFFF0F29B540FFFFFF0F28BD50FFFFFF0FC6FFFF0F28F7410F59F5410F58F0410F59FB0F587DA00F29BD50FFFFFF440F284580450FC6C0FF410F28F8410F59FD0F58FA450F59C3440F588510FFFFFF440F294580440F2845B0450FC6C0FF410F28D0410F59D5410F58D1450F59C3450F58C6440F2945B0440F2845C0450FC6C0FF450F59E8450F58EA450F59C3440F58C1440F2945C0420F288CA630E4FFFF0F298D60FFFFFF0FC6C900450F28B500D0FFFF440F28C1450F59C6440F58C0410F288510D0FFFF0F59C8410F58CC460F288CA630E8FFFF440F298DF0FEFFFF450FC6C900450F28D1450F59D6450F58D7440F2955A0440F59C8440F58CB420F289CA630ECFFFF0F295D900FC6DB00440F28D3450F59D6440F589530FFFFFF0F59D80F58DC420F28A4A630F0FFFF0F29A530FFFFFF0FC6E400440F28E4450F59E6440F58A540FFFFFF0F59E00F58E5420F28ACA630F4FFFF0F29AD40FFFFFF0FC6ED00440F28FD450F59FE440F58BD50FFFFFF0F59E80F58EE420F28B4A630F8FFFF0F29B520FFFFFF0FC6F600440F28DE450F59DE440F585D80440F299D00FFFFFF0F59F00F58F7460F289CA630FCFFFF440F299D50FFFFFF450FC6DB00410F28FB410F59FE0F587DB00F29BD70FFFFFF440F59D8440F58DA420F2854A6300F2955800FC6D200440F59F2440F5875C0440F2975C00F59D0410F58D5440F28AD60FFFFFF450FC6ED55410F28BD10E0FFFF450F28F5440F59F7440F58F1440F2975B0410F288500E0FFFF440F59E8450F58E8440F2885F0FEFFFF450FC6C055410F28C80F59CF410F58C90F298D10FFFFFF440F59C0440F5845A0440F284D90450FC6C955410F28C90F59CF0F58CB0F294DA0440F59C8450F58CA440F289530FFFFFF450FC6D255410F28DA0F59DF0F58DC440F59D0450F58D4440F28A540FFFFFF450FC6E455410F28E40F59E70F58E5440F59E0450F58E7440F28BD20FFFFFF450FC6FF55410F28EF0F59EF0F58EE440F59F8440F58BD00FFFFFF0F28B550FFFFFF0FC6F6550F28CE0F59CF410F58CB0F298D00FFFFFF0F59F00F58B570FFFFFF440F287580450FC6F655410F59FE0F58FA440F59F0440F5875C0440F289D60FFFFFF450FC6DBAA410F288500F0FFFF410F28CB0F59C8410F58CD0F294DC0410F288D10F0FFFF440F59D9440F585DB00F2895F0FEFFFF0FC6D2AA440F28EA440F59E8450F58E8440F296DB00F59D10F589510FFFFFF440F286D90450FC6EDAA450F28C5440F59C0450F58C1440F298570FFFFFF440F59E9440F586DA0440F29AD80FEFFFF440F28AD30FFFFFF450FC6EDAA450F28C5440F59C0450F58C2440F298510FFFFFF440F59E9440F58EB0F289D40FFFFFF0FC6DBAA440F28C3440F59C0450F58C4440F298560FEFFFF0F59D90F58DC440F28A520FFFFFF410F28E4410FC6E4AA440F28C4440F59C0450F58C7450F28F80F59E10F58E50F28AD50FFFFFF0FC6EDAA440F28C5440F59C0440F58C6440F298570FEFFFF0F59E90F58AD00FFFFFF0F2875800FC6F6AA0F59C6410F58C60F2945A00F59F10F58F7440F288560FFFFFF450FC6C0FF410F284510450F28F0440F59F0450F58F3410F287D00440F59C7440F5845C0440F298560FFFFFF440F288DF0FEFFFF450FC6C9FF450F28C1440F59C0440F58C2440F59CF440F584DB0440F294DB00F2855900FC6D2FF440F28CA440F59C8440F588D80FEFFFF0F59D70F589570FFFFFF0F288D30FFFFFF0FC6C9FF440F28D1440F59D0450F58D50F59CF0F588D10FFFFFF0F294DC00F288D40FFFFFF0FC6C9FF440F28D9440F59D8440F58DB0F59CF0F28D90F589D60FEFFFF410F28CC410FC6CCFF440F28E1440F59E0440F58E40F59CF410F58CF0F294D900F288D50FFFFFF0FC6C9FF440F28E9440F59E8440F58ED0F59CF0F28E90F58AD70FEFFFF0F284D800FC6C9FF0F59C1440F28F80F288560FFFFFF440F58FE0F59CF0F584DA04983C4084981C5008000004981FCF80000000F820BF6FFFF0F290488440F297488100F2845B0420F290488460F29448810420F291490460F294C90100F2845C0420F290498460F295498100F291C98440F295C98100F284590420F2904B0460F2964B010420F292CB8460F296CB8100F290CB8440F297CB810488D4A084983C0204883FA184889CA0F82C5F4FFFF488B95E0FEFFFF488D4A084881C6002000004883FA180F8209F4FFFF31C04881C4F80000005B415C415D415E415F5DC3CCCCCCCCCC31C083FF03488D0D54100000480F44C1C30000000000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000080100000000000009000000000000001800000000000000F9FFFF6F000000000B000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F8010000000000000000000000000000000000000000000049524545000000000000000000000000000000000000000000000000000000002300000000020800C0300000000000000000000000000000010000001200060010200000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E74657874002E646174612E72656C2E726F002E64796E616D6963002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F000000030000000200000000000000100200000000000010020000000000002300000000000000000000000000000001000000000000000000000000000000170000000400000002000000000000003802000000000000380200000000000008010000000000000100000000000000080000000000000018000000000000002100000001000000020000000000000040030000000000004003000000000000520000000000000000000000000000000800000000000000000000000000000029000000010000000600000000000000A013000000000000A003000000000000810C0000000000000000000000000000100000000000000000000000000000002F0000000100000003000000000000003030000000000000301000000000000090000000000000000000000000000000100000000000000000000000000000003C000000060000000300000000000000C030000000000000C010000000000000C000000000000000030000000000000008000000000000001000000000000000450000000100000030000000000000000000000000000000801100000000000005000000000000000000000000000000010000000000000001000000000000004E0000000200000000000000000000000000000000000000881100000000000048000000000000000C0000000200000008000000000000001800000000000000560000000300000000000000000000000000000000000000D011000000000000680000000000000000000000000000000100000000000000000000000000000060000000030000000000000000000000000000000000000038120000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068120000000000000000000040003800070040000D000B00060000000400000040000000000000004000000000000000400000000000000088010000000000008801000000000000080000000000000001000000040000000000000000000000000000000000000000000000000000009203000000000000920300000000000000100000000000000100000005000000A003000000000000A013000000000000A013000000000000810C000000000000810C000000000000001000000000000001000000060000003010000000000000303000000000000030300000000000005001000000000000500100000000000000100000000000000200000006000000C010000000000000C030000000000000C030000000000000C000000000000000C000000000000000080000000000000052E57464040000003010000000000000303000000000000030300000000000005001000000000000D00F000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120006001020000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F717565727900000000000038300000000000000800000000000000400300000000000048300000000000000800000000000000A013000000000000503000000000000008000000000000006403000000000000583000000000000008000000000000009103000000000000683000000000000008000000000000009103000000000000703000000000000008000000000000003030000000000000903000000000000008000000000000004830000000000000983000000000000008000000000000006003000000000000A03000000000000008000000000000005030000000000000A83000000000000008000000000000005830000000000000B030000000000000080000000000000060300000000000006D61746D756C5F7374617469635F64697370617463685F300000000000000000000000006D61746D756C5F7374617469635F64697370617463685F305F6D61746D756C5F35313278313032347832353600000000000000000000000000000000554889E54157415641554154534881ECF8000000488B4620488B08488B7008488B40108B3A8B52044989F849C1E00548C1E20F4901D04C8985D8FEFFFF48C1E7074801FE4881C6007000004889B5E8FEFFFF488D340A4881C6001C000031C99048898DE0FEFFFF4889CA48C1E20A4889D14881C90004000048898DA0FEFFFF4889D14881C90008000048898DA8FEFFFF4889D14881C9000C000048898DB0FEFFFF4889D14881C90010000048898DB8FEFFFF4889D14881C90014000048898DC0FEFFFF4889D14881C90018000048898DC8FEFFFF4889D148899598FEFFFF4881CA001C0000488995D0FEFFFF4C8B85E8FEFFFF31D266662E0F1F840000000000488B8DD8FEFFFF488D3C0A488B8D98FEFFFF4801F90F280488440F287488104C8B8DA0FEFFFF4E8D0C0F420F280C880F294DB0460F284488104C8B95A8FEFFFF4E8D1417420F281490460F284C90104C8B9DB0FEFFFF4E8D1C1F420F280C980F294DC0460F28549810488B9DB8FEFFFF488D1C1F0F281C98440F285C98104C8BB5C0FEFFFF4901FE420F280CB00F294D90460F2864B0104C8BBDC8FEFFFF4901FF420F282CB8460F286CB8104803BDD0FEFFFF0F280CB8440F287CB81049C7C4F8FFFFFF4D89C5660F1F8400000000000F298D70FFFFFF0F295D80420F288CA620E4FFFF0F298DF0FEFFFF0FC6C900410F28A50090FFFF0F28F10F59F40F58F00F28C5410F28AD1090FFFF0F59CD410F58CE420F28BCA620E8FFFF0F29BD60FFFFFF0FC6FF000F28DF0F59DC0F585DB00F299D20FFFFFF0F59FD410F58F8460F2884A620ECFFFF440F298530FFFFFF450FC6C000410F28D80F59DC0F58DA0F295DA0440F59C5450F58C1460F288CA620F0FFFF440F298D40FFFFFF450FC6C900410F28D10F59D40F5855C0440F59CD450F58CA460F2894A620F4FFFF440F299550FFFFFF450FC6D200410F28DA0F59DC0F585D800F299D00FFFFFF440F59D5450F58D3420F289CA620F8FFFF0F295D800FC6DB00440F28DB440F59DC440F585D900F59DD410F58DC460F28A4A620FCFFFF440F2965B0450F28F7450F28FC450FC6FC00450F28E7440F59E4440F58E0440F59FD450F58FD460F286CA620440F296DC0450FC6ED00410F59E50F58A570FFFFFF0F296590440F59ED450F58EE440F28B5F0FEFFFF450FC6F655410F28A510A0FFFF410F28EE0F59EC0F58E9410F288D00A0FFFF440F59F1440F58F60F288560FFFFFF0FC6C0550F28F00F59F40F58F70F29B570FFFFFF0F59C10F588520FFFFFF0F28F00F288530FFFFFF0FC6C0550F28F80F59FC410F58F80F29BD20FFFFFF0F59C10F5845A00F28F80F288540FFFFFF0FC6C055440F28C0440F59C4450F58C1440F2945A00F59C10F58C2440F28C00F289550FFFFFF0FC6D2550F28C20F59C4410F58C20F298510FFFFFF0F59D10F589500FFFFFF440F285580450FC6D255450F28CA440F59CC440F58CB440F59D1450F58D3440F285DB0450FC6DB55410F28DB0F59DC410F58DF440F59D9450F58DC440F2865C0450FC6E455410F59E4410F58E5440F59E1440F5865900F2885F0FEFFFF440F28F8440FC6F8AA410F288D00B0FFFF450F28EF440F59E9450F58EE440F296D90450F28AD10B0FFFF450F59FD440F58FD0F28AD60FFFFFF0FC6EDAA440F28F5440F59F1440F58F6440F29B500FFFFFF410F59ED0F58AD70FFFFFF0F28B530FFFFFF0FC6F6AA440F28F6440F59F1440F58F7440F29B570FFFFFF410F59F50F58B520FFFFFF0F28BD40FFFFFF0FC6FFAA440F28F7440F59F1450F58F0440F29B520FFFFFF410F59FD0F587DA0440F288550FFFFFF450FC6C0AA450F28F0440F59F1440F58F2440F2975A0450F59C5440F588510FFFFFF0F2855800FC6D2AA440F28F2440F59F1450F58F2440F29B510FFFFFF410F59D5410F58D1440F284DB0450FC6C9AA450F28F1440F59F1450F58F3450F59CD440F58CB440F2855C0450FC6D2AA410F59CA410F58CC450F59D5440F58D40FC6C0FF450F28AD10C0FFFF440F28E0450F59E5450F58E7450F289D00C0FFFF410F59C30F5845900F28A560FFFFFF0FC6E4FF0F28DC410F59DD0F58DD410F59E30F58A500FFFFFF440F28FC0F28AD30FFFFFF0FC6EDFF0F28E5410F59E50F58E6410F59EB0F58AD70FFFFFF0F29AD30FFFFFF0F28B540FFFFFF0FC6F6FF0F28EE410F59ED0F58EF410F59F30F58B520FFFFFF0F29B540FFFFFF0F28BD50FFFFFF0FC6FFFF0F28F7410F59F5410F58F0410F59FB0F587DA00F29BD50FFFFFF440F284580450FC6C0FF410F28F8410F59FD0F58FA450F59C3440F588510FFFFFF440F294580440F2845B0450FC6C0FF410F28D0410F59D5410F58D1450F59C3450F58C6440F2945B0440F2845C0450FC6C0FF450F59E8450F58EA450F59C3440F58C1440F2945C0420F288CA630E4FFFF0F298D60FFFFFF0FC6C900450F28B500D0FFFF440F28C1450F59C6440F58C0410F288510D0FFFF0F59C8410F58CC460F288CA630E8FFFF440F298DF0FEFFFF450FC6C900450F28D1450F59D6450F58D7440F2955A0440F59C8440F58CB420F289CA630ECFFFF0F295D900FC6DB00440F28D3450F59D6440F589530FFFFFF0F59D80F58DC420F28A4A630F0FFFF0F29A530FFFFFF0FC6E400440F28E4450F59E6440F58A540FFFFFF0F59E00F58E5420F28ACA630F4FFFF0F29AD40FFFFFF0FC6ED00440F28FD450F59FE440F58BD50FFFFFF0F59E80F58EE420F28B4A630F8FFFF0F29B520FFFFFF0FC6F600440F28DE450F59DE440F585D80440F299D00FFFFFF0F59F00F58F7460F289CA630FCFFFF440F299D50FFFFFF450FC6DB00410F28FB410F59FE0F587DB00F29BD70FFFFFF440F59D8440F58DA420F2854A6300F2955800FC6D200440F59F2440F5875C0440F2975C00F59D0410F58D5440F28AD60FFFFFF450FC6ED55410F28BD10E0FFFF450F28F5440F59F7440F58F1440F2975B0410F288500E0FFFF440F59E8450F58E8440F2885F0FEFFFF450FC6C055410F28C80F59CF410F58C90F298D10FFFFFF440F59C0440F5845A0440F284D90450FC6C955410F28C90F59CF0F58CB0F294DA0440F59C8450F58CA440F289530FFFFFF450FC6D255410F28DA0F59DF0F58DC440F59D0450F58D4440F28A540FFFFFF450FC6E455410F28E40F59E70F58E5440F59E0450F58E7440F28BD20FFFFFF450FC6FF55410F28EF0F59EF0F58EE440F59F8440F58BD00FFFFFF0F28B550FFFFFF0FC6F6550F28CE0F59CF410F58CB0F298D00FFFFFF0F59F00F58B570FFFFFF440F287580450FC6F655410F59FE0F58FA440F59F0440F5875C0440F289D60FFFFFF450FC6DBAA410F288500F0FFFF410F28CB0F59C8410F58CD0F294DC0410F288D10F0FFFF440F59D9440F585DB00F2895F0FEFFFF0FC6D2AA440F28EA440F59E8450F58E8440F296DB00F59D10F589510FFFFFF440F286D90450FC6EDAA450F28C5440F59C0450F58C1440F298570FFFFFF440F59E9440F586DA0440F29AD80FEFFFF440F28AD30FFFFFF450FC6EDAA450F28C5440F59C0450F58C2440F298510FFFFFF440F59E9440F58EB0F289D40FFFFFF0FC6DBAA440F28C3440F59C0450F58C4440F298560FEFFFF0F59D90F58DC440F28A520FFFFFF410F28E4410FC6E4AA440F28C4440F59C0450F58C7450F28F80F59E10F58E50F28AD50FFFFFF0FC6EDAA440F28C5440F59C0440F58C6440F298570FEFFFF0F59E90F58AD00FFFFFF0F2875800FC6F6AA0F59C6410F58C60F2945A00F59F10F58F7440F288560FFFFFF450FC6C0FF410F284510450F28F0440F59F0450F58F3410F287D00440F59C7440F5845C0440F298560FFFFFF440F288DF0FEFFFF450FC6C9FF450F28C1440F59C0440F58C2440F59CF440F584DB0440F294DB00F2855900FC6D2FF440F28CA440F59C8440F588D80FEFFFF0F59D70F589570FFFFFF0F288D30FFFFFF0FC6C9FF440F28D1440F59D0450F58D50F59CF0F588D10FFFFFF0F294DC00F288D40FFFFFF0FC6C9FF440F28D9440F59D8440F58DB0F59CF0F28D90F589D60FEFFFF410F28CC410FC6CCFF440F28E1440F59E0440F58E40F59CF410F58CF0F294D900F288D50FFFFFF0FC6C9FF440F28E9440F59E8440F58ED0F59CF0F28E90F58AD70FEFFFF0F284D800FC6C9FF0F59C1440F28F80F288560FFFFFF440F58FE0F59CF0F584DA04983C4084981C5008000004981FCF80000000F820BF6FFFF0F290488440F297488100F2845B0420F290488460F29448810420F291490460F294C90100F2845C0420F290498460F295498100F291C98440F295C98100F284590420F2904B0460F2964B010420F292CB8460F296CB8100F290CB8440F297CB810488D4A084983C0204883FA184889CA0F82C5F4FFFF488B95E0FEFFFF488D4A084881C6002000004883FA180F8209F4FFFF31C04881C4F80000005B415C415D415E415F5DC3CCCCCCCCCC31C083FF03488D0D54100000480F44C1C30000000000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000080100000000000009000000000000001800000000000000F9FFFF6F000000000B000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F8010000000000000000000000000000000000000000000049524545000000000000000000000000000000000000000000000000000000002300000000020800C0300000000000000000000000000000010000001200060010200000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E74657874002E646174612E72656C2E726F002E64796E616D6963002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F000000030000000200000000000000100200000000000010020000000000002300000000000000000000000000000001000000000000000000000000000000170000000400000002000000000000003802000000000000380200000000000008010000000000000100000000000000080000000000000018000000000000002100000001000000020000000000000040030000000000004003000000000000520000000000000000000000000000000800000000000000000000000000000029000000010000000600000000000000A013000000000000A003000000000000810C0000000000000000000000000000100000000000000000000000000000002F0000000100000003000000000000003030000000000000301000000000000090000000000000000000000000000000100000000000000000000000000000003C000000060000000300000000000000C030000000000000C010000000000000C000000000000000030000000000000008000000000000001000000000000000450000000100000030000000000000000000000000000000801100000000000005000000000000000000000000000000010000000000000001000000000000004E0000000200000000000000000000000000000000000000881100000000000048000000000000000C0000000200000008000000000000001800000000000000560000000300000000000000000000000000000000000000D011000000000000680000000000000000000000000000000100000000000000000000000000000060000000030000000000000000000000000000000000000038120000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068120000000000000000000040003800070040000D000B00060000000400000040000000000000004000000000000000400000000000000088010000000000008801000000000000080000000000000001000000040000000000000000000000000000000000000000000000000000009203000000000000920300000000000000100000000000000100000005000000A003000000000000A013000000000000A013000000000000810C000000000000810C000000000000001000000000000001000000060000003010000000000000303000000000000030300000000000005001000000000000500100000000000000100000000000000200000006000000C010000000000000C030000000000000C030000000000000C000000000000000C000000000000000080000000000000052E57464040000003010000000000000303000000000000030300000000000005001000000000000D00F000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120006001020000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F717565727900000000000038300000000000000800000000000000400300000000000048300000000000000800000000000000A013000000000000503000000000000008000000000000006403000000000000583000000000000008000000000000009103000000000000683000000000000008000000000000009103000000000000703000000000000008000000000000003030000000000000903000000000000008000000000000004830000000000000983000000000000008000000000000006003000000000000A03000000000000008000000000000005030000000000000A83000000000000008000000000000005830000000000000B030000000000000080000000000000060300000000000006D61746D756C5F7374617469635F64697370617463685F300000000000000000000000006D61746D756C5F7374617469635F64697370617463685F305F6D61746D756C5F35313278313032347832353600000000000000000000000000000000554889E54157415641554154534881ECF8000000488B4620488B08488B7008488B40108B3A8B52044989F849C1E00548C1E20F4901D04C8985D8FEFFFF48C1E7074801FE4881C6007000004889B5E8FEFFFF488D340A4881C6001C000031C99048898DE0FEFFFF4889CA48C1E20A4889D14881C90004000048898DA0FEFFFF4889D14881C90008000048898DA8FEFFFF4889D14881C9000C000048898DB0FEFFFF4889D14881C90010000048898DB8FEFFFF4889D14881C90014000048898DC0FEFFFF4889D14881C90018000048898DC8FEFFFF4889D148899598FEFFFF4881CA001C0000488995D0FEFFFF4C8B85E8FEFFFF31D266662E0F1F840000000000488B8DD8FEFFFF488D3C0A488B8D98FEFFFF4801F90F280488440F287488104C8B8DA0FEFFFF4E8D0C0F420F280C880F294DB0460F284488104C8B95A8FEFFFF4E8D1417420F281490460F284C90104C8B9DB0FEFFFF4E8D1C1F420F280C980F294DC0460F28549810488B9DB8FEFFFF488D1C1F0F281C98440F285C98104C8BB5C0FEFFFF4901FE420F280CB00F294D90460F2864B0104C8BBDC8FEFFFF4901FF420F282CB8460F286CB8104803BDD0FEFFFF0F280CB8440F287CB81049C7C4F8FFFFFF4D89C5660F1F8400000000000F298D70FFFFFF0F295D80420F288CA620E4FFFF0F298DF0FEFFFF0FC6C900410F28A50090FFFF0F28F10F59F40F58F00F28C5410F28AD1090FFFF0F59CD410F58CE420F28BCA620E8FFFF0F29BD60FFFFFF0FC6FF000F28DF0F59DC0F585DB00F299D20FFFFFF0F59FD410F58F8460F2884A620ECFFFF440F298530FFFFFF450FC6C000410F28D80F59DC0F58DA0F295DA0440F59C5450F58C1460F288CA620F0FFFF440F298D40FFFFFF450FC6C900410F28D10F59D40F5855C0440F59CD450F58CA460F2894A620F4FFFF440F299550FFFFFF450FC6D200410F28DA0F59DC0F585D800F299D00FFFFFF440F59D5450F58D3420F289CA620F8FFFF0F295D800FC6DB00440F28DB440F59DC440F585D900F59DD410F58DC460F28A4A620FCFFFF440F2965B0450F28F7450F28FC450FC6FC00450F28E7440F59E4440F58E0440F59FD450F58FD460F286CA620440F296DC0450FC6ED00410F59E50F58A570FFFFFF0F296590440F59ED450F58EE440F28B5F0FEFFFF450FC6F655410F28A510A0FFFF410F28EE0F59EC0F58E9410F288D00A0FFFF440F59F1440F58F60F288560FFFFFF0FC6C0550F28F00F59F40F58F70F29B570FFFFFF0F59C10F588520FFFFFF0F28F00F288530FFFFFF0FC6C0550F28F80F59FC410F58F80F29BD20FFFFFF0F59C10F5845A00F28F80F288540FFFFFF0FC6C055440F28C0440F59C4450F58C1440F2945A00F59C10F58C2440F28C00F289550FFFFFF0FC6D2550F28C20F59C4410F58C20F298510FFFFFF0F59D10F589500FFFFFF440F285580450FC6D255450F28CA440F59CC440F58CB440F59D1450F58D3440F285DB0450FC6DB55410F28DB0F59DC410F58DF440F59D9450F58DC440F2865C0450FC6E455410F59E4410F58E5440F59E1440F5865900F2885F0FEFFFF440F28F8440FC6F8AA410F288D00B0FFFF450F28EF440F59E9450F58EE440F296D90450F28AD10B0FFFF450F59FD440F58FD0F28AD60FFFFFF0FC6EDAA440F28F5440F59F1440F58F6440F29B500FFFFFF410F59ED0F58AD70FFFFFF0F28B530FFFFFF0FC6F6AA440F28F6440F59F1440F58F7440F29B570FFFFFF410F59F50F58B520FFFFFF0F28BD40FFFFFF0FC6FFAA440F28F7440F59F1450F58F0440F29B520FFFFFF410F59FD0F587DA0440F288550FFFFFF450FC6C0AA450F28F0440F59F1440F58F2440F2975A0450F59C5440F588510FFFFFF0F2855800FC6D2AA440F28F2440F59F1450F58F2440F29B510FFFFFF410F59D5410F58D1440F284DB0450FC6C9AA450F28F1440F59F1450F58F3450F59CD440F58CB440F2855C0450FC6D2AA410F59CA410F58CC450F59D5440F58D40FC6C0FF450F28AD10C0FFFF440F28E0450F59E5450F58E7450F289D00C0FFFF410F59C30F5845900F28A560FFFFFF0FC6E4FF0F28DC410F59DD0F58DD410F59E30F58A500FFFFFF440F28FC0F28AD30FFFFFF0FC6EDFF0F28E5410F59E50F58E6410F59EB0F58AD70FFFFFF0F29AD30FFFFFF0F28B540FFFFFF0FC6F6FF0F28EE410F59ED0F58EF410F59F30F58B520FFFFFF0F29B540FFFFFF0F28BD50FFFFFF0FC6FFFF0F28F7410F59F5410F58F0410F59FB0F587DA00F29BD50FFFFFF440F284580450FC6C0FF410F28F8410F59FD0F58FA450F59C3440F588510FFFFFF440F294580440F2845B0450FC6C0FF410F28D0410F59D5410F58D1450F59C3450F58C6440F2945B0440F2845C0450FC6C0FF450F59E8450F58EA450F59C3440F58C1440F2945C0420F288CA630E4FFFF0F298D60FFFFFF0FC6C900450F28B500D0FFFF440F28C1450F59C6440F58C0410F288510D0FFFF0F59C8410F58CC460F288CA630E8FFFF440F298DF0FEFFFF450FC6C900450F28D1450F59D6450F58D7440F2955A0440F59C8440F58CB420F289CA630ECFFFF0F295D900FC6DB00440F28D3450F59D6440F589530FFFFFF0F59D80F58DC420F28A4A630F0FFFF0F29A530FFFFFF0FC6E400440F28E4450F59E6440F58A540FFFFFF0F59E00F58E5420F28ACA630F4FFFF0F29AD40FFFFFF0FC6ED00440F28FD450F59FE440F58BD50FFFFFF0F59E80F58EE420F28B4A630F8FFFF0F29B520FFFFFF0FC6F600440F28DE450F59DE440F585D80440F299D00FFFFFF0F59F00F58F7460F289CA630FCFFFF440F299D50FFFFFF450FC6DB00410F28FB410F59FE0F587DB00F29BD70FFFFFF440F59D8440F58DA420F2854A6300F2955800FC6D200440F59F2440F5875C0440F2975C00F59D0410F58D5440F28AD60FFFFFF450FC6ED55410F28BD10E0FFFF450F28F5440F59F7440F58F1440F2975B0410F288500E0FFFF440F59E8450F58E8440F2885F0FEFFFF450FC6C055410F28C80F59CF410F58C90F298D10FFFFFF440F59C0440F5845A0440F284D90450FC6C955410F28C90F59CF0F58CB0F294DA0440F59C8450F58CA440F289530FFFFFF450FC6D255410F28DA0F59DF0F58DC440F59D0450F58D4440F28A540FFFFFF450FC6E455410F28E40F59E70F58E5440F59E0450F58E7440F28BD20FFFFFF450FC6FF55410F28EF0F59EF0F58EE440F59F8440F58BD00FFFFFF0F28B550FFFFFF0FC6F6550F28CE0F59CF410F58CB0F298D00FFFFFF0F59F00F58B570FFFFFF440F287580450FC6F655410F59FE0F58FA440F59F0440F5875C0440F289D60FFFFFF450FC6DBAA410F288500F0FFFF410F28CB0F59C8410F58CD0F294DC0410F288D10F0FFFF440F59D9440F585DB00F2895F0FEFFFF0FC6D2AA440F28EA440F59E8450F58E8440F296DB00F59D10F589510FFFFFF440F286D90450FC6EDAA450F28C5440F59C0450F58C1440F298570FFFFFF440F59E9440F586DA0440F29AD80FEFFFF440F28AD30FFFFFF450FC6EDAA450F28C5440F59C0450F58C2440F298510FFFFFF440F59E9440F58EB0F289D40FFFFFF0FC6DBAA440F28C3440F59C0450F58C4440F298560FEFFFF0F59D90F58DC440F28A520FFFFFF410F28E4410FC6E4AA440F28C4440F59C0450F58C7450F28F80F59E10F58E50F28AD50FFFFFF0FC6EDAA440F28C5440F59C0440F58C6440F298570FEFFFF0F59E90F58AD00FFFFFF0F2875800FC6F6AA0F59C6410F58C60F2945A00F59F10F58F7440F288560FFFFFF450FC6C0FF410F284510450F28F0440F59F0450F58F3410F287D00440F59C7440F5845C0440F298560FFFFFF440F288DF0FEFFFF450FC6C9FF450F28C1440F59C0440F58C2440F59CF440F584DB0440F294DB00F2855900FC6D2FF440F28CA440F59C8440F588D80FEFFFF0F59D70F589570FFFFFF0F288D30FFFFFF0FC6C9FF440F28D1440F59D0450F58D50F59CF0F588D10FFFFFF0F294DC00F288D40FFFFFF0FC6C9FF440F28D9440F59D8440F58DB0F59CF0F28D90F589D60FEFFFF410F28CC410FC6CCFF440F28E1440F59E0440F58E40F59CF410F58CF0F294D900F288D50FFFFFF0FC6C9FF440F28E9440F59E8440F58ED0F59CF0F28E90F58AD70FEFFFF0F284D800FC6C9FF0F59C1440F28F80F288560FFFFFF440F58FE0F59CF0F584DA04983C4084981C5008000004981FCF80000000F820BF6FFFF0F290488440F297488100F2845B0420F290488460F29448810420F291490460F294C90100F2845C0420F290498460F295498100F291C98440F295C98100F284590420F2904B0460F2964B010420F292CB8460F296CB8100F290CB8440F297CB810488D4A084983C0204883FA184889CA0F82C5F4FFFF488B95E0FEFFFF488D4A084881C6002000004883FA180F8209F4FFFF31C04881C4F80000005B415C415D415E415F5DC3CCCCCCCCCC31C083FF03488D0D54100000480F44C1C30000000000000000000000000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000080100000000000009000000000000001800000000000000F9FFFF6F000000000B000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F8010000000000000000000000000000000000000000000049524545000000000000000000000000000000000000000000000000000000002300000000020800C0300000000000000000000000000000010000001200060010200000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E74657874002E646174612E72656C2E726F002E64796E616D6963002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F000000030000000200000000000000100200000000000010020000000000002300000000000000000000000000000001000000000000000000000000000000170000000400000002000000000000003802000000000000380200000000000008010000000000000100000000000000080000000000000018000000000000002100000001000000020000000000000040030000000000004003000000000000520000000000000000000000000000000800000000000000000000000000000029000000010000000600000000000000A013000000000000A003000000000000810C0000000000000000000000000000100000000000000000000000000000002F0000000100000003000000000000003030000000000000301000000000000090000000000000000000000000000000100000000000000000000000000000003C000000060000000300000000000000C030000000000000C010000000000000C000000000000000030000000000000008000000000000001000000000000000450000000100000030000000000000000000000000000000801100000000000005000000000000000000000000000000010000000000000001000000000000004E0000000200000000000000000000000000000000000000881100000000000048000000000000000C0000000200000008000000000000001800000000000000560000000300000000000000000000000000000000000000D011000000000000680000000000000000000000000000000100000000000000000000000000000060000000030000000000000000000000000000000000000038120000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
    vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
    vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
    vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
    vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
    vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
    vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
    vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c2 = vm.const.i32 2
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c32 = vm.const.i32 32
      %zero = vm.const.i32.zero
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c256 = vm.const.i64 256
      %c1 = vm.const.i32 1
      %c553648160 = vm.const.i32 553648160
      %c1_0 = vm.const.i64 1
      %c1024 = vm.const.i64 1024
      %c512 = vm.const.i64 512
      %c2097152 = vm.const.i64 2097152
      %c1048576 = vm.const.i64 1048576
      %c524288 = vm.const.i64 524288
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %c2_2 = vm.const.i64 2
      %c-1_3 = vm.const.i32 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %0, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %0, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_static attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c2 = vm.const.i32 2
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c32 = vm.const.i32 32
  %zero = vm.const.i32.zero
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c256 = vm.const.i64 256
  %c1 = vm.const.i32 1
  %c553648160 = vm.const.i32 553648160
  %c1_0 = vm.const.i64 1
  %c1024 = vm.const.i64 1024
  %c512 = vm.const.i64 512
  %c2097152 = vm.const.i64 2097152
  %c1048576 = vm.const.i64 1048576
  %c524288 = vm.const.i64 524288
  %zero_1 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %c2_2 = vm.const.i64 2
  %c-1_3 = vm.const.i32 -1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.cond_br %_device_query_0, ^bb1, ^bb4
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %0, ^bb3, ^bb2
^bb2:  // pred: ^bb1
  %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_10 : !vm.ref<!hal.buffer_view>
^bb3:  // pred: ^bb1
  vm.fail %0, "failed to wait on timepoint"
^bb4:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.cond_br %3, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
  %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 18, export_funcs = 2, internal_funcs = 2, global_bytes = 4, global_refs = 2, rodatas = 4, rwdatas = 0>} {
  vm.global.i32 private mutable @_device_query_0 {ordinal = 0 : i32} : i32
  vm.global.ref private mutable @_pipeline_layout_0 {ordinal = 0 : i32} : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_matmul_static_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.rodata private @matmul_static_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf", ordinal = 0 : i32} dense<"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"> : vector<5544xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64, ordinal = 1 : i32} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64, ordinal = 2 : i32} "embedded-elf-x86_64"
  vm.import @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 0 : i32, sym_visibility = "private"}
  vm.import @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 1 : i32, sym_visibility = "private"}
  vm.import @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 2 : i32, sym_visibility = "private"}
  vm.import @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 3 : i32, sym_visibility = "private"}
  vm.import @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 4 : i32, sym_visibility = "private"}
  vm.import @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {ordinal = 5 : i32, sym_visibility = "private"}
  vm.import @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 6 : i32, sym_visibility = "private"}
  vm.import @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {ordinal = 7 : i32, sym_visibility = "private"}
  vm.import @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 8 : i32, sym_visibility = "private"}
  vm.import @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {ordinal = 9 : i32, sym_visibility = "private"}
  vm.import @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, ordinal = 10 : i32, sym_visibility = "private"}
  vm.import @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 11 : i32, sym_visibility = "private"}
  vm.import @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 12 : i32, sym_visibility = "private"}
  vm.import @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {ordinal = 13 : i32, sym_visibility = "private"}
  vm.import @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 14 : i32, sym_visibility = "private"}
  vm.import @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {ordinal = 15 : i32, sym_visibility = "private"}
  vm.import @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 16 : i32, sym_visibility = "private", vm.yield}
  vm.import @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, ordinal = 17 : i32, sym_visibility = "private"}
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64, ordinal = 3 : i32} "tensor"
  vm.func private @matmul_static(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>, %arg2: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {ordinal = 0 : i32} {
    %c2 = vm.const.i32 2
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c32 = vm.const.i32 32
    %zero = vm.const.i32.zero
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c256 = vm.const.i64 256
    %c1 = vm.const.i32 1
    %c553648160 = vm.const.i32 553648160
    %c1_0 = vm.const.i64 1
    %c1024 = vm.const.i64 1024
    %c512 = vm.const.i64 512
    %c2097152 = vm.const.i64 2097152
    %c1048576 = vm.const.i64 1048576
    %c524288 = vm.const.i64 524288
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %c2_2 = vm.const.i64 2
    %c-1_3 = vm.const.i32 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_matmul_static_dispatch_0 = vm.global.load.ref @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c256]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c524288, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c256, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_6 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_6, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c1048576, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    vm.call.variadic @hal.buffer_view.assert(%arg2, %_utf8_tensor_3C6209B4FD120BDC, %c553648160, %c1, [%c512, %c1024]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref_7 = vm.call @hal.buffer_view.buffer(%arg2) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_7, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c2097152, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero_1, [(%zero_1, %zero, %ref, %zero_1, %c524288), (%c1_0, %zero, %ref_6, %zero_1, %c1048576), (%c2_2, %zero, %ref_7, %zero_1, %c2097152)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_matmul_static_dispatch_0, %zero, %c32, %c16, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %0 = vm.call.variadic @hal.fence.await(%c-1_3, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %0, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %c2097152, %c553648160, %c1, [%c512, %c1024]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %0, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_static attributes {iree.abi.stub, ordinal = 0 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 1 : i32} {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %matmul_static_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @matmul_static_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %matmul_static_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable_matmul_static_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

